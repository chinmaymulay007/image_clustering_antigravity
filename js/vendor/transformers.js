/**
 * Bundled by jsDelivr using Rollup v2.79.2 and Terser v5.39.0.
 * Original file: /npm/@xenova/transformers@2.14.0/src/transformers.js
 *
 * Do NOT use SRI with dynamically generated files! More information: https://www.jsdelivr.com/using-sri-with-dynamic-files
 */
import *as e from "./onnxruntime-web.js"; import { Template as t } from "./jinja.js"; function s(e, t) { return t.forEach((function (t) { t && "string" != typeof t && !Array.isArray(t) && Object.keys(t).forEach((function (s) { if ("default" !== s && !(s in e)) { var n = Object.getOwnPropertyDescriptor(t, s); Object.defineProperty(e, s, n.get ? n : { enumerable: !0, get: function () { return t[s] } }) } })) })), Object.freeze(e) } function n(e, t) { e && e(t) } function r(e) { return e.replace(/[.*+?^${}()|[\]\\]/g, "\\$&") } const i = class { constructor() { let e = function (...t) { return e._call(...t) }; return Object.setPrototypeOf(e, new.target.prototype) } _call(...e) { throw Error("Must implement _call method in subclass") } }; function o(e) { return Number.isInteger(e) || "bigint" == typeof e } function a(e) { const t = []; let s = e; for (; Array.isArray(s);)t.push(s.length), s = s[0]; return t } function l(e, t, s = void 0) { const n = e[t]; if (void 0 !== n) return delete e[t], n; if (void 0 === s) throw Error(`Key ${t} does not exist in object.`); return s } function c(...e) { return Array.prototype.concat.apply([], e) } function h(...e) { return e.reduce(((e, t) => e.flatMap((e => t.map((t => [e, t])))))) } function d(e, t) { return Math.abs((e + t) % (2 * t) - t) } var u = "undefined" != typeof global ? global : "undefined" != typeof self ? self : "undefined" != typeof window ? window : {}; function _() { throw new Error("setTimeout has not been defined") } function f() { throw new Error("clearTimeout has not been defined") } var p = _, m = f; function g(e) { if (p === setTimeout) return setTimeout(e, 0); if ((p === _ || !p) && setTimeout) return p = setTimeout, setTimeout(e, 0); try { return p(e, 0) } catch (t) { try { return p.call(null, e, 0) } catch (t) { return p.call(this, e, 0) } } } "function" == typeof u.setTimeout && (p = setTimeout), "function" == typeof u.clearTimeout && (m = clearTimeout); var w, y = [], x = !1, k = -1; function b() { x && w && (x = !1, w.length ? y = w.concat(y) : k = -1, y.length && v()) } function v() { if (!x) { var e = g(b); x = !0; for (var t = y.length; t;) { for (w = y, y = []; ++k < t;)w && w[k].run(); k = -1, t = y.length } w = null, x = !1, function (e) { if (m === clearTimeout) return clearTimeout(e); if ((m === f || !m) && clearTimeout) return m = clearTimeout, clearTimeout(e); try { return m(e) } catch (t) { try { return m.call(null, e) } catch (t) { return m.call(this, e) } } }(e) } } function A(e, t) { this.fun = e, this.array = t } A.prototype.run = function () { this.fun.apply(null, this.array) }; function M() { } var z = M, E = M, T = M, S = M, C = M, P = M, F = M; var L = u.performance || {}, I = L.now || L.mozNow || L.msNow || L.oNow || L.webkitNow || function () { return (new Date).getTime() }; var B = new Date; var R = { nextTick: function (e) { var t = new Array(arguments.length - 1); if (arguments.length > 1) for (var s = 1; s < arguments.length; s++)t[s - 1] = arguments[s]; y.push(new A(e, t)), 1 !== y.length || x || g(v) }, title: "browser", browser: !0, env: {}, argv: [], version: "", versions: {}, on: z, addListener: E, once: T, off: S, removeListener: C, removeAllListeners: P, emit: F, binding: function (e) { throw new Error("process.binding is not supported") }, cwd: function () { return "/" }, chdir: function (e) { throw new Error("process.chdir is not supported") }, umask: function () { return 0 }, hrtime: function (e) { var t = .001 * I.call(L), s = Math.floor(t), n = Math.floor(t % 1 * 1e9); return e && (s -= e[0], (n -= e[1]) < 0 && (s--, n += 1e9)), [s, n] }, platform: "browser", release: {}, config: {}, uptime: function () { return (new Date - B) / 1e3 } }, O = [], N = [], U = "undefined" != typeof Uint8Array ? Uint8Array : Array, $ = !1; function D() { $ = !0; for (var e = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/", t = 0; t < 64; ++t)O[t] = e[t], N[e.charCodeAt(t)] = t; N["-".charCodeAt(0)] = 62, N["_".charCodeAt(0)] = 63 } function j(e, t, s) { for (var n, r, i = [], o = t; o < s; o += 3)n = (e[o] << 16) + (e[o + 1] << 8) + e[o + 2], i.push(O[(r = n) >> 18 & 63] + O[r >> 12 & 63] + O[r >> 6 & 63] + O[63 & r]); return i.join("") } function q(e) { var t; $ || D(); for (var s = e.length, n = s % 3, r = "", i = [], o = 16383, a = 0, l = s - n; a < l; a += o)i.push(j(e, a, a + o > l ? l : a + o)); return 1 === n ? (t = e[s - 1], r += O[t >> 2], r += O[t << 4 & 63], r += "==") : 2 === n && (t = (e[s - 2] << 8) + e[s - 1], r += O[t >> 10], r += O[t >> 4 & 63], r += O[t << 2 & 63], r += "="), i.push(r), i.join("") } function G(e, t, s, n, r) { var i, o, a = 8 * r - n - 1, l = (1 << a) - 1, c = l >> 1, h = -7, d = s ? r - 1 : 0, u = s ? -1 : 1, _ = e[t + d]; for (d += u, i = _ & (1 << -h) - 1, _ >>= -h, h += a; h > 0; i = 256 * i + e[t + d], d += u, h -= 8); for (o = i & (1 << -h) - 1, i >>= -h, h += n; h > 0; o = 256 * o + e[t + d], d += u, h -= 8); if (0 === i) i = 1 - c; else { if (i === l) return o ? NaN : 1 / 0 * (_ ? -1 : 1); o += Math.pow(2, n), i -= c } return (_ ? -1 : 1) * o * Math.pow(2, i - n) } function W(e, t, s, n, r, i) { var o, a, l, c = 8 * i - r - 1, h = (1 << c) - 1, d = h >> 1, u = 23 === r ? Math.pow(2, -24) - Math.pow(2, -77) : 0, _ = n ? 0 : i - 1, f = n ? 1 : -1, p = t < 0 || 0 === t && 1 / t < 0 ? 1 : 0; for (t = Math.abs(t), isNaN(t) || t === 1 / 0 ? (a = isNaN(t) ? 1 : 0, o = h) : (o = Math.floor(Math.log(t) / Math.LN2), t * (l = Math.pow(2, -o)) < 1 && (o--, l *= 2), (t += o + d >= 1 ? u / l : u * Math.pow(2, 1 - d)) * l >= 2 && (o++, l /= 2), o + d >= h ? (a = 0, o = h) : o + d >= 1 ? (a = (t * l - 1) * Math.pow(2, r), o += d) : (a = t * Math.pow(2, d - 1) * Math.pow(2, r), o = 0)); r >= 8; e[s + _] = 255 & a, _ += f, a /= 256, r -= 8); for (o = o << r | a, c += r; c > 0; e[s + _] = 255 & o, _ += f, o /= 256, c -= 8); e[s + _ - f] |= 128 * p } var Y = {}.toString, V = Array.isArray || function (e) { return "[object Array]" == Y.call(e) }; function X() { return H.TYPED_ARRAY_SUPPORT ? 2147483647 : 1073741823 } function K(e, t) { if (X() < t) throw new RangeError("Invalid typed array length"); return H.TYPED_ARRAY_SUPPORT ? (e = new Uint8Array(t)).__proto__ = H.prototype : (null === e && (e = new H(t)), e.length = t), e } function H(e, t, s) { if (!(H.TYPED_ARRAY_SUPPORT || this instanceof H)) return new H(e, t, s); if ("number" == typeof e) { if ("string" == typeof t) throw new Error("If encoding is specified then the first argument must be a string"); return Z(this, e) } return Q(this, e, t, s) } function Q(e, t, s, n) { if ("number" == typeof t) throw new TypeError('"value" argument must not be a number'); return "undefined" != typeof ArrayBuffer && t instanceof ArrayBuffer ? function (e, t, s, n) { if (t.byteLength, s < 0 || t.byteLength < s) throw new RangeError("'offset' is out of bounds"); if (t.byteLength < s + (n || 0)) throw new RangeError("'length' is out of bounds"); t = void 0 === s && void 0 === n ? new Uint8Array(t) : void 0 === n ? new Uint8Array(t, s) : new Uint8Array(t, s, n); H.TYPED_ARRAY_SUPPORT ? (e = t).__proto__ = H.prototype : e = ee(e, t); return e }(e, t, s, n) : "string" == typeof t ? function (e, t, s) { "string" == typeof s && "" !== s || (s = "utf8"); if (!H.isEncoding(s)) throw new TypeError('"encoding" must be a valid string encoding'); var n = 0 | ne(t, s); e = K(e, n); var r = e.write(t, s); r !== n && (e = e.slice(0, r)); return e }(e, t, s) : function (e, t) { if (se(t)) { var s = 0 | te(t.length); return 0 === (e = K(e, s)).length || t.copy(e, 0, 0, s), e } if (t) { if ("undefined" != typeof ArrayBuffer && t.buffer instanceof ArrayBuffer || "length" in t) return "number" != typeof t.length || (n = t.length) != n ? K(e, 0) : ee(e, t); if ("Buffer" === t.type && V(t.data)) return ee(e, t.data) } var n; throw new TypeError("First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.") }(e, t) } function J(e) { if ("number" != typeof e) throw new TypeError('"size" argument must be a number'); if (e < 0) throw new RangeError('"size" argument must not be negative') } function Z(e, t) { if (J(t), e = K(e, t < 0 ? 0 : 0 | te(t)), !H.TYPED_ARRAY_SUPPORT) for (var s = 0; s < t; ++s)e[s] = 0; return e } function ee(e, t) { var s = t.length < 0 ? 0 : 0 | te(t.length); e = K(e, s); for (var n = 0; n < s; n += 1)e[n] = 255 & t[n]; return e } function te(e) { if (e >= X()) throw new RangeError("Attempt to allocate Buffer larger than maximum size: 0x" + X().toString(16) + " bytes"); return 0 | e } function se(e) { return !(null == e || !e._isBuffer) } function ne(e, t) { if (se(e)) return e.length; if ("undefined" != typeof ArrayBuffer && "function" == typeof ArrayBuffer.isView && (ArrayBuffer.isView(e) || e instanceof ArrayBuffer)) return e.byteLength; "string" != typeof e && (e = "" + e); var s = e.length; if (0 === s) return 0; for (var n = !1; ;)switch (t) { case "ascii": case "latin1": case "binary": return s; case "utf8": case "utf-8": case void 0: return Ce(e).length; case "ucs2": case "ucs-2": case "utf16le": case "utf-16le": return 2 * s; case "hex": return s >>> 1; case "base64": return Pe(e).length; default: if (n) return Ce(e).length; t = ("" + t).toLowerCase(), n = !0 } } function re(e, t, s) { var n = !1; if ((void 0 === t || t < 0) && (t = 0), t > this.length) return ""; if ((void 0 === s || s > this.length) && (s = this.length), s <= 0) return ""; if ((s >>>= 0) <= (t >>>= 0)) return ""; for (e || (e = "utf8"); ;)switch (e) { case "hex": return ye(this, t, s); case "utf8": case "utf-8": return pe(this, t, s); case "ascii": return ge(this, t, s); case "latin1": case "binary": return we(this, t, s); case "base64": return fe(this, t, s); case "ucs2": case "ucs-2": case "utf16le": case "utf-16le": return xe(this, t, s); default: if (n) throw new TypeError("Unknown encoding: " + e); e = (e + "").toLowerCase(), n = !0 } } function ie(e, t, s) { var n = e[t]; e[t] = e[s], e[s] = n } function oe(e, t, s, n, r) { if (0 === e.length) return -1; if ("string" == typeof s ? (n = s, s = 0) : s > 2147483647 ? s = 2147483647 : s < -2147483648 && (s = -2147483648), s = +s, isNaN(s) && (s = r ? 0 : e.length - 1), s < 0 && (s = e.length + s), s >= e.length) { if (r) return -1; s = e.length - 1 } else if (s < 0) { if (!r) return -1; s = 0 } if ("string" == typeof t && (t = H.from(t, n)), se(t)) return 0 === t.length ? -1 : ae(e, t, s, n, r); if ("number" == typeof t) return t &= 255, H.TYPED_ARRAY_SUPPORT && "function" == typeof Uint8Array.prototype.indexOf ? r ? Uint8Array.prototype.indexOf.call(e, t, s) : Uint8Array.prototype.lastIndexOf.call(e, t, s) : ae(e, [t], s, n, r); throw new TypeError("val must be string, number or Buffer") } function ae(e, t, s, n, r) { var i, o = 1, a = e.length, l = t.length; if (void 0 !== n && ("ucs2" === (n = String(n).toLowerCase()) || "ucs-2" === n || "utf16le" === n || "utf-16le" === n)) { if (e.length < 2 || t.length < 2) return -1; o = 2, a /= 2, l /= 2, s /= 2 } function c(e, t) { return 1 === o ? e[t] : e.readUInt16BE(t * o) } if (r) { var h = -1; for (i = s; i < a; i++)if (c(e, i) === c(t, -1 === h ? 0 : i - h)) { if (-1 === h && (h = i), i - h + 1 === l) return h * o } else -1 !== h && (i -= i - h), h = -1 } else for (s + l > a && (s = a - l), i = s; i >= 0; i--) { for (var d = !0, u = 0; u < l; u++)if (c(e, i + u) !== c(t, u)) { d = !1; break } if (d) return i } return -1 } function le(e, t, s, n) { s = Number(s) || 0; var r = e.length - s; n ? (n = Number(n)) > r && (n = r) : n = r; var i = t.length; if (i % 2 != 0) throw new TypeError("Invalid hex string"); n > i / 2 && (n = i / 2); for (var o = 0; o < n; ++o) { var a = parseInt(t.substr(2 * o, 2), 16); if (isNaN(a)) return o; e[s + o] = a } return o } function ce(e, t, s, n) { return Fe(Ce(t, e.length - s), e, s, n) } function he(e, t, s, n) { return Fe(function (e) { for (var t = [], s = 0; s < e.length; ++s)t.push(255 & e.charCodeAt(s)); return t }(t), e, s, n) } function de(e, t, s, n) { return he(e, t, s, n) } function ue(e, t, s, n) { return Fe(Pe(t), e, s, n) } function _e(e, t, s, n) { return Fe(function (e, t) { for (var s, n, r, i = [], o = 0; o < e.length && !((t -= 2) < 0); ++o)n = (s = e.charCodeAt(o)) >> 8, r = s % 256, i.push(r), i.push(n); return i }(t, e.length - s), e, s, n) } function fe(e, t, s) { return 0 === t && s === e.length ? q(e) : q(e.slice(t, s)) } function pe(e, t, s) { s = Math.min(e.length, s); for (var n = [], r = t; r < s;) { var i, o, a, l, c = e[r], h = null, d = c > 239 ? 4 : c > 223 ? 3 : c > 191 ? 2 : 1; if (r + d <= s) switch (d) { case 1: c < 128 && (h = c); break; case 2: 128 == (192 & (i = e[r + 1])) && (l = (31 & c) << 6 | 63 & i) > 127 && (h = l); break; case 3: i = e[r + 1], o = e[r + 2], 128 == (192 & i) && 128 == (192 & o) && (l = (15 & c) << 12 | (63 & i) << 6 | 63 & o) > 2047 && (l < 55296 || l > 57343) && (h = l); break; case 4: i = e[r + 1], o = e[r + 2], a = e[r + 3], 128 == (192 & i) && 128 == (192 & o) && 128 == (192 & a) && (l = (15 & c) << 18 | (63 & i) << 12 | (63 & o) << 6 | 63 & a) > 65535 && l < 1114112 && (h = l) }null === h ? (h = 65533, d = 1) : h > 65535 && (h -= 65536, n.push(h >>> 10 & 1023 | 55296), h = 56320 | 1023 & h), n.push(h), r += d } return function (e) { var t = e.length; if (t <= me) return String.fromCharCode.apply(String, e); var s = "", n = 0; for (; n < t;)s += String.fromCharCode.apply(String, e.slice(n, n += me)); return s }(n) } H.TYPED_ARRAY_SUPPORT = void 0 === u.TYPED_ARRAY_SUPPORT || u.TYPED_ARRAY_SUPPORT, X(), H.poolSize = 8192, H._augment = function (e) { return e.__proto__ = H.prototype, e }, H.from = function (e, t, s) { return Q(null, e, t, s) }, H.TYPED_ARRAY_SUPPORT && (H.prototype.__proto__ = Uint8Array.prototype, H.__proto__ = Uint8Array, "undefined" != typeof Symbol && Symbol.species && H[Symbol.species]), H.alloc = function (e, t, s) { return function (e, t, s, n) { return J(t), t <= 0 ? K(e, t) : void 0 !== s ? "string" == typeof n ? K(e, t).fill(s, n) : K(e, t).fill(s) : K(e, t) }(null, e, t, s) }, H.allocUnsafe = function (e) { return Z(null, e) }, H.allocUnsafeSlow = function (e) { return Z(null, e) }, H.isBuffer = function (e) { return null != e && (!!e._isBuffer || Le(e) || function (e) { return "function" == typeof e.readFloatLE && "function" == typeof e.slice && Le(e.slice(0, 0)) }(e)) }, H.compare = function (e, t) { if (!se(e) || !se(t)) throw new TypeError("Arguments must be Buffers"); if (e === t) return 0; for (var s = e.length, n = t.length, r = 0, i = Math.min(s, n); r < i; ++r)if (e[r] !== t[r]) { s = e[r], n = t[r]; break } return s < n ? -1 : n < s ? 1 : 0 }, H.isEncoding = function (e) { switch (String(e).toLowerCase()) { case "hex": case "utf8": case "utf-8": case "ascii": case "latin1": case "binary": case "base64": case "ucs2": case "ucs-2": case "utf16le": case "utf-16le": return !0; default: return !1 } }, H.concat = function (e, t) { if (!V(e)) throw new TypeError('"list" argument must be an Array of Buffers'); if (0 === e.length) return H.alloc(0); var s; if (void 0 === t) for (t = 0, s = 0; s < e.length; ++s)t += e[s].length; var n = H.allocUnsafe(t), r = 0; for (s = 0; s < e.length; ++s) { var i = e[s]; if (!se(i)) throw new TypeError('"list" argument must be an Array of Buffers'); i.copy(n, r), r += i.length } return n }, H.byteLength = ne, H.prototype._isBuffer = !0, H.prototype.swap16 = function () { var e = this.length; if (e % 2 != 0) throw new RangeError("Buffer size must be a multiple of 16-bits"); for (var t = 0; t < e; t += 2)ie(this, t, t + 1); return this }, H.prototype.swap32 = function () { var e = this.length; if (e % 4 != 0) throw new RangeError("Buffer size must be a multiple of 32-bits"); for (var t = 0; t < e; t += 4)ie(this, t, t + 3), ie(this, t + 1, t + 2); return this }, H.prototype.swap64 = function () { var e = this.length; if (e % 8 != 0) throw new RangeError("Buffer size must be a multiple of 64-bits"); for (var t = 0; t < e; t += 8)ie(this, t, t + 7), ie(this, t + 1, t + 6), ie(this, t + 2, t + 5), ie(this, t + 3, t + 4); return this }, H.prototype.toString = function () { var e = 0 | this.length; return 0 === e ? "" : 0 === arguments.length ? pe(this, 0, e) : re.apply(this, arguments) }, H.prototype.equals = function (e) { if (!se(e)) throw new TypeError("Argument must be a Buffer"); return this === e || 0 === H.compare(this, e) }, H.prototype.inspect = function () { var e = ""; return this.length > 0 && (e = this.toString("hex", 0, 50).match(/.{2}/g).join(" "), this.length > 50 && (e += " ... ")), "<Buffer " + e + ">" }, H.prototype.compare = function (e, t, s, n, r) { if (!se(e)) throw new TypeError("Argument must be a Buffer"); if (void 0 === t && (t = 0), void 0 === s && (s = e ? e.length : 0), void 0 === n && (n = 0), void 0 === r && (r = this.length), t < 0 || s > e.length || n < 0 || r > this.length) throw new RangeError("out of range index"); if (n >= r && t >= s) return 0; if (n >= r) return -1; if (t >= s) return 1; if (this === e) return 0; for (var i = (r >>>= 0) - (n >>>= 0), o = (s >>>= 0) - (t >>>= 0), a = Math.min(i, o), l = this.slice(n, r), c = e.slice(t, s), h = 0; h < a; ++h)if (l[h] !== c[h]) { i = l[h], o = c[h]; break } return i < o ? -1 : o < i ? 1 : 0 }, H.prototype.includes = function (e, t, s) { return -1 !== this.indexOf(e, t, s) }, H.prototype.indexOf = function (e, t, s) { return oe(this, e, t, s, !0) }, H.prototype.lastIndexOf = function (e, t, s) { return oe(this, e, t, s, !1) }, H.prototype.write = function (e, t, s, n) { if (void 0 === t) n = "utf8", s = this.length, t = 0; else if (void 0 === s && "string" == typeof t) n = t, s = this.length, t = 0; else { if (!isFinite(t)) throw new Error("Buffer.write(string, encoding, offset[, length]) is no longer supported"); t |= 0, isFinite(s) ? (s |= 0, void 0 === n && (n = "utf8")) : (n = s, s = void 0) } var r = this.length - t; if ((void 0 === s || s > r) && (s = r), e.length > 0 && (s < 0 || t < 0) || t > this.length) throw new RangeError("Attempt to write outside buffer bounds"); n || (n = "utf8"); for (var i = !1; ;)switch (n) { case "hex": return le(this, e, t, s); case "utf8": case "utf-8": return ce(this, e, t, s); case "ascii": return he(this, e, t, s); case "latin1": case "binary": return de(this, e, t, s); case "base64": return ue(this, e, t, s); case "ucs2": case "ucs-2": case "utf16le": case "utf-16le": return _e(this, e, t, s); default: if (i) throw new TypeError("Unknown encoding: " + n); n = ("" + n).toLowerCase(), i = !0 } }, H.prototype.toJSON = function () { return { type: "Buffer", data: Array.prototype.slice.call(this._arr || this, 0) } }; var me = 4096; function ge(e, t, s) { var n = ""; s = Math.min(e.length, s); for (var r = t; r < s; ++r)n += String.fromCharCode(127 & e[r]); return n } function we(e, t, s) { var n = ""; s = Math.min(e.length, s); for (var r = t; r < s; ++r)n += String.fromCharCode(e[r]); return n } function ye(e, t, s) { var n = e.length; (!t || t < 0) && (t = 0), (!s || s < 0 || s > n) && (s = n); for (var r = "", i = t; i < s; ++i)r += Se(e[i]); return r } function xe(e, t, s) { for (var n = e.slice(t, s), r = "", i = 0; i < n.length; i += 2)r += String.fromCharCode(n[i] + 256 * n[i + 1]); return r } function ke(e, t, s) { if (e % 1 != 0 || e < 0) throw new RangeError("offset is not uint"); if (e + t > s) throw new RangeError("Trying to access beyond buffer length") } function be(e, t, s, n, r, i) { if (!se(e)) throw new TypeError('"buffer" argument must be a Buffer instance'); if (t > r || t < i) throw new RangeError('"value" argument is out of bounds'); if (s + n > e.length) throw new RangeError("Index out of range") } function ve(e, t, s, n) { t < 0 && (t = 65535 + t + 1); for (var r = 0, i = Math.min(e.length - s, 2); r < i; ++r)e[s + r] = (t & 255 << 8 * (n ? r : 1 - r)) >>> 8 * (n ? r : 1 - r) } function Ae(e, t, s, n) { t < 0 && (t = 4294967295 + t + 1); for (var r = 0, i = Math.min(e.length - s, 4); r < i; ++r)e[s + r] = t >>> 8 * (n ? r : 3 - r) & 255 } function Me(e, t, s, n, r, i) { if (s + n > e.length) throw new RangeError("Index out of range"); if (s < 0) throw new RangeError("Index out of range") } function ze(e, t, s, n, r) { return r || Me(e, 0, s, 4), W(e, t, s, n, 23, 4), s + 4 } function Ee(e, t, s, n, r) { return r || Me(e, 0, s, 8), W(e, t, s, n, 52, 8), s + 8 } H.prototype.slice = function (e, t) { var s, n = this.length; if ((e = ~~e) < 0 ? (e += n) < 0 && (e = 0) : e > n && (e = n), (t = void 0 === t ? n : ~~t) < 0 ? (t += n) < 0 && (t = 0) : t > n && (t = n), t < e && (t = e), H.TYPED_ARRAY_SUPPORT) (s = this.subarray(e, t)).__proto__ = H.prototype; else { var r = t - e; s = new H(r, void 0); for (var i = 0; i < r; ++i)s[i] = this[i + e] } return s }, H.prototype.readUIntLE = function (e, t, s) { e |= 0, t |= 0, s || ke(e, t, this.length); for (var n = this[e], r = 1, i = 0; ++i < t && (r *= 256);)n += this[e + i] * r; return n }, H.prototype.readUIntBE = function (e, t, s) { e |= 0, t |= 0, s || ke(e, t, this.length); for (var n = this[e + --t], r = 1; t > 0 && (r *= 256);)n += this[e + --t] * r; return n }, H.prototype.readUInt8 = function (e, t) { return t || ke(e, 1, this.length), this[e] }, H.prototype.readUInt16LE = function (e, t) { return t || ke(e, 2, this.length), this[e] | this[e + 1] << 8 }, H.prototype.readUInt16BE = function (e, t) { return t || ke(e, 2, this.length), this[e] << 8 | this[e + 1] }, H.prototype.readUInt32LE = function (e, t) { return t || ke(e, 4, this.length), (this[e] | this[e + 1] << 8 | this[e + 2] << 16) + 16777216 * this[e + 3] }, H.prototype.readUInt32BE = function (e, t) { return t || ke(e, 4, this.length), 16777216 * this[e] + (this[e + 1] << 16 | this[e + 2] << 8 | this[e + 3]) }, H.prototype.readIntLE = function (e, t, s) { e |= 0, t |= 0, s || ke(e, t, this.length); for (var n = this[e], r = 1, i = 0; ++i < t && (r *= 256);)n += this[e + i] * r; return n >= (r *= 128) && (n -= Math.pow(2, 8 * t)), n }, H.prototype.readIntBE = function (e, t, s) { e |= 0, t |= 0, s || ke(e, t, this.length); for (var n = t, r = 1, i = this[e + --n]; n > 0 && (r *= 256);)i += this[e + --n] * r; return i >= (r *= 128) && (i -= Math.pow(2, 8 * t)), i }, H.prototype.readInt8 = function (e, t) { return t || ke(e, 1, this.length), 128 & this[e] ? -1 * (255 - this[e] + 1) : this[e] }, H.prototype.readInt16LE = function (e, t) { t || ke(e, 2, this.length); var s = this[e] | this[e + 1] << 8; return 32768 & s ? 4294901760 | s : s }, H.prototype.readInt16BE = function (e, t) { t || ke(e, 2, this.length); var s = this[e + 1] | this[e] << 8; return 32768 & s ? 4294901760 | s : s }, H.prototype.readInt32LE = function (e, t) { return t || ke(e, 4, this.length), this[e] | this[e + 1] << 8 | this[e + 2] << 16 | this[e + 3] << 24 }, H.prototype.readInt32BE = function (e, t) { return t || ke(e, 4, this.length), this[e] << 24 | this[e + 1] << 16 | this[e + 2] << 8 | this[e + 3] }, H.prototype.readFloatLE = function (e, t) { return t || ke(e, 4, this.length), G(this, e, !0, 23, 4) }, H.prototype.readFloatBE = function (e, t) { return t || ke(e, 4, this.length), G(this, e, !1, 23, 4) }, H.prototype.readDoubleLE = function (e, t) { return t || ke(e, 8, this.length), G(this, e, !0, 52, 8) }, H.prototype.readDoubleBE = function (e, t) { return t || ke(e, 8, this.length), G(this, e, !1, 52, 8) }, H.prototype.writeUIntLE = function (e, t, s, n) { (e = +e, t |= 0, s |= 0, n) || be(this, e, t, s, Math.pow(2, 8 * s) - 1, 0); var r = 1, i = 0; for (this[t] = 255 & e; ++i < s && (r *= 256);)this[t + i] = e / r & 255; return t + s }, H.prototype.writeUIntBE = function (e, t, s, n) { (e = +e, t |= 0, s |= 0, n) || be(this, e, t, s, Math.pow(2, 8 * s) - 1, 0); var r = s - 1, i = 1; for (this[t + r] = 255 & e; --r >= 0 && (i *= 256);)this[t + r] = e / i & 255; return t + s }, H.prototype.writeUInt8 = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 1, 255, 0), H.TYPED_ARRAY_SUPPORT || (e = Math.floor(e)), this[t] = 255 & e, t + 1 }, H.prototype.writeUInt16LE = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 2, 65535, 0), H.TYPED_ARRAY_SUPPORT ? (this[t] = 255 & e, this[t + 1] = e >>> 8) : ve(this, e, t, !0), t + 2 }, H.prototype.writeUInt16BE = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 2, 65535, 0), H.TYPED_ARRAY_SUPPORT ? (this[t] = e >>> 8, this[t + 1] = 255 & e) : ve(this, e, t, !1), t + 2 }, H.prototype.writeUInt32LE = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 4, 4294967295, 0), H.TYPED_ARRAY_SUPPORT ? (this[t + 3] = e >>> 24, this[t + 2] = e >>> 16, this[t + 1] = e >>> 8, this[t] = 255 & e) : Ae(this, e, t, !0), t + 4 }, H.prototype.writeUInt32BE = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 4, 4294967295, 0), H.TYPED_ARRAY_SUPPORT ? (this[t] = e >>> 24, this[t + 1] = e >>> 16, this[t + 2] = e >>> 8, this[t + 3] = 255 & e) : Ae(this, e, t, !1), t + 4 }, H.prototype.writeIntLE = function (e, t, s, n) { if (e = +e, t |= 0, !n) { var r = Math.pow(2, 8 * s - 1); be(this, e, t, s, r - 1, -r) } var i = 0, o = 1, a = 0; for (this[t] = 255 & e; ++i < s && (o *= 256);)e < 0 && 0 === a && 0 !== this[t + i - 1] && (a = 1), this[t + i] = (e / o | 0) - a & 255; return t + s }, H.prototype.writeIntBE = function (e, t, s, n) { if (e = +e, t |= 0, !n) { var r = Math.pow(2, 8 * s - 1); be(this, e, t, s, r - 1, -r) } var i = s - 1, o = 1, a = 0; for (this[t + i] = 255 & e; --i >= 0 && (o *= 256);)e < 0 && 0 === a && 0 !== this[t + i + 1] && (a = 1), this[t + i] = (e / o | 0) - a & 255; return t + s }, H.prototype.writeInt8 = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 1, 127, -128), H.TYPED_ARRAY_SUPPORT || (e = Math.floor(e)), e < 0 && (e = 255 + e + 1), this[t] = 255 & e, t + 1 }, H.prototype.writeInt16LE = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 2, 32767, -32768), H.TYPED_ARRAY_SUPPORT ? (this[t] = 255 & e, this[t + 1] = e >>> 8) : ve(this, e, t, !0), t + 2 }, H.prototype.writeInt16BE = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 2, 32767, -32768), H.TYPED_ARRAY_SUPPORT ? (this[t] = e >>> 8, this[t + 1] = 255 & e) : ve(this, e, t, !1), t + 2 }, H.prototype.writeInt32LE = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 4, 2147483647, -2147483648), H.TYPED_ARRAY_SUPPORT ? (this[t] = 255 & e, this[t + 1] = e >>> 8, this[t + 2] = e >>> 16, this[t + 3] = e >>> 24) : Ae(this, e, t, !0), t + 4 }, H.prototype.writeInt32BE = function (e, t, s) { return e = +e, t |= 0, s || be(this, e, t, 4, 2147483647, -2147483648), e < 0 && (e = 4294967295 + e + 1), H.TYPED_ARRAY_SUPPORT ? (this[t] = e >>> 24, this[t + 1] = e >>> 16, this[t + 2] = e >>> 8, this[t + 3] = 255 & e) : Ae(this, e, t, !1), t + 4 }, H.prototype.writeFloatLE = function (e, t, s) { return ze(this, e, t, !0, s) }, H.prototype.writeFloatBE = function (e, t, s) { return ze(this, e, t, !1, s) }, H.prototype.writeDoubleLE = function (e, t, s) { return Ee(this, e, t, !0, s) }, H.prototype.writeDoubleBE = function (e, t, s) { return Ee(this, e, t, !1, s) }, H.prototype.copy = function (e, t, s, n) { if (s || (s = 0), n || 0 === n || (n = this.length), t >= e.length && (t = e.length), t || (t = 0), n > 0 && n < s && (n = s), n === s) return 0; if (0 === e.length || 0 === this.length) return 0; if (t < 0) throw new RangeError("targetStart out of bounds"); if (s < 0 || s >= this.length) throw new RangeError("sourceStart out of bounds"); if (n < 0) throw new RangeError("sourceEnd out of bounds"); n > this.length && (n = this.length), e.length - t < n - s && (n = e.length - t + s); var r, i = n - s; if (this === e && s < t && t < n) for (r = i - 1; r >= 0; --r)e[r + t] = this[r + s]; else if (i < 1e3 || !H.TYPED_ARRAY_SUPPORT) for (r = 0; r < i; ++r)e[r + t] = this[r + s]; else Uint8Array.prototype.set.call(e, this.subarray(s, s + i), t); return i }, H.prototype.fill = function (e, t, s, n) { if ("string" == typeof e) { if ("string" == typeof t ? (n = t, t = 0, s = this.length) : "string" == typeof s && (n = s, s = this.length), 1 === e.length) { var r = e.charCodeAt(0); r < 256 && (e = r) } if (void 0 !== n && "string" != typeof n) throw new TypeError("encoding must be a string"); if ("string" == typeof n && !H.isEncoding(n)) throw new TypeError("Unknown encoding: " + n) } else "number" == typeof e && (e &= 255); if (t < 0 || this.length < t || this.length < s) throw new RangeError("Out of range index"); if (s <= t) return this; var i; if (t >>>= 0, s = void 0 === s ? this.length : s >>> 0, e || (e = 0), "number" == typeof e) for (i = t; i < s; ++i)this[i] = e; else { var o = se(e) ? e : Ce(new H(e, n).toString()), a = o.length; for (i = 0; i < s - t; ++i)this[i + t] = o[i % a] } return this }; var Te = /[^+\/0-9A-Za-z-_]/g; function Se(e) { return e < 16 ? "0" + e.toString(16) : e.toString(16) } function Ce(e, t) { var s; t = t || 1 / 0; for (var n = e.length, r = null, i = [], o = 0; o < n; ++o) { if ((s = e.charCodeAt(o)) > 55295 && s < 57344) { if (!r) { if (s > 56319) { (t -= 3) > -1 && i.push(239, 191, 189); continue } if (o + 1 === n) { (t -= 3) > -1 && i.push(239, 191, 189); continue } r = s; continue } if (s < 56320) { (t -= 3) > -1 && i.push(239, 191, 189), r = s; continue } s = 65536 + (r - 55296 << 10 | s - 56320) } else r && (t -= 3) > -1 && i.push(239, 191, 189); if (r = null, s < 128) { if ((t -= 1) < 0) break; i.push(s) } else if (s < 2048) { if ((t -= 2) < 0) break; i.push(s >> 6 | 192, 63 & s | 128) } else if (s < 65536) { if ((t -= 3) < 0) break; i.push(s >> 12 | 224, s >> 6 & 63 | 128, 63 & s | 128) } else { if (!(s < 1114112)) throw new Error("Invalid code point"); if ((t -= 4) < 0) break; i.push(s >> 18 | 240, s >> 12 & 63 | 128, s >> 6 & 63 | 128, 63 & s | 128) } } return i } function Pe(e) { return function (e) { var t, s, n, r, i, o; $ || D(); var a = e.length; if (a % 4 > 0) throw new Error("Invalid string. Length must be a multiple of 4"); i = "=" === e[a - 2] ? 2 : "=" === e[a - 1] ? 1 : 0, o = new U(3 * a / 4 - i), n = i > 0 ? a - 4 : a; var l = 0; for (t = 0, s = 0; t < n; t += 4, s += 3)r = N[e.charCodeAt(t)] << 18 | N[e.charCodeAt(t + 1)] << 12 | N[e.charCodeAt(t + 2)] << 6 | N[e.charCodeAt(t + 3)], o[l++] = r >> 16 & 255, o[l++] = r >> 8 & 255, o[l++] = 255 & r; return 2 === i ? (r = N[e.charCodeAt(t)] << 2 | N[e.charCodeAt(t + 1)] >> 4, o[l++] = 255 & r) : 1 === i && (r = N[e.charCodeAt(t)] << 10 | N[e.charCodeAt(t + 1)] << 4 | N[e.charCodeAt(t + 2)] >> 2, o[l++] = r >> 8 & 255, o[l++] = 255 & r), o }(function (e) { if ((e = function (e) { return e.trim ? e.trim() : e.replace(/^\s+|\s+$/g, "") }(e).replace(Te, "")).length < 2) return ""; for (; e.length % 4 != 0;)e += "="; return e }(e)) } function Fe(e, t, s, n) { for (var r = 0; r < n && !(r + s >= t.length || r >= e.length); ++r)t[r + s] = e[r]; return r } function Le(e) { return !!e.constructor && "function" == typeof e.constructor.isBuffer && e.constructor.isBuffer(e) } var Ie = {}, Be = s({ __proto__: null, default: Ie }, [Ie]); let Re; const Oe = ["wasm"]; if ("node" === R?.release?.name) Re = Ie ?? Be, Oe.unshift("cpu"); else { Re = e.default ?? e; "undefined" != typeof navigator && /iP(hone|od|ad).+16_4.+AppleWebKit/.test(navigator.userAgent) && (Re.env.wasm.simd = !1) } const { env: Ne } = Re, Ue = "2.14.0", $e = "undefined" != typeof self && "caches" in self, De = !Ke(Ie), je = !Ke(Ie), qe = De && je, Ge = qe ? Ie.dirname(Ie.dirname(Ie.fileURLToPath(import.meta.url))) : "./", We = qe ? Ie.join(Ge, "/.cache/") : null, Ye = "/models/", Ve = qe ? Ie.join(Ge, Ye) : Ye; Ne.wasm.wasmPaths = qe ? Ie.join(Ge, "/dist/") : `https://cdn.jsdelivr.net/npm/@xenova/transformers@${Ue}/dist/`; const Xe = { backends: { onnx: Ne, tfjs: {} }, __dirname: Ge, version: Ue, allowRemoteModels: !0, remoteHost: "https://huggingface.co/", remotePathTemplate: "{model}/resolve/{revision}/", allowLocalModels: !0, localModelPath: Ve, useFS: De, useBrowserCache: $e, useFSCache: De, cacheDir: We, useCustomCache: !1, customCache: null }; function Ke(e) { return 0 === Object.keys(e).length } globalThis.ReadableStream || (globalThis.ReadableStream = Ie.ReadableStream); class He { _CONTENT_TYPE_MAP = { txt: "text/plain", html: "text/html", css: "text/css", js: "text/javascript", json: "application/json", png: "image/png", jpg: "image/jpeg", jpeg: "image/jpeg", gif: "image/gif" }; constructor(e) { if (this.filePath = e, this.headers = new Headers, this.exists = Ie.existsSync(e), this.exists) { this.status = 200, this.statusText = "OK"; let t = Ie.statSync(e); this.headers.set("content-length", t.size.toString()), this.updateContentType(); let s = this; this.body = new ReadableStream({ start(e) { s.arrayBuffer().then((t => { e.enqueue(new Uint8Array(t)), e.close() })) } }) } else this.status = 404, this.statusText = "Not Found", this.body = null } updateContentType() { const e = this.filePath.toString().split(".").pop().toLowerCase(); this.headers.set("content-type", this._CONTENT_TYPE_MAP[e] ?? "application/octet-stream") } clone() { let e = new He(this.filePath); return e.exists = this.exists, e.status = this.status, e.statusText = this.statusText, e.headers = new Headers(this.headers), e } async arrayBuffer() { return (await Ie.promises.readFile(this.filePath)).buffer } async blob() { const e = await Ie.promises.readFile(this.filePath); return new Blob([e], { type: this.headers.get("content-type") }) } async text() { return await Ie.promises.readFile(this.filePath, "utf8") } async json() { return JSON.parse(await this.text()) } } function Qe(e, t = null) { let s; try { s = new URL(e) } catch (e) { return !1 } return !(t && !t.includes(s.hostname)) && ("http:" === s.protocol || "https:" === s.protocol) } async function Je(e) { if (Xe.useFS && !Qe(e)) return new He(e); if ("node" === R?.release?.name) { const t = !!R.env?.TESTING_REMOTELY, s = Xe.version, n = new Headers; n.set("User-Agent", `transformers.js/${s}; is_ci/${t};`); if (Qe(e, ["huggingface.co", "hf.co"])) { const e = R.env?.HF_TOKEN ?? R.env?.HF_ACCESS_TOKEN; e && n.set("Authorization", `Bearer ${e}`) } return fetch(e, { headers: n }) } return fetch(e) } const Ze = { 400: "Bad request error occurred while trying to load file", 401: "Unauthorized access to file", 403: "Forbidden access to file", 404: "Could not locate file", 408: "Request timeout error occurred while trying to load file", 500: "Internal server error error occurred while trying to load file", 502: "Bad gateway error occurred while trying to load file", 503: "Service unavailable error occurred while trying to load file", 504: "Gateway timeout error occurred while trying to load file" }; class et { constructor(e) { this.path = e } async match(e) { let t = Ie.join(this.path, e), s = new He(t); return s.exists ? s : void 0 } async put(e, t) { const s = H.from(await t.arrayBuffer()); let n = Ie.join(this.path, e); try { await Ie.promises.mkdir(Ie.dirname(n), { recursive: !0 }), await Ie.promises.writeFile(n, s) } catch (e) { console.warn("An error occurred while writing the file to cache:", e) } } } async function tt(e, t, s = !0, r = {}) { if (!Xe.allowLocalModels) { if (r.local_files_only) throw Error("Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`)."); if (!Xe.allowRemoteModels) throw Error("Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.") } let i; if (n(r.progress_callback, { status: "initiate", name: e, file: t }), !i && Xe.useBrowserCache) { if ("undefined" == typeof caches) throw Error("Browser cache is not available in this environment."); try { i = await caches.open("transformers-cache") } catch (e) { console.warn("An error occurred while opening the browser cache:", e) } } if (!i && Xe.useFSCache && (i = new et(r.cache_dir ?? Xe.cacheDir)), !i && Xe.useCustomCache) { if (!Xe.customCache) throw Error("`env.useCustomCache=true`, but `env.customCache` is not defined."); if (!Xe.customCache.match || !Xe.customCache.put) throw new Error("`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache"); i = Xe.customCache } const o = r.revision ?? "main"; let a, l, c = nt(e, t), h = nt(Xe.localModelPath, c), d = nt(Xe.remoteHost, Xe.remotePathTemplate.replaceAll("{model}", e).replaceAll("{revision}", encodeURIComponent(o)), t), u = "main" === o ? c : nt(e, o, t), _ = i instanceof et ? u : d, f = !1; i && (l = await async function (e, ...t) { for (let s of t) try { let t = await e.match(s); if (t) return t } catch (e) { continue } }(i, h, _)); const p = void 0 !== l; if (void 0 === l) { if (Xe.allowLocalModels) { if (Qe(c)) { if (r.local_files_only) throw new Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${c}.`); if (!Xe.allowRemoteModels) throw new Error(`\`env.allowRemoteModels=false\`, but attempted to load a remote file from: ${c}.`) } else try { l = await Je(h), a = h } catch (e) { console.warn(`Unable to load from local path "${h}": "${e}"`) } } if (void 0 === l || 404 === l.status) { if (r.local_files_only || !Xe.allowRemoteModels) { if (s) throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${h}".`); return null } if (l = await Je(d), 200 !== l.status) return function (e, t, s) { if (!s) return null; throw Error(`${Ze[e] ?? `Error (${e}) occurred while trying to load file`}: "${t}".`) }(l.status, d, s); a = _ } f = i && "undefined" != typeof Response && l instanceof Response && 200 === l.status } n(r.progress_callback, { status: "download", name: e, file: t }); const m = { status: "progress", name: e, file: t }; let g; return r.progress_callback ? p && "undefined" != typeof navigator && /firefox/i.test(navigator.userAgent) ? (g = new Uint8Array(await l.arrayBuffer()), n(r.progress_callback, { ...m, progress: 100, loaded: g.length, total: g.length })) : g = await async function (e, t) { const s = e.headers.get("Content-Length"); null === s && console.warn("Unable to determine content-length from response headers. Will expand buffer when needed."); let n = parseInt(s ?? "0"), r = new Uint8Array(n), i = 0; const o = e.body.getReader(); async function a() { const { done: e, value: s } = await o.read(); if (e) return; let l = i + s.length; if (l > n) { n = l; let e = new Uint8Array(n); e.set(r), r = e } r.set(s, i), i = l; return t({ progress: i / n * 100, loaded: i, total: n }), a() } return await a(), r }(l, (e => { n(r.progress_callback, { ...m, ...e }) })) : g = new Uint8Array(await l.arrayBuffer()), f && a && void 0 === await i.match(a) && await i.put(a, new Response(g, { headers: l.headers })).catch((e => { console.warn(`Unable to add response to browser cache: ${e}.`) })), n(r.progress_callback, { status: "done", name: e, file: t }), g } async function st(e, t, s = !0, n = {}) { let r = await tt(e, t, s, n); if (null === r) return {}; let i = new TextDecoder("utf-8").decode(r); return JSON.parse(i) } function nt(...e) { return (e = e.map(((t, s) => (s && (t = t.replace(new RegExp("^/"), "")), s !== e.length - 1 && (t = t.replace(new RegExp("/$"), "")), t)))).join("/") } function rt(e, [t, s, n], [r, i], o = "bilinear", a = !1) { const l = i / n, c = r / s, h = new e.constructor(r * i * t), d = s * n, u = r * i; for (let o = 0; o < r; ++o)for (let r = 0; r < i; ++r) { const a = o * i + r, _ = (r + .5) / l - .5, f = (o + .5) / c - .5; let p = Math.floor(_), m = Math.floor(f); const g = Math.min(p + 1, n - 1), w = Math.min(m + 1, s - 1); p = Math.max(p, 0), m = Math.max(m, 0); const y = _ - p, x = f - m, k = (1 - y) * (1 - x), b = y * (1 - x), v = (1 - y) * x, A = y * x, M = m * n, z = w * n, E = M + p, T = M + g, S = z + p, C = z + g; for (let s = 0; s < t; ++s) { const t = s * d; h[s * u + a] = k * e[t + E] + b * e[t + T] + v * e[t + S] + A * e[t + C] } } return h } function it(e, t, s) { const n = new Array(s.length), r = new Array(s.length); for (let e = s.length - 1, i = 1; e >= 0; --e)r[e] = i, n[e] = t[s[e]], i *= n[e]; const i = s.map(((e, t) => r[s.indexOf(t)])), o = new e.constructor(e.length); for (let s = 0; s < e.length; ++s) { let n = 0; for (let e = t.length - 1, r = s; e >= 0; --e)n += r % t[e] * i[e], r = Math.floor(r / t[e]); o[n] = e[s] } return [o, n] } function ot(e) { const t = _t(e)[0], s = e.map((e => Math.exp(e - t))), n = s.reduce(((e, t) => e + t), 0); return s.map((e => e / n)) } function at(e) { return ot(e).map((e => Math.log(e))) } function lt(e, t) { return e.reduce(((e, s, n) => e + s * t[n]), 0) } function ct(e, t = 0) { return e = Array.from(e).map(((e, t) => [t, e])).sort(((e, t) => t[1] - e[1])), null !== t && t > 0 && (e = e.slice(0, t)), e } function ht(e, t) { return lt(e, t) / (dt(e) * dt(t)) } function dt(e) { return Math.sqrt(e.reduce(((e, t) => e + t * t), 0)) } function ut(e) { if (0 === e.length) throw Error("Array must not be empty"); let t = e[0], s = 0; for (let n = 1; n < e.length; ++n)e[n] < t && (t = e[n], s = n); return [t, s] } function _t(e) { if (0 === e.length) throw Error("Array must not be empty"); let t = e[0], s = 0; for (let n = 1; n < e.length; ++n)e[n] > t && (t = e[n], s = n); return [Number(t), s] } function ft(e) { return e > 0 && !(e & e - 1) } class pt { constructor(e) { if (this.size = 0 | e, this.size <= 1 || !ft(this.size)) throw new Error("FFT size must be a power of two larger than 1"); this._csize = e << 1, this.table = new Float64Array(2 * this.size); for (let e = 0; e < this.table.length; e += 2) { const t = Math.PI * e / this.size; this.table[e] = Math.cos(t), this.table[e + 1] = -Math.sin(t) } let t = 0; for (let e = 1; this.size > e; e <<= 1)++t; this._width = t % 2 == 0 ? t - 1 : t, this._bitrev = new Int32Array(1 << this._width); for (let e = 0; e < this._bitrev.length; ++e) { this._bitrev[e] = 0; for (let t = 0; t < this._width; t += 2) { const s = this._width - t - 2; this._bitrev[e] |= (e >>> t & 3) << s } } } createComplexArray() { return new Float64Array(this._csize) } fromComplexArray(e, t) { const s = t || new Array(e.length >>> 1); for (let t = 0; t < e.length; t += 2)s[t >>> 1] = e[t]; return s } toComplexArray(e, t) { const s = t || this.createComplexArray(); for (let t = 0; t < s.length; t += 2)s[t] = e[t >>> 1], s[t + 1] = 0; return s } completeSpectrum(e) { const t = this._csize, s = t >>> 1; for (let n = 2; n < s; n += 2)e[t - n] = e[n], e[t - n + 1] = -e[n + 1] } transform(e, t) { if (e === t) throw new Error("Input and output buffers must be different"); this._transform4(e, t, 1) } realTransform(e, t) { if (e === t) throw new Error("Input and output buffers must be different"); this._realTransform4(e, t, 1) } inverseTransform(e, t) { if (e === t) throw new Error("Input and output buffers must be different"); this._transform4(e, t, -1); for (let t = 0; t < e.length; ++t)e[t] /= this.size } _transform4(e, t, s) { const n = this._csize; let r, i, o = 1 << this._width, a = n / o << 1; const l = this._bitrev; if (4 === a) for (r = 0, i = 0; r < n; r += a, ++i) { const s = l[i]; this._singleTransform2(t, e, r, s, o) } else for (r = 0, i = 0; r < n; r += a, ++i) { const n = l[i]; this._singleTransform4(t, e, r, n, o, s) } for (o >>= 2; o >= 2; o >>= 2) { a = n / o << 1; const t = a >>> 2; for (r = 0; r < n; r += a) { const n = r + t - 1; for (let i = r, a = 0; i < n; i += 2, a += o) { const n = i, r = n + t, o = r + t, l = o + t, c = e[n], h = e[n + 1], d = e[r], u = e[r + 1], _ = e[o], f = e[o + 1], p = e[l], m = e[l + 1], g = this.table[a], w = s * this.table[a + 1], y = d * g - u * w, x = d * w + u * g, k = this.table[2 * a], b = s * this.table[2 * a + 1], v = _ * k - f * b, A = _ * b + f * k, M = this.table[3 * a], z = s * this.table[3 * a + 1], E = p * M - m * z, T = p * z + m * M, S = c + v, C = h + A, P = c - v, F = h - A, L = y + E, I = x + T, B = s * (y - E), R = s * (x - T); e[n] = S + L, e[n + 1] = C + I, e[r] = P + R, e[r + 1] = F - B, e[o] = S - L, e[o + 1] = C - I, e[l] = P - R, e[l + 1] = F + B } } } } _singleTransform2(e, t, s, n, r) { const i = e[n], o = e[n + 1], a = e[n + r], l = e[n + r + 1]; t[s] = i + a, t[s + 1] = o + l, t[s + 2] = i - a, t[s + 3] = o - l } _singleTransform4(e, t, s, n, r, i) { const o = 2 * r, a = 3 * r, l = e[n], c = e[n + 1], h = e[n + r], d = e[n + r + 1], u = e[n + o], _ = e[n + o + 1], f = e[n + a], p = e[n + a + 1], m = l + u, g = c + _, w = l - u, y = c - _, x = h + f, k = d + p, b = i * (h - f), v = i * (d - p); t[s] = m + x, t[s + 1] = g + k, t[s + 2] = w + v, t[s + 3] = y - b, t[s + 4] = m - x, t[s + 5] = g - k, t[s + 6] = w - v, t[s + 7] = y + b } _realTransform4(e, t, s) { const n = this._csize; let r, i, o = 1 << this._width, a = n / o << 1; const l = this._bitrev; if (4 === a) for (r = 0, i = 0; r < n; r += a, ++i) { const s = l[i]; this._singleRealTransform2(t, e, r, s >>> 1, o >>> 1) } else for (r = 0, i = 0; r < n; r += a, ++i) { const n = l[i]; this._singleRealTransform4(t, e, r, n >>> 1, o >>> 1, s) } for (o >>= 2; o >= 2; o >>= 2) { a = n / o << 1; const t = a >>> 2; for (r = 0; r < n; r += a) { const n = r + t - 1; for (let i = r, a = 0; i < n; i += 2, a += o) { const n = i, r = n + t, o = r + t, l = o + t, c = e[n], h = e[n + 1], d = e[r], u = e[r + 1], _ = e[o], f = e[o + 1], p = e[l], m = e[l + 1], g = this.table[a], w = s * this.table[a + 1], y = d * g - u * w, x = d * w + u * g, k = this.table[2 * a], b = s * this.table[2 * a + 1], v = _ * k - f * b, A = _ * b + f * k, M = this.table[3 * a], z = s * this.table[3 * a + 1], E = p * M - m * z, T = p * z + m * M, S = c + v, C = h + A, P = c - v, F = h - A, L = y + E, I = x + T, B = s * (y - E), R = s * (x - T); e[n] = S + L, e[n + 1] = C + I, e[r] = P + R, e[r + 1] = F - B, e[o] = S - L, e[o + 1] = C - I, e[l] = P - R, e[l + 1] = F + B } } } } _singleRealTransform2(e, t, s, n, r) { const i = e[n], o = e[n + r]; t[s] = i + o, t[s + 1] = 0, t[s + 2] = i - o, t[s + 3] = 0 } _singleRealTransform4(e, t, s, n, r, i) { const o = 2 * r, a = 3 * r, l = e[n], c = e[n + r], h = e[n + o], d = e[n + a], u = l + h, _ = l - h, f = c + d, p = i * (c - d); t[s] = u + f, t[s + 1] = 0, t[s + 2] = _, t[s + 3] = -p, t[s + 4] = u - f, t[s + 5] = 0, t[s + 6] = _, t[s + 7] = p } } class mt { constructor(e) { const t = 2 * (e - 1), s = 2 * (2 * e - 1), n = 2 ** Math.ceil(Math.log2(s)); this.bufferSize = n, this._a = t; const r = new Float64Array(s), i = new Float64Array(n); this._chirpBuffer = new Float64Array(n), this._buffer1 = new Float64Array(n), this._buffer2 = new Float64Array(n), this._outBuffer1 = new Float64Array(n), this._outBuffer2 = new Float64Array(n); const o = -2 * Math.PI / e, a = Math.cos(o), l = Math.sin(o); for (let t = 0; t < s >> 1; ++t) { const s = (t + 1 - e) ** 2 / 2, n = Math.sqrt(a ** 2 + l ** 2) ** s, o = s * Math.atan2(l, a), c = 2 * t; r[c] = n * Math.cos(o), r[c + 1] = n * Math.sin(o), i[c] = r[c], i[c + 1] = -r[c + 1] } this._slicedChirpBuffer = r.subarray(t, s), this._f = new pt(n >> 1), this._f.transform(this._chirpBuffer, i) } _transform(e, t, s) { const n = this._buffer1, r = this._buffer2, i = this._outBuffer1, o = this._outBuffer2, a = this._chirpBuffer, l = this._slicedChirpBuffer, c = this._a; if (s) for (let e = 0; e < l.length; e += 2) { const s = e + 1, r = t[e >> 1]; n[e] = r * l[e], n[s] = r * l[s] } else for (let e = 0; e < l.length; e += 2) { const s = e + 1; n[e] = t[e] * l[e] - t[s] * l[s], n[s] = t[e] * l[s] + t[s] * l[e] } this._f.transform(i, n); for (let e = 0; e < a.length; e += 2) { const t = e + 1; r[e] = i[e] * a[e] - i[t] * a[t], r[t] = i[e] * a[t] + i[t] * a[e] } this._f.inverseTransform(o, r); for (let t = 0; t < o.length; t += 2) { const s = o[t + c], n = o[t + c + 1], r = l[t], i = l[t + 1]; e[t] = s * r - n * i, e[t + 1] = s * i + n * r } } transform(e, t) { this._transform(e, t, !1) } realTransform(e, t) { this._transform(e, t, !0) } } class gt { constructor(e) { this.fft_length = e, this.isPowerOfTwo = ft(e), this.isPowerOfTwo ? (this.fft = new pt(e), this.outputBufferSize = 2 * e) : (this.fft = new mt(e), this.outputBufferSize = this.fft.bufferSize) } realTransform(e, t) { this.fft.realTransform(e, t) } transform(e, t) { this.fft.transform(e, t) } } function wt(e, t) { if (t % 2 == 0 || t <= 0) throw new Error("Window size must be a positive odd number"); const s = new e.constructor(e.length), n = new e.constructor(t), r = Math.floor(t / 2); for (let t = 0; t < e.length; ++t) { let i = 0; for (let s = -r; s <= r; ++s) { let r = t + s; r < 0 ? r = Math.abs(r) : r >= e.length && (r = 2 * (e.length - 1) - r), n[i++] = e[r] } n.sort(), s[t] = n[r] } return s } function yt(e, t) { const s = Math.pow(10, t); return Math.round(e * s) / s } const xt = Object.freeze({ float32: Float32Array, float64: Float64Array, string: Array, int8: Int8Array, uint8: Uint8Array, int16: Int16Array, uint16: Uint16Array, int32: Int32Array, uint32: Uint32Array, int64: BigInt64Array, uint64: BigUint64Array, bool: Uint8Array }), kt = Re.Tensor; class bt { dims; type; data; size; constructor(...e) { return e[0] instanceof kt ? Object.assign(this, e[0]) : Object.assign(this, new kt(e[0], e[1], e[2])), new Proxy(this, { get: (e, t) => { if ("string" == typeof t) { let s = Number(t); if (Number.isInteger(s)) return e._getitem(s) } return e[t] }, set: (e, t, s) => e[t] = s }) } *[Symbol.iterator]() { const [e, ...t] = this.dims; if (t.length > 0) { const s = t.reduce(((e, t) => e * t)); for (let n = 0; n < e; ++n)yield this._subarray(n, s, t) } else yield* this.data } _getitem(e) { const [t, ...s] = this.dims; if (e = Tt(e, t), s.length > 0) { const t = s.reduce(((e, t) => e * t)); return this._subarray(e, t, s) } return new bt(this.type, [this.data[e]], s) } indexOf(e) { for (let t = 0; t < this.data.length; ++t)if (this.data[t] == e) return t; return -1 } _subarray(e, t, s) { const n = e * t, r = (e + 1) * t, i = "subarray" in this.data ? this.data.subarray(n, r) : this.data.slice(n, r); return new bt(this.type, i, s) } item() { if (1 !== this.data.length) throw new Error(`a Tensor with ${this.data.length} elements cannot be converted to Scalar`); return this.data[0] } tolist() { return function (e, t) { const s = e.length, n = t.reduce(((e, t) => e * t)); if (s !== n) throw Error(`cannot reshape array of size ${s} into shape (${t})`); let r = e; for (let e = t.length - 1; e >= 0; e--)r = r.reduce(((s, n) => { let r = s[s.length - 1]; return r.length < t[e] ? r.push(n) : s.push([n]), s }), [[]]); return r[0] }(this.data, this.dims) } sigmoid() { return this.clone().sigmoid_() } sigmoid_() { for (let e = 0; e < this.data.length; ++e)this.data[e] = 1 / (1 + Math.exp(-this.data[e])); return this } mul(e) { return this.clone().mul_(e) } mul_(e) { for (let t = 0; t < this.data.length; ++t)this.data[t] *= e; return this } add(e) { return this.clone().add_(e) } add_(e) { for (let t = 0; t < this.data.length; ++t)this.data[t] += e; return this } clone() { return new bt(this.type, this.data.slice(), this.dims.slice()) } slice(...e) { let t = [], s = []; for (let n = 0; n < this.dims.length; ++n) { let r = e[n]; if (null == r) s.push([0, this.dims[n]]), t.push(this.dims[n]); else if ("number" == typeof r) r = Tt(r, this.dims[n], n), s.push([r, r + 1]); else { if (!Array.isArray(r) || 2 !== r.length) throw new Error(`Invalid slice: ${r}`); { if (r[0] > r[1]) throw new Error(`Invalid slice: ${r}`); let e = [Math.max(r[0], 0), Math.min(r[1], this.dims[n])]; s.push(e), t.push(e[1] - e[0]) } } } let n = s.map((([e, t]) => t - e)), r = n.reduce(((e, t) => e * t)), i = new this.data.constructor(r); const o = this.stride(); for (let e = 0; e < r; ++e) { let t = 0; for (let r = n.length - 1, i = e; r >= 0; --r) { const e = n[r]; t += (i % e + s[r][0]) * o[r], i = Math.floor(i / e) } i[e] = this.data[t] } return new bt(this.type, i, t) } transpose(...e) { return vt(this, e) } sum(e = null, t = !1) { return this.norm(1, e, t) } norm(e = "fro", t = null, s = !1) { if ("fro" === e) e = 2; else if ("string" == typeof e) throw Error(`Unsupported norm: ${e}`); if (null === t) { let t = this.data.reduce(((t, s) => t + s ** e), 0) ** (1 / e); return new bt(this.type, [t], []) } t = Tt(t, this.dims.length); const n = this.dims.slice(); n[t] = 1; const r = new this.data.constructor(this.data.length / this.dims[t]); for (let s = 0; s < this.data.length; ++s) { let i = 0; for (let e = this.dims.length - 1, r = s, o = 1; e >= 0; --e) { const s = this.dims[e]; if (e !== t) { i += r % s * o, o *= n[e] } r = Math.floor(r / s) } r[i] += this.data[s] ** e } if (1 !== e) for (let t = 0; t < r.length; ++t)r[t] = r[t] ** (1 / e); return s || n.splice(t, 1), new bt(this.type, r, n) } normalize_(e = 2, t = 1) { t = Tt(t, this.dims.length); const s = this.norm(e, t, !0); for (let e = 0; e < this.data.length; ++e) { let n = 0; for (let s = this.dims.length - 1, r = e, i = 1; s >= 0; --s) { const e = this.dims[s]; if (s !== t) { n += r % e * i, i *= this.dims[s] } r = Math.floor(r / e) } this.data[e] /= s.data[n] } return this } normalize(e = 2, t = 1) { return this.clone().normalize_(e, t) } stride() { return function (e) { const t = new Array(e.length); for (let s = e.length - 1, n = 1; s >= 0; --s)t[s] = n, n *= e[s]; return t }(this.dims) } squeeze(e = null) { return new bt(this.type, this.data, zt(this.dims, e)) } squeeze_(e = null) { return this.dims = zt(this.dims, e), this } unsqueeze(e = null) { return new bt(this.type, this.data, Et(this.dims, e)) } unsqueeze_(e = null) { return this.dims = Et(this.dims, e), this } flatten_(e = 0, t = -1) { t = (t + this.dims.length) % this.dims.length; let s = this.dims.slice(0, e), n = this.dims.slice(e, t + 1), r = this.dims.slice(t + 1); return this.dims = [...s, n.reduce(((e, t) => e * t), 1), ...r], this } flatten(e = 0, t = -1) { return this.clone().flatten_(e, t) } view(...e) { let t = -1; for (let s = 0; s < e.length; ++s)if (-1 === e[s]) { if (-1 !== t) throw new Error("Only one dimension can be inferred"); t = s } if (-1 !== t) { const s = e.reduce(((e, s, n) => n !== t ? e * s : e), 1); e[t] = this.data.length / s } return new bt(this.type, this.data, e) } neg_() { for (let e = 0; e < this.data.length; ++e)this.data[e] = -this.data[e]; return this } neg() { return this.clone().neg_() } clamp_(e, t) { for (let s = 0; s < this.data.length; ++s)this.data[s] = Math.min(Math.max(this.data[s], e), t); return this } clamp(e, t) { return this.clone().clamp_(e, t) } round_() { for (let e = 0; e < this.data.length; ++e)this.data[e] = Math.round(this.data[e]); return this } round() { return this.clone().round_() } to(e) { if (this.type === e) return this; if (!xt.hasOwnProperty(e)) throw new Error(`Unsupported type: ${e}`); return new bt(e, xt[e].from(this.data), this.dims) } } function vt(e, t) { const [s, n] = it(e.data, e.dims, t); return new bt(e.type, s, n) } function At(e, [t, s], n = "bilinear", r = !1) { const i = e.dims.at(-3) ?? 1, o = e.dims.at(-2), a = e.dims.at(-1); let l = rt(e.data, [i, o, a], [t, s], n, r); return new bt(e.type, l, [i, t, s]) } function Mt(e, t) { let s = [e.dims[0], e.dims[2]], n = new e.data.constructor(s[0] * s[1]), [r, i, o] = e.dims, a = 0; for (let s = 0; s < r; ++s) { let r = s * o * i; for (let l = 0; l < o; ++l) { let c = 0, h = 0, d = s * i, u = r + l; for (let s = 0; s < i; ++s) { let n = Number(t.data[d + s]); h += n, c += e.data[u + s * o] * n } let _ = c / h; n[a++] = _ } } return new bt(e.type, n, s) } function zt(e, t) { return e = e.slice(), null === t ? e = e.filter((e => 1 !== e)) : "number" == typeof t ? 1 === e[t] && e.splice(t, 1) : Array.isArray(t) && (e = e.filter(((e, s) => 1 !== e || !t.includes(s)))), e } function Et(e, t) { return t = Tt(t, e.length + 1), (e = e.slice()).splice(t, 0, 1), e } function Tt(e, t, s = null) { if (e < -t || e >= t) throw new Error(`IndexError: index ${e} is out of bounds for dimension${null === s ? "" : " " + s} with size ${t}`); return e < 0 && (e = (e % t + t) % t), e } function St(e, t = 0) { t = Tt(t, e[0].dims.length); const s = e[0].dims.slice(); s[t] = e.reduce(((e, s) => e + s.dims[t]), 0); const n = s.reduce(((e, t) => e * t), 1), r = new e[0].data.constructor(n), i = e[0].type; if (0 === t) { let t = 0; for (let s of e) r.set(s.data, t), t += s.data.length } else { let n = 0; for (let i = 0; i < e.length; ++i) { let o = e[i]; for (let e = 0; e < o.data.length; ++e) { let i = 0; for (let r = o.dims.length - 1, a = e, l = 1; r >= 0; --r) { const e = o.dims[r]; let c = a % e; r === t && (c += n), i += c * l, l *= s[r], a = Math.floor(a / e) } r[i] = o.data[e] } n += o.dims[t] } } return new bt(i, r, s) } function Ct(e, t = 0) { return St(e.map((e => e.unsqueeze(t))), t) } function Pt(e, t = null, s = 1, n = !1) { if (null === t) { const t = e.data.reduce(((e, t) => e + t), 0) / e.data.length, n = Math.sqrt(e.data.reduce(((e, s) => e + (s - t) ** 2), 0) / (e.data.length - s)), r = new bt(e.type, [t], []); return [new bt(e.type, [n], []), r] } const r = Ft(e, t = Tt(t, e.dims.length), n), i = e.dims.slice(); i[t] = 1; const o = new e.data.constructor(e.data.length / e.dims[t]); for (let s = 0; s < e.data.length; ++s) { let n = 0; for (let r = e.dims.length - 1, o = s, a = 1; r >= 0; --r) { const s = e.dims[r]; if (r !== t) { n += o % s * a, a *= i[r] } o = Math.floor(o / s) } o[n] += (e.data[s] - r.data[n]) ** 2 } for (let n = 0; n < o.length; ++n)o[n] = Math.sqrt(o[n] / (e.dims[t] - s)); n || i.splice(t, 1); return [new bt(e.type, o, i), r] } function Ft(e, t = null, s = !1) { if (null === t) { let t = e.data.reduce(((e, t) => e + t), 0); return new bt(e.type, [t / e.data.length], []) } t = Tt(t, e.dims.length); const n = e.dims.slice(); n[t] = 1; const r = new e.data.constructor(e.data.length / e.dims[t]); for (let s = 0; s < e.data.length; ++s) { let i = 0; for (let r = e.dims.length - 1, o = s, a = 1; r >= 0; --r) { const s = e.dims[r]; if (r !== t) { i += o % s * a, a *= n[r] } o = Math.floor(o / s) } r[i] += e.data[s] } if (1 !== e.dims[t]) for (let s = 0; s < r.length; ++s)r[s] = r[s] / e.dims[t]; return s || n.splice(t, 1), new bt(e.type, r, n) } function Lt(e) { const [t, s] = e.dims, n = [t + 1, s + 1], r = new bt("float32", new Float32Array(n[0] * n[1]).fill(1 / 0), n), i = new bt("float32", new Float32Array(n[0] * n[1]).fill(-1), n); r[0].data[0] = 0; for (let n = 1; n < s + 1; ++n)for (let s = 1; s < t + 1; ++s) { const t = r[s - 1][n - 1].item(), o = r[s - 1][n].item(), a = r[s][n - 1].item(); let l, c; t < o && t < a ? (l = t, c = 0) : o < t && o < a ? (l = o, c = 1) : (l = a, c = 2), r[s].data[n] = e[s - 1][n - 1].item() + l, i[s].data[n] = c } let o = t, a = s; i.data.fill(2, 0, n[1]); for (let e = 0; e < n[0]; ++e)i[e].data[0] = 1; let l = [], c = []; for (; o > 0 || a > 0;) { l.push(o - 1), c.push(a - 1); switch (i[o][a].item()) { case 0: --o, --a; break; case 1: --o; break; case 2: --a; break; default: throw new Error(`Internal error in dynamic time warping. Unexpected trace[${o}, ${a}]. Please file a bug report.`) } } return l.reverse(), c.reverse(), [l, c] } function It(e) { const t = e.reduce(((e, t) => e * t), 1); return new bt("int64", new BigInt64Array(t).fill(1n), e) } function Bt(e) { return It(e.dims) } class Rt { constructor(e = (e, t) => e > t) { this._heap = [], this._comparator = e } get size() { return this._heap.length } isEmpty() { return 0 === this.size } peek() { return this._heap[0] } push(...e) { return this.extend(e) } extend(e) { for (const t of e) this._heap.push(t), this._siftUp(); return this.size } pop() { const e = this.peek(), t = this.size - 1; return t > 0 && this._swap(0, t), this._heap.pop(), this._siftDown(), e } replace(e) { const t = this.peek(); return this._heap[0] = e, this._siftDown(), t } _parent(e) { return (e + 1 >>> 1) - 1 } _left(e) { return 1 + (e << 1) } _right(e) { return e + 1 << 1 } _greater(e, t) { return this._comparator(this._heap[e], this._heap[t]) } _swap(e, t) { const s = this._heap[e]; this._heap[e] = this._heap[t], this._heap[t] = s } _siftUp() { let e = this.size - 1; for (; e > 0 && this._greater(e, this._parent(e));)this._swap(e, this._parent(e)), e = this._parent(e) } _siftDown() { let e = 0; for (; this._left(e) < this.size && this._greater(this._left(e), e) || this._right(e) < this.size && this._greater(this._right(e), e);) { const t = this._right(e) < this.size && this._greater(this._right(e), this._left(e)) ? this._right(e) : this._left(e); this._swap(e, t), e = t } } } class Ot { constructor() { this.root = Nt.default() } extend(e) { for (let t of e) this.push(t) } push(e) { let t = this.root; for (let s of e) { let e = t.children.get(s); void 0 === e && (e = Nt.default(), t.children.set(s, e)), t = e } t.isLeaf = !0 } *commonPrefixSearch(e) { let t = this.root, s = ""; for (let n = 0; n < e.length && void 0 !== t; ++n) { const r = e[n]; s += r, t = t.children.get(r), void 0 !== t && t.isLeaf && (yield s) } } } class Nt { constructor(e, t) { this.isLeaf = e, this.children = t } static default() { return new Nt(!1, new Map) } } class Ut { constructor(e, t, s) { this.sentence = e, this.len = e.length, this.bosTokenId = t, this.eosTokenId = s, this.nodes = [], this.beginNodes = Array.from({ length: this.len + 1 }, (() => [])), this.endNodes = Array.from({ length: this.len + 1 }, (() => [])); const n = new $t(this.bosTokenId, 0, 0, 0, 0), r = new $t(this.eosTokenId, 1, this.len, 0, 0); this.nodes.push(n.clone()), this.nodes.push(r.clone()), this.beginNodes[this.len].push(r), this.endNodes[0].push(n) } insert(e, t, s, n) { const r = this.nodes.length, i = new $t(n, r, e, t, s); this.beginNodes[e].push(i), this.endNodes[e + t].push(i), this.nodes.push(i) } viterbi() { const e = this.len; let t = 0; for (; t <= e;) { if (0 == this.beginNodes[t].length) return []; for (let e of this.beginNodes[t]) { e.prev = null; let s = 0, n = null; for (let r of this.endNodes[t]) { const t = r.backtraceScore + e.score; (null === n || t > s) && (n = r.clone(), s = t) } if (null === n) return []; e.prev = n, e.backtraceScore = s } ++t } const s = [], n = this.beginNodes[e][0].prev; if (null === n) return []; let r = n.clone(); for (; null !== r.prev;) { s.push(r.clone()); const e = r.clone(); r = e.prev.clone() } return s.reverse(), s } piece(e) { return this.sentence.slice(e.pos, e.pos + e.length) } tokens() { return this.viterbi().map((e => this.piece(e))) } tokenIds() { return this.viterbi().map((e => e.tokenId)) } } class $t { constructor(e, t, s, n, r) { this.tokenId = e, this.nodeId = t, this.pos = s, this.length = n, this.score = r, this.prev = null, this.backtraceScore = 0 } clone() { const e = new $t(this.tokenId, this.nodeId, this.pos, this.length, this.score); return e.prev = this.prev, e.backtraceScore = this.backtraceScore, e } } async function Dt(e, t) { const s = await Promise.all([st(e, "tokenizer.json", !0, t), st(e, "tokenizer_config.json", !0, t)]); return null !== t.legacy && (s[1].legacy = t.legacy), s } function jt(e, t = !0) { if (void 0 !== e.Regex) { const t = e.Regex.replace(/\\([#&~])/g, "$1"); return new RegExp(t, "gu") } if (void 0 !== e.String) { const s = r(e.String); return new RegExp(t ? s : `(${s})`, "gu") } return console.warn("Unknown pattern type:", e), null } function qt(e) { return new Map(Object.entries(e)) } function Gt(e) { const t = e.dims; switch (t.length) { case 1: return e.tolist(); case 2: if (1 !== t[0]) throw new Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs."); return e.tolist()[0]; default: throw new Error(`Expected tensor to have 1-2 dimensions, got ${t.length}.`) } } function Wt(e) { return e.replace(/ \./g, ".").replace(/ \?/g, "?").replace(/ \!/g, "!").replace(/ ,/g, ",").replace(/ \' /g, "'").replace(/ n\'t/g, "n't").replace(/ \'m/g, "'m").replace(/ \'s/g, "'s").replace(/ \'ve/g, "'ve").replace(/ \'re/g, "'re") } function Yt(e) { return e.replace(/[\u0300-\u036f]/g, "") } const Vt = "\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E"; class Xt { constructor(e) { this.content = e.content, this.id = e.id, this.single_word = e.single_word ?? !1, this.lstrip = e.lstrip ?? !1, this.rstrip = e.rstrip ?? !1, this.special = e.special ?? !1, this.normalized = e.normalized ?? null } } class Kt extends i { constructor(e) { super(), this.config = e, this.vocab = [], this.tokens_to_ids = new Map, this.unk_token_id = void 0, this.unk_token = void 0, this.end_of_word_suffix = void 0, this.fuse_unk = this.config.fuse_unk ?? !1 } static fromConfig(e, ...t) { switch (e.type) { case "WordPiece": return new Ht(e); case "Unigram": return new Qt(e, ...t); case "BPE": return new ts(e); default: if (e.vocab) return new ss(e, ...t); throw new Error(`Unknown TokenizerModel type: ${e.type}`) } } _call(e) { let t = this.encode(e); return this.fuse_unk && (t = function (e, t, s) { const n = []; let r = 0; for (; r < e.length;)if (n.push(e[r]), (s.get(e[r]) ?? t) === t) for (; r < e.length && (s.get(e[r]) ?? t) === t;)++r; else ++r; return n }(t, this.unk_token_id, this.tokens_to_ids)), t } encode(e) { throw Error("encode should be implemented in subclass.") } convert_tokens_to_ids(e) { return e.map((e => this.tokens_to_ids.get(e) ?? this.unk_token_id)) } convert_ids_to_tokens(e) { return e.map((e => this.vocab[e] ?? this.unk_token)) } } class Ht extends Kt { constructor(e) { super(e), this.tokens_to_ids = qt(e.vocab), this.unk_token_id = this.tokens_to_ids.get(e.unk_token), this.unk_token = e.unk_token, this.max_input_chars_per_word = e.max_input_chars_per_word ?? 100, this.vocab = new Array(this.tokens_to_ids.size); for (const [e, t] of this.tokens_to_ids) this.vocab[t] = e } encode(e) { const t = []; for (const s of e) { const e = [...s]; if (e.length > this.max_input_chars_per_word) { t.push(this.unk_token); continue } let n = !1, r = 0; const i = []; for (; r < e.length;) { let t = e.length, s = null; for (; r < t;) { let n = e.slice(r, t).join(""); if (r > 0 && (n = this.config.continuing_subword_prefix + n), this.tokens_to_ids.has(n)) { s = n; break } --t } if (null === s) { n = !0; break } i.push(s), r = t } n ? t.push(this.unk_token) : t.push(...i) } return t } } class Qt extends Kt { constructor(e, t) { super(e); const s = e.vocab.length; this.vocab = new Array(s), this.scores = new Array(s); for (let t = 0; t < s; ++t) { const s = e.vocab[t]; this.vocab[t] = s[0], this.scores[t] = s[1] } this.unk_token_id = e.unk_id, this.unk_token = this.vocab[e.unk_id], this.tokens_to_ids = new Map(this.vocab.map(((e, t) => [e, t]))), this.bosToken = " ", this.bosTokenId = this.tokens_to_ids.get(this.bosToken), this.eosToken = t.eos_token, this.eosTokenId = this.tokens_to_ids.get(this.eosToken), this.unkToken = this.vocab[this.unk_token_id], this.minScore = ut(this.scores)[0], this.unkScore = this.minScore - 10, this.scores[this.unk_token_id] = this.unkScore, this.trie = new Ot, this.trie.extend(this.vocab), this.fuse_unk = !0 } populateNodes(e) { const t = e.sentence, s = t.length; let n = 0; for (; n < s;) { const s = 1; let r = !1; for (let i of this.trie.commonPrefixSearch(t.slice(n))) { const t = this.tokens_to_ids.get(i), o = this.scores[t], a = i.length; e.insert(n, a, o, t), r || a !== s || (r = !0) } r || e.insert(n, s, this.unkScore, this.unk_token_id), n += s } } tokenize(e) { const t = new Ut(e, this.bosTokenId, this.eosTokenId); return this.populateNodes(t), t.tokens() } encode(e) { const t = []; for (const s of e) { const e = this.tokenize(s); t.push(...e) } return t } } const Jt = (() => { const e = [...Array.from({ length: "~".charCodeAt(0) - "!".charCodeAt(0) + 1 }, ((e, t) => t + "!".charCodeAt(0))), ...Array.from({ length: "".charCodeAt(0) - "".charCodeAt(0) + 1 }, ((e, t) => t + "".charCodeAt(0))), ...Array.from({ length: "".charCodeAt(0) - "".charCodeAt(0) + 1 }, ((e, t) => t + "".charCodeAt(0)))], t = e.slice(); let s = 0; for (let n = 0; n < 256; ++n)e.includes(n) || (e.push(n), t.push(256 + s), s += 1); const n = t.map((e => String.fromCharCode(e))); return Object.fromEntries(e.map(((e, t) => [e, n[t]]))) })(), Zt = (es = Jt, Object.fromEntries(Object.entries(es).map((([e, t]) => [t, e])))); var es; class ts extends Kt { constructor(e) { super(e), this.BPE_SPLIT_TOKEN = " ", this.tokens_to_ids = qt(e.vocab), this.unk_token_id = this.tokens_to_ids.get(e.unk_token), this.unk_token = e.unk_token, this.vocab = new Array(this.tokens_to_ids.size); for (const [e, t] of this.tokens_to_ids) this.vocab[t] = e; this.bpe_ranks = new Map(e.merges.map(((e, t) => [e, t]))), this.merges = e.merges.map((e => e.split(this.BPE_SPLIT_TOKEN))), this.end_of_word_suffix = e.end_of_word_suffix, this.continuing_subword_suffix = e.continuing_subword_suffix ?? null, this.byte_fallback = this.config.byte_fallback ?? !1, this.byte_fallback && (this.text_encoder = new TextEncoder), this.cache = new Map } bpe(e) { if (0 === e.length) return []; const t = this.cache.get(e); if (void 0 !== t) return t; const s = Array.from(e); this.end_of_word_suffix && (s[s.length - 1] += this.end_of_word_suffix); let n = []; if (s.length > 1) { const e = new Rt(((e, t) => e.score < t.score)); let t = { token: s[0], bias: 0, prev: null, next: null }, r = t; for (let t = 1; t < s.length; ++t) { const n = { bias: t / s.length, token: s[t], prev: r, next: null }; r.next = n, this._add_node(e, r), r = n } for (; !e.isEmpty();) { const s = e.pop(); if (s.deleted || !s.next || s.next.deleted) continue; if (s.deleted = !0, s.next.deleted = !0, s.prev) { const e = { ...s.prev }; s.prev.deleted = !0, s.prev = e, e.prev ? e.prev.next = e : t = e } const n = { token: s.token + s.next.token, bias: s.bias, prev: s.prev, next: s.next.next }; n.prev ? (n.prev.next = n, this._add_node(e, n.prev)) : t = n, n.next && (n.next.prev = n, this._add_node(e, n)) } for (let e = t; null !== e; e = e.next)n.push(e.token) } else n = s; if (this.continuing_subword_suffix) for (let e = 0; e < n.length - 1; ++e)n[e] += this.continuing_subword_suffix; return this.cache.set(e, n), n } _add_node(e, t) { const s = this.bpe_ranks.get(t.token + this.BPE_SPLIT_TOKEN + t.next.token); void 0 !== s && (t.score = s + t.bias, e.push(t)) } encode(e) { const t = []; for (const s of e) { const e = this.bpe(s); for (const s of e) this.tokens_to_ids.has(s) ? t.push(s) : this.byte_fallback ? t.push(...Array.from(this.text_encoder.encode(s)).map((e => `<0x${e.toString(16).toUpperCase().padStart(2, "0")}>`))) : t.push(this.unk_token) } return t } } class ss extends Kt { constructor(e, t) { super(e), this.tokens_to_ids = qt(t.target_lang ? e.vocab[t.target_lang] : e.vocab), this.bos_token = t.bos_token, this.bos_token_id = this.tokens_to_ids.get(this.bos_token), this.eos_token = t.eos_token, this.eos_token_id = this.tokens_to_ids.get(this.eos_token), this.pad_token = t.pad_token, this.pad_token_id = this.tokens_to_ids.get(this.pad_token), this.unk_token = t.unk_token, this.unk_token_id = this.tokens_to_ids.get(this.unk_token), this.vocab = new Array(this.tokens_to_ids.size); for (const [e, t] of this.tokens_to_ids) this.vocab[t] = e } encode(e) { return e } } class ns extends i { constructor(e) { super(), this.config = e } static fromConfig(e) { if (null === e) return null; switch (e.type) { case "BertNormalizer": return new _s(e); case "Precompiled": return new Ns(e); case "Sequence": return new us(e); case "Replace": return new rs(e); case "NFC": return new is(e); case "NFKC": return new os(e); case "NFKD": return new as(e); case "Strip": return new ls(e); case "StripAccents": return new cs(e); case "Lowercase": return new hs(e); case "Prepend": return new ds(e); default: throw new Error(`Unknown Normalizer type: ${e.type}`) } } normalize(e) { throw Error("normalize should be implemented in subclass.") } _call(e) { return this.normalize(e) } } class rs extends ns { normalize(e) { const t = jt(this.config.pattern); return null === t ? e : e.replaceAll(t, this.config.content) } } class is extends ns { normalize(e) { return e = e.normalize("NFC") } } class os extends ns { normalize(e) { return e = e.normalize("NFKC") } } class as extends ns { normalize(e) { return e = e.normalize("NFKD") } } class ls extends ns { normalize(e) { return this.config.strip_left && this.config.strip_right ? e = e.trim() : (this.config.strip_left && (e = e.trimStart()), this.config.strip_right && (e = e.trimEnd())), e } } class cs extends ns { normalize(e) { return e = Yt(e) } } class hs extends ns { normalize(e) { return e = e.toLowerCase() } } class ds extends ns { normalize(e) { return e = this.config.prepend + e } } class us extends ns { constructor(e) { super(e), this.normalizers = e.normalizers.map((e => ns.fromConfig(e))) } normalize(e) { return this.normalizers.reduce(((e, t) => t.normalize(e)), e) } } class _s extends ns { _tokenize_chinese_chars(e) { const t = []; for (let s = 0; s < e.length; ++s) { const n = e[s], r = n.charCodeAt(0); this._is_chinese_char(r) ? (t.push(" "), t.push(n), t.push(" ")) : t.push(n) } return t.join("") } _is_chinese_char(e) { return e >= 19968 && e <= 40959 || e >= 13312 && e <= 19903 || e >= 131072 && e <= 173791 || e >= 173824 && e <= 177983 || e >= 177984 && e <= 178207 || e >= 178208 && e <= 183983 || e >= 63744 && e <= 64255 || e >= 194560 && e <= 195103 } stripAccents(e) { return e.normalize("NFD").replace(/[\u0300-\u036f]/g, "") } _is_control(e) { switch (e) { case "\t": case "\n": case "\r": return !1; default: return /^\p{Cc}|\p{Cf}|\p{Co}|\p{Cs}$/u.test(e) } } _clean_text(e) { const t = []; for (const s of e) { const e = s.charCodeAt(0); 0 === e || 65533 === e || this._is_control(s) || (/^\s$/.test(s) ? t.push(" ") : t.push(s)) } return t.join("") } normalize(e) { return this.config.clean_text && (e = this._clean_text(e)), this.config.handle_chinese_chars && (e = this._tokenize_chinese_chars(e)), this.config.lowercase ? (e = e.toLowerCase(), !1 !== this.config.strip_accents && (e = this.stripAccents(e))) : this.config.strip_accents && (e = this.stripAccents(e)), e } } class fs extends i { static fromConfig(e) { if (null === e) return null; switch (e.type) { case "BertPreTokenizer": return new ps(e); case "Sequence": return new Us(e); case "WhitespaceSplit": return new $s(e); case "Metaspace": return new Rs(e); case "ByteLevel": return new ms(e); case "Split": return new gs(e); case "Punctuation": return new ws(e); case "Digits": return new ys(e); case "Replace": return new Ds(e); default: throw new Error(`Unknown PreTokenizer type: ${e.type}`) } } pre_tokenize_text(e, t) { throw Error("pre_tokenize_text should be implemented in subclass.") } pre_tokenize(e, t) { return (Array.isArray(e) ? e.map((e => this.pre_tokenize_text(e, t))) : this.pre_tokenize_text(e, t)).flat() } _call(e, t) { return this.pre_tokenize(e, t) } } class ps extends fs { constructor(e) { super(), this.pattern = new RegExp(`[^\\s${Vt}]+|[${Vt}]`, "gu") } pre_tokenize_text(e, t) { return e.trim().match(this.pattern) || [] } } class ms extends fs { constructor(e) { super(), this.config = e, this.add_prefix_space = this.config.add_prefix_space, this.trim_offsets = this.config.trim_offsets, this.use_regex = this.config.use_regex ?? !0, this.pattern = /'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+/gu, this.byte_encoder = Jt, this.text_encoder = new TextEncoder } pre_tokenize_text(e, t) { this.add_prefix_space && !e.startsWith(" ") && (e = " " + e); return (this.use_regex ? e.match(this.pattern) || [] : [e]).map((e => Array.from(this.text_encoder.encode(e), (e => this.byte_encoder[e])).join(""))) } } class gs extends fs { constructor(e) { super(), this.config = e, this.pattern = jt(this.config.pattern, this.config.invert) } pre_tokenize_text(e, t) { return null === this.pattern ? [] : this.config.invert ? e.match(this.pattern) || [] : function (e, t) { const s = []; let n = 0; for (const r of e.matchAll(t)) { const t = r[0]; n < r.index && s.push(e.slice(n, r.index)), t.length > 0 && s.push(t), n = r.index + t.length } return n < e.length && s.push(e.slice(n)), s }(e, this.pattern) } } class ws extends fs { constructor(e) { super(), this.config = e, this.pattern = new RegExp(`[^${Vt}]+|[${Vt}]+`, "gu") } pre_tokenize_text(e, t) { return e.match(this.pattern) || [] } } class ys extends fs { constructor(e) { super(), this.config = e; const t = "[^\\d]+|\\d" + (this.config.individual_digits ? "" : "+"); this.pattern = new RegExp(t, "gu") } pre_tokenize_text(e, t) { return e.match(this.pattern) || [] } } class xs extends i { constructor(e) { super(), this.config = e } static fromConfig(e) { if (null === e) return null; switch (e.type) { case "TemplateProcessing": return new vs(e); case "ByteLevel": return new As(e); case "RobertaProcessing": return new bs(e); case "BertProcessing": return new ks(e); default: throw new Error(`Unknown PostProcessor type: ${e.type}`) } } post_process(e, ...t) { throw Error("post_process should be implemented in subclass.") } _call(e, ...t) { return this.post_process(e, ...t) } } class ks extends xs { constructor(e) { super(e), this.cls = e.cls[0], this.sep = e.sep[0] } post_process(e, t = null, { add_special_tokens: s = !0 } = {}) { s && (e = c([this.cls], e, [this.sep])); let n = new Array(e.length).fill(0); if (null !== t) { const r = s && this instanceof bs ? [this.sep] : [], i = s ? [this.sep] : []; e = c(e, r, t, i), n = c(n, new Array(t.length + r.length + i.length).fill(1)) } return { tokens: e, token_type_ids: n } } } class bs extends ks { } class vs extends xs { constructor(e) { super(e), this.single = e.single, this.pair = e.pair } post_process(e, t = null, { add_special_tokens: s = !0 } = {}) { const n = null === t ? this.single : this.pair; let r = [], i = []; for (const o of n) "SpecialToken" in o ? s && (r.push(o.SpecialToken.id), i.push(o.SpecialToken.type_id)) : "Sequence" in o && ("A" === o.Sequence.id ? (r = c(r, e), i = c(i, new Array(e.length).fill(o.Sequence.type_id))) : "B" === o.Sequence.id && (r = c(r, t), i = c(i, new Array(t.length).fill(o.Sequence.type_id)))); return { tokens: r, token_type_ids: i } } } class As extends xs { post_process(e, t = null) { return t && (e = c(e, t)), { tokens: e } } } class Ms extends i { constructor(e) { super(), this.config = e, this.added_tokens = [], this.end_of_word_suffix = null, this.trim_offsets = e.trim_offsets } static fromConfig(e) { if (null === e) return null; switch (e.type) { case "WordPiece": return new Cs(e); case "Metaspace": return new Os(e); case "ByteLevel": return new Ps(e); case "Replace": return new zs(e); case "ByteFallback": return new Es(e); case "Fuse": return new Ts(e); case "Strip": return new Ss(e); case "Sequence": return new Ls(e); case "CTC": return new Fs(e); case "BPEDecoder": return new Is(e); default: throw new Error(`Unknown Decoder type: ${e.type}`) } } _call(e) { return this.decode(e) } decode(e) { return this.decode_chain(e).join("") } decode_chain(e) { throw Error("`decode_chain` should be implemented in subclass.") } } class zs extends Ms { decode_chain(e) { const t = jt(this.config.pattern); return null === t ? e : e.map((e => e.replaceAll(t, this.config.content))) } } class Es extends Ms { constructor(e) { super(e), this.text_decoder = new TextDecoder } decode_chain(e) { const t = []; let s = []; for (const n of e) { let e = null; if (6 === n.length && n.startsWith("<0x") && n.endsWith(">")) { const t = parseInt(n.slice(3, 5), 16); isNaN(t) || (e = t) } if (null !== e) s.push(e); else { if (s.length > 0) { const e = this.text_decoder.decode(Uint8Array.from(s)); t.push(e), s = [] } t.push(n) } } if (s.length > 0) { const e = this.text_decoder.decode(Uint8Array.from(s)); t.push(e), s = [] } return t } } class Ts extends Ms { decode_chain(e) { return [e.join("")] } } class Ss extends Ms { constructor(e) { super(e), this.content = this.config.content, this.start = this.config.start, this.stop = this.config.stop } decode_chain(e) { return e.map((e => { let t = 0; for (let s = 0; s < this.start && e[s] === this.content; ++s)t = s + 1; let s = e.length; for (let t = 0; t < this.stop; ++t) { const n = e.length - t - 1; if (e[n] !== this.content) break; s = n } return e.slice(t, s) })) } } class Cs extends Ms { constructor(e) { super(e), this.cleanup = e.cleanup } decode_chain(e) { return e.map(((e, t) => (0 !== t && (e = e.startsWith(this.config.prefix) ? e.replace(this.config.prefix, "") : " " + e), this.cleanup && (e = Wt(e)), e))) } } class Ps extends Ms { constructor(e) { super(e), this.byte_decoder = Zt, this.text_decoder = new TextDecoder("utf-8", { fatal: !1, ignoreBOM: !0 }), this.end_of_word_suffix = null } convert_tokens_to_string(e) { const t = e.join(""), s = new Uint8Array([...t].map((e => this.byte_decoder[e]))); return this.text_decoder.decode(s) } decode_chain(e) { const t = []; let s = []; for (const n of e) void 0 !== this.added_tokens.find((e => e.content === n)) ? (s.length > 0 && (t.push(this.convert_tokens_to_string(s)), s = []), t.push(n)) : s.push(n); return s.length > 0 && t.push(this.convert_tokens_to_string(s)), t } } class Fs extends Ms { constructor(e) { super(e), this.pad_token = this.config.pad_token, this.word_delimiter_token = this.config.word_delimiter_token, this.cleanup = this.config.cleanup } convert_tokens_to_string(e) { if (0 === e.length) return ""; const t = [e[0]]; for (let s = 1; s < e.length; ++s)e[s] !== t.at(-1) && t.push(e[s]); let s = t.filter((e => e !== this.pad_token)).join(""); return this.cleanup && (s = Wt(s).replaceAll(this.word_delimiter_token, " ").trim()), s } decode_chain(e) { return [this.convert_tokens_to_string(e)] } } class Ls extends Ms { constructor(e) { super(e), this.decoders = e.decoders.map((e => Ms.fromConfig(e))) } decode_chain(e) { return this.decoders.reduce(((e, t) => t.decode_chain(e)), e) } } class Is extends Ms { constructor(e) { super(e), this.suffix = this.config.suffix } decode_chain(e) { return e.map(((t, s) => t.replaceAll(this.suffix, s === e.length - 1 ? "" : " "))) } } class Bs extends Ms { decode_chain(e) { let t = ""; for (let s = 1; s < e.length; s += 2)t += e[s]; return [t] } } class Rs extends fs { constructor(e) { super(), this.addPrefixSpace = e.add_prefix_space, this.replacement = e.replacement, this.strRep = e.str_rep || this.replacement, this.prepend_scheme = e.prepend_scheme ?? "always" } pre_tokenize_text(e, { section_index: t } = {}) { let s = e.replaceAll(" ", this.strRep); return this.addPrefixSpace && !s.startsWith(this.replacement) && ("always" === this.prepend_scheme || "first" === this.prepend_scheme && 0 === t) && (s = this.strRep + s), [s] } } class Os extends Ms { constructor(e) { super(e), this.addPrefixSpace = e.add_prefix_space, this.replacement = e.replacement } decode_chain(e) { const t = []; for (let s = 0; s < e.length; ++s) { let n = e[s].replaceAll(this.replacement, " "); this.addPrefixSpace && 0 == s && n.startsWith(" ") && (n = n.substring(1)), t.push(n) } return t } } class Ns extends ns { constructor(e) { super(e), this.charsmap = e.precompiled_charsmap } normalize(e) { if ((e = (e = e.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm, "")).replace(/[\u0009\u000A\u000C\u000D\u1680\u200B\u200C\u200E\u200F\u2028\u2029\u2581\uFEFF\uFFFD]/gm, " ")).includes("")) { const t = e.split(""); e = t.map((e => e.normalize("NFKC"))).join("") } else e = e.normalize("NFKC"); return e } } class Us extends fs { constructor(e) { super(), this.tokenizers = e.pretokenizers.map((e => fs.fromConfig(e))) } pre_tokenize_text(e, t) { return this.tokenizers.reduce(((e, s) => s.pre_tokenize(e, t)), [e]) } } class $s extends fs { constructor(e) { super() } pre_tokenize_text(e, t) { return function (e) { return e.match(/\S+/g) || [] }(e) } } class Ds extends fs { constructor(e) { super(), this.config = e, this.pattern = jt(this.config.pattern), this.content = this.config.content } pre_tokenize_text(e, t) { return null === this.pattern ? [e] : [e.replaceAll(this.pattern, this.config.content)] } } const js = ["bos_token", "eos_token", "unk_token", "sep_token", "pad_token", "cls_token", "mask_token"]; function qs(e, t, s, n) { for (const r of Object.keys(e)) { const i = t - e[r].length, o = s(r), a = new Array(i).fill(o); e[r] = "right" === n ? c(e[r], a) : c(a, e[r]) } } function Gs(e, t) { for (const s of Object.keys(e)) e[s].length = t } class Ws extends i { return_token_type_ids = !1; _default_chat_template = "{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"; constructor(e, t) { super(), this._tokenizer_config = t, this.normalizer = ns.fromConfig(e.normalizer), this.pre_tokenizer = fs.fromConfig(e.pre_tokenizer), this.model = Kt.fromConfig(e.model, t), this.post_processor = xs.fromConfig(e.post_processor), this.decoder = Ms.fromConfig(e.decoder), this.special_tokens = [], this.all_special_ids = [], this.added_tokens = []; for (const t of e.added_tokens) { const e = new Xt(t); this.added_tokens.push(e), this.model.tokens_to_ids.set(e.content, e.id), this.model.vocab[e.id] = e.content, e.special && (this.special_tokens.push(e.content), this.all_special_ids.push(e.id)) } this.additional_special_tokens = t.additional_special_tokens ?? [], this.special_tokens.push(...this.additional_special_tokens), this.special_tokens = [...new Set(this.special_tokens)], this.decoder && (this.decoder.added_tokens = this.added_tokens, this.decoder.end_of_word_suffix = this.model.end_of_word_suffix), this.added_tokens_regex = this.added_tokens.length > 0 ? new RegExp(this.added_tokens.map((e => `${e.lstrip ? "\\s*" : ""}(${r(e.content)})${e.rstrip ? "\\s*" : ""}`)).join("|")) : null, this.mask_token = this.getToken("mask_token"), this.mask_token_id = this.model.tokens_to_ids.get(this.mask_token), this.pad_token = this.getToken("pad_token", "eos_token"), this.pad_token_id = this.model.tokens_to_ids.get(this.pad_token), this.sep_token = this.getToken("sep_token"), this.sep_token_id = this.model.tokens_to_ids.get(this.sep_token), this.unk_token = this.getToken(t, "unk_token"), this.unk_token_id = this.model.tokens_to_ids.get(this.unk_token), this.model_max_length = t.model_max_length, this.remove_space = t.remove_space, this.clean_up_tokenization_spaces = t.clean_up_tokenization_spaces ?? !0, this.do_lowercase_and_remove_accent = t.do_lowercase_and_remove_accent ?? !1, this.padding_side = "right", this.legacy = !1, this.chat_template = t.chat_template ?? null, this._compiled_template_cache = new Map } getToken(...e) { for (const t of e) { const e = this._tokenizer_config[t]; if (e) { if ("object" == typeof e) { if ("AddedToken" === e.__type) return e.content; throw Error(`Unknown token: ${e}`) } return e } } return null } static async from_pretrained(e, { progress_callback: t = null, config: s = null, cache_dir: n = null, local_files_only: r = !1, revision: i = "main", legacy: o = null } = {}) { return new this(...await Dt(e, { progress_callback: t, config: s, cache_dir: n, local_files_only: r, revision: i, legacy: o })) } _call(e, { text_pair: t = null, add_special_tokens: s = !0, padding: n = !1, truncation: r = null, max_length: i = null, return_tensor: o = !0 } = {}) { const a = Array.isArray(e); let l; if (a) { if (0 === e.length) throw Error("text array must be non-empty"); if (null !== t) { if (!Array.isArray(t)) throw Error("text_pair must also be an array"); if (e.length !== t.length) throw Error("text and text_pair must have the same length"); l = e.map(((e, n) => this._encode_plus(e, t[n], { add_special_tokens: s }))) } else l = e.map((e => this._encode_plus(e, null, { add_special_tokens: s }))) } else { if (null === e) throw Error("text may not be null"); if (Array.isArray(t)) throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array)."); l = [this._encode_plus(e, t, { add_special_tokens: s })] } if (null === i ? i = "max_length" === n ? this.model_max_length : _t(l.map((e => e.input_ids.length)))[0] : r || console.warn("Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=true` to explicitly truncate examples to max length."), i = Math.min(i, this.model_max_length), n || r) for (let e = 0; e < l.length; ++e)l[e].input_ids.length !== i && (l[e].input_ids.length > i ? r && Gs(l[e], i) : n && qs(l[e], i, (e => "input_ids" === e ? this.pad_token_id : 0), this.padding_side)); const c = {}; if (o) { if ((!n || !r) && l.some((e => { for (const t of Object.keys(e)) if (e[t].length !== l[0][t]?.length) return !0; return !1 }))) throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length."); const e = [l.length, l[0].input_ids.length]; for (const t of Object.keys(l[0])) c[t] = new bt("int64", BigInt64Array.from(l.flatMap((e => e[t])).map(BigInt)), e) } else { for (const e of Object.keys(l[0])) c[e] = l.map((t => t[e])); if (!a) for (const e of Object.keys(c)) c[e] = c[e][0] } return c } _encode_text(e) { if (null === e) return null; const t = (this.added_tokens_regex ? e.split(this.added_tokens_regex).filter((e => e)) : [e]).map(((e, t) => { if (void 0 !== this.added_tokens.find((t => t.content === e))) return e; { !0 === this.remove_space && (e = e.trim().split(/\s+/).join(" ")), this.do_lowercase_and_remove_accent && (e = function (e) { return Yt(e.toLowerCase()) }(e)), null !== this.normalizer && (e = this.normalizer(e)); const s = null !== this.pre_tokenizer ? this.pre_tokenizer(e, { section_index: t }) : [e]; return this.model(s) } })).flat(); return t } _encode_plus(e, t = null, { add_special_tokens: s = !0 } = {}) { const n = this._encode_text(e), r = this._encode_text(t), i = this.post_processor ? this.post_processor(n, r, { add_special_tokens: s }) : { tokens: c(n ?? [], r ?? []) }, o = this.model.convert_tokens_to_ids(i.tokens), a = { input_ids: o, attention_mask: new Array(o.length).fill(1) }; return this.return_token_type_ids && i.token_type_ids && (a.token_type_ids = i.token_type_ids), a } encode(e, t = null, { add_special_tokens: s = !0 } = {}) { const { input_ids: n } = this._encode_plus(e, t, { add_special_tokens: s }); return n } batch_decode(e, t = {}) { return e instanceof bt && (e = e.tolist()), e.map((e => this.decode(e, t))) } decode(e, t = {}) { if (e instanceof bt && (e = Gt(e)), !Array.isArray(e) || 0 === e.length || !o(e[0])) throw Error("token_ids must be a non-empty array of integers."); return this.decode_single(e, t) } decode_single(e, { skip_special_tokens: t = !1, clean_up_tokenization_spaces: s = null }) { let n = this.model.convert_ids_to_tokens(e); t && (n = n.filter((e => !this.special_tokens.includes(e)))); let r = this.decoder ? this.decoder(n) : n.join(" "); return this.decoder && this.decoder.end_of_word_suffix && (r = r.replaceAll(this.decoder.end_of_word_suffix, " "), t && (r = r.trim())), (s ?? this.clean_up_tokenization_spaces) && (r = Wt(r)), r } get default_chat_template() { return this._warned_about_chat_template || (console.warn("No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information."), this._warned_about_chat_template = !0), this._default_chat_template } apply_chat_template(e, { chat_template: s = null, add_generation_prompt: n = !1, tokenize: r = !0, padding: i = !1, truncation: o = !1, max_length: a = null, return_tensor: l = !0 } = {}) { s ??= this.chat_template ?? this.default_chat_template; let c = this._compiled_template_cache.get(s); void 0 === c && (c = new t(s), this._compiled_template_cache.set(s, c)); const h = Object.create(null); for (const e of js) { const t = this.getToken(e); t && (h[e] = t) } const d = c.render({ messages: e, add_generation_prompt: n, ...h }); return r ? this._call(d, { add_special_tokens: !1, padding: i, truncation: o, max_length: a, return_tensor: l }).input_ids : d } } class Ys extends Ws { return_token_type_ids = !0 } class Vs extends Ws { return_token_type_ids = !0 } class Xs extends Ws { return_token_type_ids = !0 } class Ks extends Ws { return_token_type_ids = !0 } class Hs extends Ws { return_token_type_ids = !0 } class Qs extends Ws { return_token_type_ids = !0 } class Js extends Ws { return_token_type_ids = !0 } class Zs extends Ws { return_token_type_ids = !0 } class en extends Ws { return_token_type_ids = !0 } class tn extends Ws { } class sn extends Ws { } class nn extends Ws { return_token_type_ids = !0; constructor(e, t) { super(e, t), console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.') } } class rn extends Ws { return_token_type_ids = !0 } class on extends Ws { } class an extends Ws { _default_chat_template = '{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}' } class ln extends Ws { } class cn extends Ws { constructor(e, t) { super(e, t), this.languageRegex = /^[a-z]{2}_[A-Z]{2}$/, this.language_codes = this.special_tokens.filter((e => this.languageRegex.test(e))), this.lang_to_token = e => e } _build_translation_inputs(e, t, s) { return kn(this, e, t, s) } } class hn extends cn { } class dn extends Ws { } class un extends an { constructor(e, t) { const s = ".,!?", n = e.pre_tokenizer?.pretokenizers[0]?.pattern; n && n.Regex === ` ?[^(\\s|[${s}])]+` && (n.Regex = ` ?[^\\s${s}]+`), super(e, t) } } const _n = ""; class fn extends Ws { _default_chat_template = "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif USE_DEFAULT_PROMPT == true and not '<<SYS>>' in messages[0]['content'] %}{% set loop_messages = messages %}{% set system_message = 'DEFAULT_SYSTEM_MESSAGE' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\n' + content.strip() + '\n<</SYS>>\n\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}"; DEFAULT_SYSTEM_PROMPT = "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."; constructor(e, t) { super(e, t), this.use_default_system_prompt = t.use_default_system_prompt ?? !1, this.legacy = t.legacy ?? !0, this.legacy || (this.normalizer = null, this.pre_tokenizer = new Rs({ replacement: _n, add_prefix_space: !0, prepend_scheme: "first" })) } _encode_text(e) { if (null === e) return null; if (this.legacy || 0 === e.length) return super._encode_text(e); let t = super._encode_text(_n + e.replaceAll(_n, " ")); return t.length > 1 && t[0] === _n && this.special_tokens.includes(t[1]) && (t = t.slice(1)), t } get default_chat_template() { return super.default_chat_template.replaceAll("USE_DEFAULT_PROMPT", this.use_default_system_prompt ? "true" : "false").replaceAll("DEFAULT_SYSTEM_MESSAGE", this.DEFAULT_SYSTEM_PROMPT.replaceAll("\n", "\\n").replaceAll("'", "\\'")) } } class pn extends fn { } class mn extends Ws { } class gn extends Ws { } class wn extends Ws { } class yn extends Ws { } class xn extends Ws { } function kn(e, t, s, n) { if (!("language_codes" in e) || !Array.isArray(e.language_codes)) throw new Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids."); if (!("languageRegex" in e && e.languageRegex instanceof RegExp)) throw new Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression."); if (!("lang_to_token" in e) || "function" != typeof e.lang_to_token) throw new Error("Tokenizer must have `lang_to_token` attribute set and it should be a function."); const r = n.src_lang, i = n.tgt_lang; if (!e.language_codes.includes(i)) throw new Error(`Target language code "${i}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`); if (void 0 !== r) { if (!e.language_codes.includes(r)) throw new Error(`Source language code "${r}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`); for (const t of e.post_processor.config.single) if ("SpecialToken" in t && e.languageRegex.test(t.SpecialToken.id)) { t.SpecialToken.id = e.lang_to_token(r); break } } return n.forced_bos_token_id = e.model.convert_tokens_to_ids([e.lang_to_token(i)])[0], e._call(t, s) } class bn extends Ws { constructor(e, t) { super(e, t), this.languageRegex = /^[a-z]{3}_[A-Z][a-z]{3}$/, this.language_codes = this.special_tokens.filter((e => this.languageRegex.test(e))), this.lang_to_token = e => e } _build_translation_inputs(e, t, s) { return kn(this, e, t, s) } } class vn extends Ws { constructor(e, t) { super(e, t), this.languageRegex = /^__[a-z]{2,3}__$/, this.language_codes = this.special_tokens.filter((e => this.languageRegex.test(e))).map((e => e.slice(2, -2))), this.lang_to_token = e => `__${e}__` } _build_translation_inputs(e, t, s) { return kn(this, e, t, s) } } const An = [["en", "english"], ["zh", "chinese"], ["de", "german"], ["es", "spanish"], ["ru", "russian"], ["ko", "korean"], ["fr", "french"], ["ja", "japanese"], ["pt", "portuguese"], ["tr", "turkish"], ["pl", "polish"], ["ca", "catalan"], ["nl", "dutch"], ["ar", "arabic"], ["sv", "swedish"], ["it", "italian"], ["id", "indonesian"], ["hi", "hindi"], ["fi", "finnish"], ["vi", "vietnamese"], ["he", "hebrew"], ["uk", "ukrainian"], ["el", "greek"], ["ms", "malay"], ["cs", "czech"], ["ro", "romanian"], ["da", "danish"], ["hu", "hungarian"], ["ta", "tamil"], ["no", "norwegian"], ["th", "thai"], ["ur", "urdu"], ["hr", "croatian"], ["bg", "bulgarian"], ["lt", "lithuanian"], ["la", "latin"], ["mi", "maori"], ["ml", "malayalam"], ["cy", "welsh"], ["sk", "slovak"], ["te", "telugu"], ["fa", "persian"], ["lv", "latvian"], ["bn", "bengali"], ["sr", "serbian"], ["az", "azerbaijani"], ["sl", "slovenian"], ["kn", "kannada"], ["et", "estonian"], ["mk", "macedonian"], ["br", "breton"], ["eu", "basque"], ["is", "icelandic"], ["hy", "armenian"], ["ne", "nepali"], ["mn", "mongolian"], ["bs", "bosnian"], ["kk", "kazakh"], ["sq", "albanian"], ["sw", "swahili"], ["gl", "galician"], ["mr", "marathi"], ["pa", "punjabi"], ["si", "sinhala"], ["km", "khmer"], ["sn", "shona"], ["yo", "yoruba"], ["so", "somali"], ["af", "afrikaans"], ["oc", "occitan"], ["ka", "georgian"], ["be", "belarusian"], ["tg", "tajik"], ["sd", "sindhi"], ["gu", "gujarati"], ["am", "amharic"], ["yi", "yiddish"], ["lo", "lao"], ["uz", "uzbek"], ["fo", "faroese"], ["ht", "haitian creole"], ["ps", "pashto"], ["tk", "turkmen"], ["nn", "nynorsk"], ["mt", "maltese"], ["sa", "sanskrit"], ["lb", "luxembourgish"], ["my", "myanmar"], ["bo", "tibetan"], ["tl", "tagalog"], ["mg", "malagasy"], ["as", "assamese"], ["tt", "tatar"], ["haw", "hawaiian"], ["ln", "lingala"], ["ha", "hausa"], ["ba", "bashkir"], ["jw", "javanese"], ["su", "sundanese"]], Mn = new Map(An), zn = new Map([...An.map((([e, t]) => [t, e])), ["burmese", "my"], ["valencian", "ca"], ["flemish", "nl"], ["haitian", "ht"], ["letzeburgesch", "lb"], ["pushto", "ps"], ["panjabi", "pa"], ["moldavian", "ro"], ["moldovan", "ro"], ["sinhalese", "si"], ["castilian", "es"]]); class En extends Ws { _default_chat_template = '{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}'; _decode_asr(e, { return_timestamps: t = !1, return_language: s = !1, time_precision: n = null, force_full_sequences: r = !0 } = {}) { if (null === n) throw Error("Must specify time_precision"); let i = null; const o = "word" === t; function a() { return { language: i, timestamp: [null, null], text: "" } } const l = []; let c = a(), h = 0; const d = this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0] + 1; let u = [], _ = [], f = !1, p = null; const m = new Set(this.all_special_ids); for (const s of e) { const e = s.tokens, r = o ? s.token_timestamps : null; let g = null, w = d; if ("stride" in s) { const [t, r, i] = s.stride; if (h -= r, p = t - i, r && (w = r / n + d), i) for (let t = e.length - 1; t >= 0; --t) { const s = e[t]; if (s >= d) { if (null !== g && (s - d) * n < p) break; g = s } } } let y = [], x = []; for (let s = 0; s < e.length; ++s) { const p = e[s]; if (m.has(p)) { const e = this.decode([p]), s = Mn.get(e.slice(2, -2)); if (void 0 !== s) { if (null !== i && s !== i && !t) { u.push(y); const e = this.findLongestCommonSequence(u)[0], t = this.decode(e); c.text = t, l.push(c), u = [], y = [], c = a() } i = c.language = s } } else if (p >= d) { const e = yt((p - d) * n + h, 2); if (null !== g && p >= g) f = !0; else if (f || u.length > 0 && p < w) f = !1; else if (null === c.timestamp[0]) c.timestamp[0] = e; else if (e === c.timestamp[0]); else { c.timestamp[1] = e, u.push(y), o && _.push(x); const [t, s] = this.findLongestCommonSequence(u, _), n = this.decode(t); c.text = n, o && (c.words = this.collateWordTimestamps(t, s, i)), l.push(c), u = [], y = [], _ = [], x = [], c = a() } } else if (y.push(p), o) { let e, t = yt(r[s] + h, 2); e = s + 1 < r.length ? yt(r[s + 1] + h, 2) : null, x.push([t, e]) } } if ("stride" in s) { const [e, t, n] = s.stride; h += e - n } y.length > 0 ? (u.push(y), o && _.push(x)) : u.every((e => 0 === e.length)) && (c = a(), u = [], y = [], _ = [], x = []) } if (u.length > 0) { if (r && t) throw new Error("Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation."); const [e, s] = this.findLongestCommonSequence(u, _), n = this.decode(e); c.text = n, o && (c.words = this.collateWordTimestamps(e, s, i)), l.push(c) } let g = Object.create(null); const w = l.map((e => e.text)).join(""); if (t || s) { for (let e = 0; e < l.length; ++e) { const n = l[e]; t || delete n.timestamp, s || delete n.language } if (o) { const e = []; for (const t of l) for (const s of t.words) e.push(s); g = { chunks: e } } else g = { chunks: l } } return [w, g] } findLongestCommonSequence(e, t = null) { let s = e[0], n = s.length, r = []; const i = Array.isArray(t) && t.length > 0; let o = i ? [] : null, a = i ? t[0] : null; for (let l = 1; l < e.length; ++l) { const c = e[l]; let h = 0, d = [n, n, 0, 0]; const u = c.length; for (let e = 1; e < n + u; ++e) { const t = e / 1e4, r = Math.max(0, n - e), i = Math.min(n, n + u - e), o = s.slice(r, i), a = Math.max(0, e - n), l = Math.min(u, e), _ = c.slice(a, l); if (o.length !== _.length) throw new Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference."); const f = o.filter(((e, t) => e === _[t])).length, p = f / e + t; f > 1 && p > h && (h = p, d = [r, i, a, l]) } const [_, f, p, m] = d, g = Math.floor((f + _) / 2), w = Math.floor((m + p) / 2); r.push(...s.slice(0, g)), s = c.slice(w), n = s.length, i && (o.push(...a.slice(0, g)), a = t[l].slice(w)) } return r.push(...s), i ? (o.push(...a), [r, o]) : [r, []] } collateWordTimestamps(e, t, s) { const [n, r, i] = this.combineTokensIntoWords(e, s), o = []; for (let e = 0; e < n.length; ++e) { const s = i[e]; o.push({ text: n[e], timestamp: [t[s.at(0)][0], t[s.at(-1)][1]] }) } return o } combineTokensIntoWords(e, t, s = "\"'([{-", n = "\"'.,!?:)]}") { let r, i, o; return ["chinese", "japanese", "thai", "lao", "myanmar"].includes(t = t ?? "english") ? [r, i, o] = this.splitTokensOnUnicode(e) : [r, i, o] = this.splitTokensOnSpaces(e), this.mergePunctuations(r, i, o, s, n) } decode(e, t) { let s; return t && t.decode_with_timestamps ? (e instanceof bt && (e = Gt(e)), s = this.decodeWithTimestamps(e, t)) : s = super.decode(e, t), s } decodeWithTimestamps(e, t) { const s = t?.time_precision ?? .02, n = Array.from(this.all_special_ids).at(-1) + 1; let r = [[]]; for (const t of e) if (t >= n) { const e = yt((t - n) * s, 2); r.push(`<|${e}|>`), r.push([]) } else r[r.length - 1].push(t); return r = r.map((e => "string" == typeof e ? e : super.decode(e, t))), r.join("") } splitTokensOnUnicode(e) { const t = this.decode(e, { decode_with_timestamps: !0 }), s = [], n = [], r = []; let i = [], o = [], a = 0; for (let l = 0; l < e.length; ++l) { const c = e[l]; i.push(c), o.push(l); const h = this.decode(i, { decode_with_timestamps: !0 }); h.includes("") && "" !== t[a + h.indexOf("")] || (s.push(h), n.push(i), r.push(o), i = [], o = [], a += h.length) } return [s, n, r] } splitTokensOnSpaces(e) { const [t, s, n] = this.splitTokensOnUnicode(e), r = [], i = [], o = [], a = new RegExp(`^[${Vt}]$`, "gu"); for (let e = 0; e < t.length; ++e) { const l = t[e], c = s[e], h = n[e], d = c[0] >= this.model.tokens_to_ids.get("<|endoftext|>"), u = l.startsWith(" "), _ = l.trim(), f = a.test(_); if (d || u || f || 0 === r.length) r.push(l), i.push(c), o.push(h); else { const e = r.length - 1; r[e] += l, i[e].push(...c), o[e].push(...h) } } return [r, i, o] } mergePunctuations(e, t, s, n, r) { const i = structuredClone(e), o = structuredClone(t), a = structuredClone(s); let l = i.length - 2, h = i.length - 1; for (; l >= 0;)i[l].startsWith(" ") && n.includes(i[l].trim()) ? (i[h] = i[l] + i[h], o[h] = c(o[l], o[h]), a[h] = c(a[l], a[h]), i[l] = "", o[l] = [], a[l] = []) : h = l, --l; for (l = 0, h = 1; h < i.length;)!i[l].endsWith(" ") && r.includes(i[h]) ? (i[l] += i[h], o[l] = c(o[l], o[h]), a[l] = c(a[l], a[h]), i[h] = "", o[h] = [], a[h] = []) : l = h, ++h; return [i.filter((e => e)), o.filter((e => e.length > 0)), a.filter((e => e.length > 0))] } get_decoder_prompt_ids({ language: e = null, task: t = null, no_timestamps: s = !0 } = {}) { const n = []; if (e) { e = e.toLowerCase(); let t = zn.get(e); if (void 0 === t) { if (!Mn.has(e)) { const t = 2 === e.length ? Mn.keys() : Mn.values(); throw new Error(`Language "${e}" is not supported. Must be one of: ${JSON.stringify(t)}`) } t = e } const s = this.model.tokens_to_ids.get(`<|${t}|>`); if (void 0 === s) throw new Error(`Unable to find language "${t}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`); n.push(s) } else n.push(null); if (t) { if ("transcribe" !== (t = t.toLowerCase()) && "translate" !== t) throw new Error(`Task "${t}" is not supported. Must be one of: ["transcribe", "translate"]`); const e = this.model.tokens_to_ids.get(`<|${t}|>`); if (void 0 === e) throw new Error(`Unable to find task "${t}" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`); n.push(e) } else n.push(null); if (s) { const e = this.model.tokens_to_ids.get("<|notimestamps|>"); if (void 0 === e) throw new Error('Unable to find "<|notimestamps|>" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.'); n.push(e) } return n.map(((e, t) => [t + 1, e])).filter((e => null !== e[1])) } } class Tn extends Ws { } class Sn extends Ws { } class Cn extends Ws { } class Pn extends Ws { constructor(e, t) { super(e, t), this.languageRegex = /^(>>\w+<<)\s*/g, this.supported_language_codes = this.model.vocab.filter((e => this.languageRegex.test(e))), console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.') } _encode_text(e) { if (null === e) return null; const [t, ...s] = e.trim().split(this.languageRegex); if (0 === s.length) return super._encode_text(t); if (2 === s.length) { const [e, t] = s; return this.supported_language_codes.includes(e) || console.warn(`Unsupported language code "${e}" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`), c([e], super._encode_text(t)) } } } class Fn extends Ws { } class Ln extends Ws { _default_chat_template = "{% for message in messages %}{% if message['role'] == 'user' %}{{ ' ' }}{% endif %}{{ message['content'] }}{% if not loop.last %}{{ '  ' }}{% endif %}{% endfor %}{{ eos_token }}" } class In extends Ln { } class Bn extends Ws { } class Rn extends Ws { } class On extends Ws { constructor(e, t) { super(e, t), this.decoder = new Bs({}) } } class Nn { static TOKENIZER_CLASS_MAPPING = { T5Tokenizer: on, DistilBertTokenizer: tn, CamembertTokenizer: sn, DebertaTokenizer: Hs, DebertaV2Tokenizer: Qs, BertTokenizer: Ys, HerbertTokenizer: Js, ConvBertTokenizer: Zs, RoFormerTokenizer: en, XLMTokenizer: nn, ElectraTokenizer: rn, MobileBertTokenizer: Xs, SqueezeBertTokenizer: Ks, AlbertTokenizer: Vs, GPT2Tokenizer: an, BartTokenizer: ln, MBartTokenizer: cn, MBart50Tokenizer: hn, RobertaTokenizer: dn, WhisperTokenizer: En, CodeGenTokenizer: Tn, CLIPTokenizer: Sn, SiglipTokenizer: Cn, MarianTokenizer: Pn, BloomTokenizer: un, NllbTokenizer: bn, M2M100Tokenizer: vn, LlamaTokenizer: fn, CodeLlamaTokenizer: pn, XLMRobertaTokenizer: mn, MPNetTokenizer: gn, FalconTokenizer: wn, GPTNeoXTokenizer: yn, EsmTokenizer: xn, Wav2Vec2CTCTokenizer: Fn, BlenderbotTokenizer: Ln, BlenderbotSmallTokenizer: In, SpeechT5Tokenizer: Bn, NougatTokenizer: Rn, VitsTokenizer: On, PreTrainedTokenizer: Ws }; static async from_pretrained(e, { quantized: t = !0, progress_callback: s = null, config: n = null, cache_dir: r = null, local_files_only: i = !1, revision: o = "main", legacy: a = null } = {}) { const [l, c] = await Dt(e, { quantized: t, progress_callback: s, config: n, cache_dir: r, local_files_only: i, revision: o, legacy: a }), h = c.tokenizer_class?.replace(/Fast$/, "") ?? "PreTrainedTokenizer"; let d = this.TOKENIZER_CLASS_MAPPING[h]; return d || (console.warn(`Unknown tokenizer class "${h}", attempting to construct from base class.`), d = Ws), new d(l, c) } } class Un { constructor(e) { this.model_type = null, this.is_encoder_decoder = !1, Object.assign(this, e) } static async from_pretrained(e, { progress_callback: t = null, config: s = null, cache_dir: n = null, local_files_only: r = !1, revision: i = "main" } = {}) { let o = s ?? await async function (e, t) { return await st(e, "config.json", !0, t) }(e, { progress_callback: t, config: s, cache_dir: n, local_files_only: r, revision: i }); return new this(o) } } class $n { static async from_pretrained(...e) { return Un.from_pretrained(...e) } } class Dn extends i { constructor() { super(), this.processors = [] } push(e) { this.processors.push(e) } extend(e) { this.processors.push(...e) } _call(e, t) { for (let s of t) this.processors.forEach((t => t(e, s))) } [Symbol.iterator]() { return this.processors.values() } } class jn extends i { _call(e, t) { throw Error("`_call` should be implemented in a subclass") } } class qn extends jn { constructor(e) { super(), this.force_token_map = Object.fromEntries(e ?? []) } _call(e, t) { let s = this.force_token_map[e.length]; return null != s && (t.data.fill(-1 / 0), t.data[s] = 0), t } } class Gn extends jn { constructor(e) { super(), this.bos_token_id = e } _call(e, t) { return 1 === e.length && (t.data.fill(-1 / 0), t.data[this.bos_token_id] = 0), t } } class Wn extends jn { constructor(e, t) { super(), this.max_length = e, this.forced_eos_token_id = t } _call(e, t) { } } class Yn extends jn { constructor(e, t) { super(), this.begin_suppress_tokens = e, this.begin_index = t } _call(e, t) { if (e.length === this.begin_index) for (let e of this.begin_suppress_tokens) t.data[e] = -1 / 0; return t } } class Vn extends jn { constructor(e) { super(), this.eos_token_id = e.eos_token_id, this.no_timestamps_token_id = e.no_timestamps_token_id, this.timestamp_begin = this.no_timestamps_token_id + 1, this.begin_index = (e.forced_decoder_ids || []).length + 2, e.forced_decoder_ids.slice(-1)[0][1] === this.no_timestamps_token_id && (this.begin_index -= 1), this.max_initial_timestamp_index = e.max_initial_timestamp_index } _call(e, t) { const s = t.data; if (s[this.no_timestamps_token_id] = -1 / 0, e.length === this.begin_index - 1) return s.fill(-1 / 0), s[this.timestamp_begin] = 0, t; const n = e.slice(this.begin_index), r = n.length >= 1 && n[n.length - 1] >= this.timestamp_begin, i = n.length < 2 || n[n.length - 2] >= this.timestamp_begin; if (r && (i ? s.subarray(this.timestamp_begin).fill(-1 / 0) : s.subarray(0, this.eos_token_id).fill(-1 / 0)), e.length === this.begin_index && null !== this.max_initial_timestamp_index) { const e = this.timestamp_begin + this.max_initial_timestamp_index; s.subarray(e + 1).fill(-1 / 0) } const o = at(s); return Math.log(o.subarray(this.timestamp_begin).map(Math.exp).reduce(((e, t) => e + t))) > _t(o.subarray(0, this.timestamp_begin))[0] && s.subarray(0, this.timestamp_begin).fill(-1 / 0), t } } class Xn extends jn { constructor(e) { super(), this.no_repeat_ngram_size = e } getNgrams(e) { const t = e.length, s = []; for (let n = 0; n < t + 1 - this.no_repeat_ngram_size; ++n) { const t = []; for (let s = 0; s < this.no_repeat_ngram_size; ++s)t.push(e[n + s]); s.push(t) } const n = new Map; for (const e of s) { const t = e.slice(0, e.length - 1), s = JSON.stringify(t), r = n.get(s) ?? []; r.push(e[e.length - 1]), n.set(s, r) } return n } getGeneratedNgrams(e, t) { const s = t.slice(t.length + 1 - this.no_repeat_ngram_size, t.length); return e.get(JSON.stringify(s)) ?? [] } calcBannedNgramTokens(e) { const t = []; if (e.length + 1 < this.no_repeat_ngram_size) return t; { const t = this.getNgrams(e); return this.getGeneratedNgrams(t, e) } } _call(e, t) { const s = this.calcBannedNgramTokens(e); for (const e of s) t.data[e] = -1 / 0; return t } } class Kn extends jn { constructor(e) { super(), this.penalty = e } _call(e, t) { for (const s of e) t.data[s] < 0 ? t.data[s] *= this.penalty : t.data[s] /= this.penalty; return t } } class Hn extends jn { constructor(e, t) { super(), this.min_length = e, this.eos_token_id = Array.isArray(t) ? t : [t] } _call(e, t) { if (e.length < this.min_length) for (const e of this.eos_token_id) t.data[e] = -1 / 0; return t } } class Qn extends jn { constructor(e, t, s) { super(), this.prompt_length_to_skip = e, this.min_new_tokens = t, this.eos_token_id = Array.isArray(s) ? s : [s] } _call(e, t) { if (e.length - this.prompt_length_to_skip < this.min_new_tokens) for (const e of this.eos_token_id) t.data[e] = -1 / 0; return t } } class Jn extends jn { constructor(e, t) { super(), this.bad_words_ids = e, this.eos_token_id = Array.isArray(t) ? t : [t] } _call(e, t) { for (const s of this.bad_words_ids) { let n = !0; for (let t = 1; t <= s.length - 1 && s.length < e.length; ++t)if (s.at(-t - 1) !== e.at(-t)) { n = !1; break } n && (t.data[s.at(-1)] = -1 / 0) } return t } } const Zn = class { constructor(e = {}) { this.max_length = e.max_length ?? 20, this.max_new_tokens = e.max_new_tokens ?? null, this.min_length = e.min_length ?? 0, this.min_new_tokens = e.min_new_tokens ?? null, this.early_stopping = e.early_stopping ?? !1, this.max_time = e.max_time ?? null, this.do_sample = e.do_sample ?? !1, this.num_beams = e.num_beams ?? 1, this.num_beam_groups = e.num_beam_groups ?? 1, this.penalty_alpha = e.penalty_alpha ?? null, this.use_cache = e.use_cache ?? !0, this.temperature = e.temperature ?? 1, this.top_k = e.top_k ?? 50, this.top_p = e.top_p ?? 1, this.typical_p = e.typical_p ?? 1, this.epsilon_cutoff = e.epsilon_cutoff ?? 0, this.eta_cutoff = e.eta_cutoff ?? 0, this.diversity_penalty = e.diversity_penalty ?? 0, this.repetition_penalty = e.repetition_penalty ?? 1, this.encoder_repetition_penalty = e.encoder_repetition_penalty ?? 1, this.length_penalty = e.length_penalty ?? 1, this.no_repeat_ngram_size = e.no_repeat_ngram_size ?? 0, this.bad_words_ids = e.bad_words_ids ?? null, this.force_words_ids = e.force_words_ids ?? null, this.renormalize_logits = e.renormalize_logits ?? !1, this.constraints = e.constraints ?? null, this.forced_bos_token_id = e.forced_bos_token_id ?? null, this.forced_eos_token_id = e.forced_eos_token_id ?? null, this.remove_invalid_values = e.remove_invalid_values ?? !1, this.exponential_decay_length_penalty = e.exponential_decay_length_penalty ?? null, this.suppress_tokens = e.suppress_tokens ?? null, this.begin_suppress_tokens = e.begin_suppress_tokens ?? null, this.forced_decoder_ids = e.forced_decoder_ids ?? null, this.num_return_sequences = e.num_return_sequences ?? 1, this.output_attentions = e.output_attentions ?? !1, this.output_hidden_states = e.output_hidden_states ?? !1, this.output_scores = e.output_scores ?? !1, this.return_dict_in_generate = e.return_dict_in_generate ?? !1, this.pad_token_id = e.pad_token_id ?? null, this.bos_token_id = e.bos_token_id ?? null, this.eos_token_id = e.eos_token_id ?? null, this.encoder_no_repeat_ngram_size = e.encoder_no_repeat_ngram_size ?? 0, this.decoder_start_token_id = e.decoder_start_token_id ?? null, this.generation_kwargs = e.generation_kwargs ?? {} } }; class er extends i { constructor(e) { super(), this.generation_config = e } _call(e, t = -1) { return this.sample(e, t) } sample(e, t) { throw Error("sample should be implemented in subclasses.") } getLogits(e, t) { let s = e.dims.at(-1), n = e.data; if (-1 === t) n = n.slice(-s); else { let e = t * s; n = n.slice(e, e + s) } return this.generation_config.temperature > 0 && (n = n.map((e => e / this.generation_config.temperature))), n } randomSelect(e) { let t = e.reduce(((e, t) => e + t), 0), s = Math.random() * t; for (let t = 0; t < e.length; ++t)if (s -= e[t], s <= 0) return t; return 0 } static getSampler(e) { if (e.do_sample) return new sr(e); if (e.num_beams > 1) return new nr(e); if (e.num_return_sequences > 1) throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${e.num_return_sequences}.`); return new tr(e) } } class tr extends er { sample(e, t = -1) { return [[_t(this.getLogits(e, t))[1], 0]] } } class sr extends er { sample(e, t = -1) { let s = e.dims.at(-1); this.generation_config.top_k > 0 && (s = Math.min(this.generation_config.top_k, s)); const n = ct(this.getLogits(e, t), s), r = ot(n.map((e => e[1]))); return Array.from({ length: this.generation_config.num_beams }, (() => { const e = this.randomSelect(r); return [n[e][0], Math.log(r[e])] })) } } class nr extends er { sample(e, t = -1) { let s = e.dims.at(-1); this.generation_config.top_k > 0 && (s = Math.min(this.generation_config.top_k, s)); const n = ct(this.getLogits(e, t), s), r = ot(n.map((e => e[1]))); return Array.from({ length: this.generation_config.num_beams }, ((e, t) => [n[t][0], Math.log(r[t])])) } } const { InferenceSession: rr, Tensor: ir, env: or } = Re, ar = 0, lr = 1, cr = 2, hr = 3, dr = 4, ur = 5, _r = new Map, fr = new Map, pr = new Map; async function mr(e, t, s) { let n = `onnx/${t}${s.quantized ? "_quantized" : ""}.onnx`, r = await tt(e, n, !0, s); try { return await rr.create(r, { executionProviders: Oe }) } catch (e) { if (1 === Oe.length && "wasm" === Oe[0]) throw e; return console.warn(e), console.warn("Something went wrong during model construction (most likely a missing operation). Using `wasm` as a fallback. "), await rr.create(r, { executionProviders: ["wasm"] }) } } async function gr(e, t) { const s = function (e, t) { const s = Object.create(null), n = []; for (const r of e.inputNames) { const e = t[r]; e instanceof bt ? s[r] = or.wasm.proxy ? e.clone() : e : n.push(r) } if (n.length > 0) throw new Error(`An error occurred during model execution: "Missing the following inputs: ${n.join(", ")}.`); const r = Object.keys(t).length, i = e.inputNames.length; if (r > i) { let s = Object.keys(t).filter((t => !e.inputNames.includes(t))); console.warn(`WARNING: Too many inputs were provided (${r} > ${i}). The following inputs will be ignored: "${s.join(", ")}".`) } return s }(e, t); try { let t = await e.run(s); return t = wr(t), t } catch (e) { throw console.error(`An error occurred during model execution: "${e}".`), console.error("Inputs given to model:", s), e } } function wr(e) { for (let t in e) e[t] instanceof ir ? e[t] = new bt(e[t]) : "object" == typeof e[t] && wr(e[t]); return e } function yr(e) { if (e instanceof bt) return e; if (0 === e.length) throw Error("items must be non-empty"); if (Array.isArray(e[0])) { if (e.some((t => t.length !== e[0].length))) throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length."); return new bt("int64", BigInt64Array.from(e.flat().map((e => BigInt(e)))), [e.length, e[0].length]) } return new bt("int64", BigInt64Array.from(e.map((e => BigInt(e)))), [1, e.length]) } function xr(e, t) { let s = e.config.pad_token_id ?? null, n = e.config.eos_token_id ?? null; o(n) && (n = [n]); let r = -1 !== t.indexOf(s), i = null === n || !n.includes(s); if (r && i) { let e = BigInt64Array.from(t.data.map((e => e != s))); return new bt("int64", e, t.dims) } return Bt(t) } function kr(e, t, s) { if (!e.inputNames.includes("position_ids")) return; const n = new BigInt64Array(t.attention_mask.data.length); for (let e = 0; e < t.attention_mask.dims[0]; ++e) { let s = e * t.attention_mask.dims[1], r = BigInt(0); for (let e = 0; e < t.attention_mask.dims[1]; ++e) { const i = s + e; 0n === t.attention_mask.data[i] ? n[i] = BigInt(1) : (n[i] = r, r += t.attention_mask.data[i]) } } t.position_ids = new bt("int64", n, t.attention_mask.dims), s && (t.position_ids = t.position_ids.slice(null, -1).unsqueeze_(-1)) } function br(e) { return new bt("bool", [e], [1]) } async function vr(e, t) { let { encoder_outputs: s, past_key_values: n } = t; s || (s = (await Er(e, t)).last_hidden_state); let r = { input_ids: t.decoder_input_ids, encoder_hidden_states: s }; const i = !!n; e.decoder_merged_session.inputNames.includes("use_cache_branch") && (r.use_cache_branch = br(i)), e.decoder_merged_session.inputNames.includes("encoder_attention_mask") && (r.encoder_attention_mask = t.attention_mask), kr(e.decoder_merged_session, r, i), e.addPastKeyValues(r, n); const o = await gr(e.decoder_merged_session, r); let a = o.logits; n = e.getPastKeyValues(o, n); const l = e.getAttentions(o); return new Lh({ logits: a, past_key_values: n, encoder_outputs: s, ...l }) } function Ar(e, t, s, n) { let r = [], i = 0; const o = e.requires_attention_mask ?? !0; let a = s.decoder_input_ids ?? s.decoder_start_token_id ?? s.bos_token_id ?? s.eos_token_id; a instanceof bt ? a = a.tolist().flat() : Array.isArray(a) || (a = [a]); for (let s of t) { s.dims = [1, ...s.dims]; let t = { inputs: s, encoder_outputs: null, prev_model_outputs: null, output_token_ids: a, done: !1, score: 0, id: i++ }; o && (t.attention_mask = xr(e, s)), r.push(t) } return r } async function Mr(e, t) { const s = e.main_input_name; let n = t.output_token_ids; t.prev_model_outputs && (n = n.slice(-1)); let r = { [s]: t.inputs, decoder_input_ids: yr(n), encoder_outputs: t.encoder_outputs, past_key_values: t.prev_model_outputs?.past_key_values }; t.attention_mask && (r.attention_mask = t.attention_mask); let i = await e.forward(r); return t.prev_model_outputs = i, t.encoder_outputs = i.encoder_outputs, i } function zr(e, t) { e.output_token_ids = [...e.output_token_ids, t] } async function Er(e, t) { const s = Object.create(null); for (const n of e.session.inputNames) s[n] = t[n]; return e.session.inputNames.includes("token_type_ids") && !s.token_type_ids && (s.token_type_ids = new bt("int64", new BigInt64Array(s.input_ids.data.length), s.input_ids.dims)), await gr(e.session, s) } async function Tr(e, t) { let { input_ids: s, past_key_values: n, attention_mask: r } = t, i = { input_ids: s, attention_mask: r ?? xr(e, s) }; const o = !!n; e.session.inputNames.includes("use_cache_branch") && (i.use_cache_branch = br(o)), kr(e.session, i, o), e.addPastKeyValues(i, n); let a = await gr(e.session, i), l = a.logits; return n = e.getPastKeyValues(a, n), { logits: l, past_key_values: n } } function Sr(e, t, s, n, r) { let i = [], o = 0; for (let s of t) { let t, a = s.tolist().map(Number); s.dims = [1, ...s.dims], r ? (t = r[o], t.dims = [1, ...t.dims]) : t = xr(e, s); let l = { input: s, model_input_ids: s, attention_mask: t, prev_model_outputs: null, output_token_ids: a, num_output_tokens: n, done: !1, score: 0, id: o++ }; i.push(l) } return i } async function Cr(e, t) { let s = new BigInt64Array(t.output_token_ids.length).fill(1n), n = { input_ids: t.model_input_ids, attention_mask: new bt("int64", s, [1, s.length]), past_key_values: t.prev_model_outputs?.past_key_values }, r = await e.forward(n); return t.prev_model_outputs = r, r } function Pr(e, t) { e.output_token_ids = [...e.output_token_ids, t], e.model_input_ids = new bt("int64", [BigInt(t)], [1, 1]) } class Fr extends i { main_input_name = "input_ids"; constructor(e, t) { super(), this.config = e, this.session = t; const s = pr.get(this.constructor), n = _r.get(s); this.can_generate = !1, this._runBeam = null, this._getStartBeams = null, this._updateBeam = null, this._forward = null, n === dr ? (this.can_generate = !0, this._runBeam = Cr, this._getStartBeams = Sr, this._updateBeam = Pr, this._forward = Tr) : n === cr || n === hr ? (this.can_generate = !0, this._runBeam = Mr, this._getStartBeams = Ar, this._updateBeam = zr, this._forward = vr) : this._forward = Er } async dispose() { const e = []; for (let t of Object.keys(this)) { const s = this[t]; s instanceof rr && e.push(s.handler.dispose()) } return await Promise.all(e) } static async from_pretrained(e, { quantized: t = !0, progress_callback: s = null, config: n = null, cache_dir: r = null, local_files_only: i = !1, revision: o = "main", model_file_name: a = null } = {}) { let l = { quantized: t, progress_callback: s, config: n, cache_dir: r, local_files_only: i, revision: o, model_file_name: a }; const c = pr.get(this), h = _r.get(c); let d; return h === dr ? d = await Promise.all([$n.from_pretrained(e, l), mr(e, l.model_file_name ?? "decoder_model_merged", l), st(e, "generation_config.json", !1, l)]) : h === cr || h === hr ? d = await Promise.all([$n.from_pretrained(e, l), mr(e, "encoder_model", l), mr(e, "decoder_model_merged", l), st(e, "generation_config.json", !1, l)]) : h === ur ? d = await Promise.all([$n.from_pretrained(e, l), mr(e, "vision_encoder", l), mr(e, "prompt_encoder_mask_decoder", l)]) : h === lr ? d = await Promise.all([$n.from_pretrained(e, l), mr(e, "encoder_model", l), mr(e, "decoder_model_merged", l)]) : (h !== ar && console.warn(`Model type for '${c}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`), d = await Promise.all([$n.from_pretrained(e, l), mr(e, l.model_file_name ?? "model", l)])), new this(...d) } async _call(e) { return await this.forward(e) } async forward(e) { return await this._forward(this, e) } _get_logits_processor(e, t, s = null) { const n = new Dn; if (null !== e.repetition_penalty && 1 !== e.repetition_penalty && n.push(new Kn(e.repetition_penalty)), null !== e.no_repeat_ngram_size && e.no_repeat_ngram_size > 0 && n.push(new Xn(e.no_repeat_ngram_size)), null !== e.bad_words_ids && n.push(new Jn(e.bad_words_ids, e.eos_token_id)), null !== e.min_length && null !== e.eos_token_id && e.min_length > 0 && n.push(new Hn(e.min_length, e.eos_token_id)), null !== e.min_new_tokens && null !== e.eos_token_id && e.min_new_tokens > 0 && n.push(new Qn(t, e.min_new_tokens, e.eos_token_id)), null !== e.forced_bos_token_id && n.push(new Gn(e.forced_bos_token_id)), null !== e.forced_eos_token_id && n.push(new Wn(e.max_length, e.forced_eos_token_id)), null !== e.begin_suppress_tokens) { let s = t > 1 || null === e.forced_bos_token_id ? t : t + 1; null !== e.forced_decoder_ids && (s += e.forced_decoder_ids[e.forced_decoder_ids.length - 1][0]), n.push(new Yn(e.begin_suppress_tokens, s)) } return null !== e.forced_decoder_ids && n.push(new qn(e.forced_decoder_ids)), null !== s && n.extend(s), n } _get_generation_config(e) { let t = new Zn(this.config); return "generation_config" in this && Object.assign(t, this.generation_config), null !== e && Object.assign(t, e), t } async generate(e, t = null, s = null, { inputs_attention_mask: n = null } = {}) { if (!this.can_generate) { let e = `The current model class (${pr.get(this.constructor)}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`; const t = this.config.model_type, s = Yc.get(t) ?? Wc.get(t) ?? $c.get(t) ?? Kc.get(t); throw s && (e += ` Please use the following class instead: '${s[0]}'`), Error(e) } if (!(e instanceof bt || (r = e, "TypedArray" === r?.prototype?.__proto__?.constructor?.name) || Array.isArray(e))) throw Error(`\`inputs\` must be a Tensor, TypedArray, or Array, but is "${e.constructor.name}".`); var r; let i; if (this.config.is_encoder_decoder) i = 0; else if (i = e instanceof bt ? e.dims.at(-1) : e.length, 0 === i) throw Error("Must supply a non-empty array of input token ids."); t = this._get_generation_config(t), s = s ?? new Dn, s = this._get_logits_processor(t, i, s); let o = t.eos_token_id; null === o || Array.isArray(o) || (o = [o]); let a = 1; const l = a + (t.max_new_tokens ?? 1 / 0), c = Number.isInteger(t.max_length) && null === (t.max_new_tokens ?? null); let h = er.getSampler(t), d = this.getStartBeams(e, t, a, n); for (; d.some((e => !e.done)) && a < l;) { let e = []; for (let n of d) { if (n.done) { e.push(n); continue } if (c && n.output_token_ids.length >= t.max_length) { n.done = !0, e.push(n); continue } let r = await this.runBeam(n); t.output_attentions && this.addAttentionsToBeam(n, r), t.output_scores; let i = r.logits.slice(null, -1, null); s(n.output_token_ids, i); let a = h(i); for (let [t, s] of a) { let r = { ...n }; this.updateBeam(r, t), r.score += s, o && o.includes(t) && (r.done = !0), e.push(r) } } ++a, e = this.groupBeams(e).map((e => e.sort(((e, t) => t.score - e.score)).slice(0, t.num_beams))), d = e.flat(), t.callback_function && t.callback_function(d) } const u = this.groupBeams(d), _ = e => u.map((s => t.num_return_sequences > 1 ? s.slice(0, t.num_return_sequences).map((t => t[e])) : [s[0][e]])).flat(), f = _("output_token_ids"); if (t.return_dict_in_generate) { return { sequences: f, decoder_attentions: _("decoder_attentions"), cross_attentions: _("cross_attentions") } } return f } addAttentionsToBeam(e, t) { if (this.config.is_encoder_decoder) { if (!t.cross_attentions || 0 === t.cross_attentions.length) throw Error("`output_attentions` is true, but the model did not produce cross-attentions. This is most likely because the model was not exported with `output_attentions=True`."); e.cross_attentions || (e.cross_attentions = []), e.cross_attentions.push(t.cross_attentions) } if (!t.decoder_attentions || 0 === t.decoder_attentions.length) throw Error("`output_attentions` is true, but the model did not produce decoder-attentions. This is most likely because the model was not exported with `output_attentions=True`."); e.decoder_attentions || (e.decoder_attentions = []), e.decoder_attentions.push(t.decoder_attentions) } groupBeams(e) { const t = Object.create(null); for (const s of e) void 0 === t[s.id] ? t[s.id] = [s] : t[s.id].push(s); return Object.values(t) } getPastKeyValues(e, t) { const s = Object.create(null); for (const n in e) if (n.startsWith("present")) { let r = n.replace("present", "past_key_values"); t && n.includes("encoder") ? s[r] = t[r] : s[r] = e[n] } return s } getAttentions(e) { const t = Object.create(null); for (const s of ["cross_attentions", "decoder_attentions"]) { const n = []; for (const t in e) if (t.startsWith(s)) { n[t.split(".").pop()] = e[t] } t[s] = n } return t } addPastKeyValues(e, t) { if (t) Object.assign(e, t); else { const t = 1; if (this.config.is_encoder_decoder && (this.add_encoder_pkv ?? 1)) { let s = [t, this.num_encoder_heads, 0, this.encoder_dim_kv], n = [t, this.num_decoder_heads, 0, this.decoder_dim_kv]; for (let t = 0; t < this.num_decoder_layers; ++t)e[`past_key_values.${t}.encoder.key`] = new bt("float32", [], s), e[`past_key_values.${t}.encoder.value`] = new bt("float32", [], s), e[`past_key_values.${t}.decoder.key`] = new bt("float32", [], n), e[`past_key_values.${t}.decoder.value`] = new bt("float32", [], n) } else if ("falcon" === this.config.model_type) { let s = [t * this.num_heads, 0, this.dim_kv]; for (let t = 0; t < this.num_layers; ++t)e[`past_key_values.${t}.key`] = new bt("float32", [], s), e[`past_key_values.${t}.value`] = new bt("float32", [], s) } else if (this.config.multi_query) { let s = [t * this.num_heads, 0, 2 * this.dim_kv]; for (let t = 0; t < this.num_layers; ++t)e[`past_key_values.${t}.key_value`] = new bt("float32", [], s) } else if ("bloom" === this.config.model_type) { let s = [t * this.num_heads, this.dim_kv, 0], n = [t * this.num_heads, 0, this.dim_kv]; for (let t = 0; t < this.num_layers; ++t)e[`past_key_values.${t}.key`] = new bt("float32", [], s), e[`past_key_values.${t}.value`] = new bt("float32", [], n) } else { let s = [t, this.num_heads, 0, this.dim_kv]; for (let t = 0; t < this.num_layers; ++t)e[`past_key_values.${t}.key`] = new bt("float32", [], s), e[`past_key_values.${t}.value`] = new bt("float32", [], s) } } } getStartBeams(e, t, s, n) { return this._getStartBeams(this, e, t, s, n) } async runBeam(e) { return await this._runBeam(this, e) } updateBeam(e, t) { return this._updateBeam(e, t) } } class Lr { } class Ir extends Lr { constructor({ last_hidden_state: e, hidden_states: t = null, attentions: s = null }) { super(), this.last_hidden_state = e, this.hidden_states = t, this.attentions = s } } class Br extends Fr { } class Rr extends Br { } class Or extends Br { async _call(e) { return new Rh(await super._call(e)) } } class Nr extends Br { async _call(e) { return new Ih(await super._call(e)) } } class Ur extends Br { async _call(e) { return new Bh(await super._call(e)) } } class $r extends Br { async _call(e) { return new Oh(await super._call(e)) } } class Dr extends Fr { } class jr extends Dr { } class qr extends Dr { async _call(e) { return new Rh(await super._call(e)) } } class Gr extends Dr { async _call(e) { return new Ih(await super._call(e)) } } class Wr extends Dr { async _call(e) { return new Bh(await super._call(e)) } } class Yr extends Dr { async _call(e) { return new Oh(await super._call(e)) } } class Vr extends Fr { } class Xr extends Vr { } class Kr extends Vr { async _call(e) { return new Rh(await super._call(e)) } } class Hr extends Vr { async _call(e) { return new Ih(await super._call(e)) } } class Qr extends Vr { async _call(e) { return new Bh(await super._call(e)) } } class Jr extends Vr { async _call(e) { return new Oh(await super._call(e)) } } class Zr extends Fr { } class ei extends Zr { } class ti extends Zr { async _call(e) { return new Rh(await super._call(e)) } } class si extends Zr { async _call(e) { return new Ih(await super._call(e)) } } class ni extends Zr { async _call(e) { return new Bh(await super._call(e)) } } class ri extends Zr { async _call(e) { return new Oh(await super._call(e)) } } class ii extends Fr { } class oi extends ii { } class ai extends ii { async _call(e) { return new Rh(await super._call(e)) } } class li extends ii { async _call(e) { return new Ih(await super._call(e)) } } class ci extends ii { async _call(e) { return new Bh(await super._call(e)) } } class hi extends ii { async _call(e) { return new Oh(await super._call(e)) } } class di extends Fr { } class ui extends di { } class _i extends di { async _call(e) { return new Rh(await super._call(e)) } } class fi extends di { async _call(e) { return new Ih(await super._call(e)) } } class pi extends di { async _call(e) { return new Bh(await super._call(e)) } } class mi extends di { async _call(e) { return new Oh(await super._call(e)) } } class gi extends Fr { } class wi extends gi { } class yi extends gi { async _call(e) { return new Rh(await super._call(e)) } } class xi extends gi { async _call(e) { return new Ih(await super._call(e)) } } class ki extends gi { async _call(e) { return new Bh(await super._call(e)) } } class bi extends gi { async _call(e) { return new Oh(await super._call(e)) } } class vi extends Fr { } class Ai extends vi { } class Mi extends vi { async _call(e) { return new Ih(await super._call(e)) } } class zi extends vi { async _call(e) { return new Bh(await super._call(e)) } } class Ei extends vi { async _call(e) { return new Oh(await super._call(e)) } } class Ti extends vi { async _call(e) { return new Rh(await super._call(e)) } } class Si extends Fr { } class Ci extends Si { } class Pi extends Si { async _call(e) { return new Rh(await super._call(e)) } } class Fi extends Si { async _call(e) { return new Ih(await super._call(e)) } } class Li extends Si { async _call(e) { return new Bh(await super._call(e)) } } class Ii extends Fr { } class Bi extends Ii { } class Ri extends Ii { async _call(e) { return new Rh(await super._call(e)) } } class Oi extends Ii { async _call(e) { return new Ih(await super._call(e)) } } class Ni extends Ii { async _call(e) { return new Oh(await super._call(e)) } } class Ui extends Fr { } class $i extends Ui { } class Di extends Ui { async _call(e) { return new Rh(await super._call(e)) } } class ji extends Ui { async _call(e) { return new Ih(await super._call(e)) } } class qi extends Ui { async _call(e) { return new Bh(await super._call(e)) } } class Gi extends Ui { async _call(e) { return new Oh(await super._call(e)) } } class Wi extends Fr { } class Yi extends Wi { } class Vi extends Wi { async _call(e) { return new Rh(await super._call(e)) } } class Xi extends Wi { async _call(e) { return new Ih(await super._call(e)) } } class Ki extends Wi { async _call(e) { return new Oh(await super._call(e)) } } class Hi extends Fr { } class Qi extends Hi { } class Ji extends Hi { async _call(e) { return new Ih(await super._call(e)) } } class Zi extends Hi { async _call(e) { return new Oh(await super._call(e)) } } class eo extends Hi { async _call(e) { return new Rh(await super._call(e)) } } class to extends Fr { } class so extends to { } class no extends to { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.num_decoder_layers, this.num_decoder_heads = this.config.num_heads, this.decoder_dim_kv = this.config.d_kv, this.num_encoder_layers = this.config.num_layers, this.num_encoder_heads = this.config.num_heads, this.encoder_dim_kv = this.config.d_kv } } class ro extends Fr { } class io extends ro { } class oo extends ro { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.num_decoder_layers, this.num_decoder_heads = this.config.num_heads, this.decoder_dim_kv = this.config.d_kv, this.num_encoder_layers = this.config.num_layers, this.num_encoder_heads = this.config.num_heads, this.encoder_dim_kv = this.config.d_kv } } class ao extends Fr { } class lo extends ao { } class co extends ao { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.num_decoder_layers, this.num_decoder_heads = this.config.num_heads, this.decoder_dim_kv = this.config.d_kv, this.num_encoder_layers = this.config.num_layers, this.num_encoder_heads = this.config.num_heads, this.encoder_dim_kv = this.config.d_kv } } class ho extends Fr { } class uo extends ho { } class _o extends ho { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads } } class fo extends ho { async _call(e) { return new Ih(await super._call(e)) } } class po extends Fr { } class mo extends po { } class go extends po { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads } } class wo extends po { async _call(e) { return new Ih(await super._call(e)) } } class yo extends po { constructor(e, t, s) { super(e, t), this.generation_config = s, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads } } class xo extends Fr { } class ko extends xo { } class bo extends xo { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads } } class vo extends Fr { } class Ao extends vo { } class Mo extends vo { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads } } class zo extends Fr { } class Eo extends zo { } class To extends zo { async _call(e) { return new Rh(await super._call(e)) } } class So extends zo { async _call(e) { return new Ih(await super._call(e)) } } class Co extends zo { async _call(e) { return new Bh(await super._call(e)) } } class Po extends zo { async _call(e) { return new Oh(await super._call(e)) } } class Fo extends Fr { } class Lo extends Fo { } class Io extends Fo { async _call(e) { return new Rh(await super._call(e)) } } class Bo extends Fo { async _call(e) { return new Ih(await super._call(e)) } } class Ro extends Fo { async _call(e) { return new Bh(await super._call(e)) } } class Oo extends Fo { async _call(e) { return new Oh(await super._call(e)) } } class No extends Fr { } class Uo extends No { } class $o extends No { async _call(e) { return new Rh(await super._call(e)) } } class Do extends No { async _call(e) { return new Ih(await super._call(e)) } } class jo extends No { async _call(e) { return new Bh(await super._call(e)) } } class qo extends No { async _call(e) { return new Oh(await super._call(e)) } } class Go extends Fr { } class Wo extends Go { } class Yo extends Go { } class Vo extends Fr { } class Xo extends Vo { } class Ko extends Vo { requires_attention_mask = !1; main_input_name = "input_features"; constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads } async generate(e, t = null, s = null) { if (t = this._get_generation_config(t), t.return_timestamps ??= !1, t.return_timestamps && (s = [new Vn(t)]), t.return_token_timestamps && (t.output_attentions = !0, t.return_dict_in_generate = !0, "translate" === t.task && console.warn("Token-level timestamps may not be reliable for task 'translate'."), !t.alignment_heads)) throw new Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config."); const n = await super.generate(e, t, s); return t.return_token_timestamps && t.alignment_heads && (n.token_timestamps = this._extract_token_timestamps(n, t.alignment_heads, t.num_frames)), n } _extract_token_timestamps(e, t, s = null, n = .02) { if (!e.cross_attentions) throw new Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`."); let r = this.config.median_filter_width; void 0 === r && (console.warn("Model config has no `median_filter_width`, using default value of 7."), r = 7); const i = e.cross_attentions.map((e => { let n = Array.from({ length: this.config.decoder_layers }, ((t, s) => St(e.map((e => e[s])), 2))), i = Ct(t.map((([e, t]) => s ? n[e].slice(null, t, null, [0, s]) : n[e].slice(null, t)))); i = i.transpose(1, 0, 2, 3); let [o, a] = Pt(i, -2, 0, !0), l = i.clone(); for (let e = 0; e < l.dims[0]; ++e) { let t = l[e]; for (let s = 0; s < t.dims[0]; ++s) { let n = t[s]; const i = o[e][s][0], l = a[e][s][0]; for (let e = 0; e < n.dims[0]; ++e) { let t = n[e]; for (let e = 0; e < t.data.length; ++e)t.data[e] = (t.data[e] - l.data[e]) / i.data[e]; t.data.set(wt(t.data, r)) } } } return Ft(l, 1) })), o = [e.sequences.length, e.sequences[0].length], a = new bt("float32", new Float32Array(o[0] * o[1]), o); for (let e = 0; e < o[0]; ++e) { const t = i[e].neg().squeeze_(0); let [s, r] = Lt(t), o = c([1], Array.from({ length: s.length - 1 }, ((e, t) => s[t + 1] - s[t]))).map((e => !!e)), l = []; for (let e = 0; e < o.length; ++e)o[e] && l.push(r[e] * n); a[e].data.set(l, 1) } return a } } class Ho extends Fr { main_input_name = "pixel_values"; constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n; const r = this.config.encoder, i = this.config.decoder, o = r.model_type; (Oc.get(o) ?? Nc.get(o)) || console.warn(`Model type for encoder '${o}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`); const a = Yc.get(i.model_type); if (!a) throw new Error(`Unable to construct \`VisionEncoderDecoder\` due to unsupported decoder: "${this.config.decoder.model_type}"`); const l = new (0, a[1])(i, s, n); this.add_encoder_pkv = "num_decoder_layers" in l, this.add_encoder_pkv ? (this.num_decoder_layers = l.num_decoder_layers, this.num_decoder_heads = l.num_decoder_heads, this.decoder_dim_kv = l.decoder_dim_kv, this.num_encoder_layers = l.num_encoder_layers, this.num_encoder_heads = l.num_encoder_heads, this.encoder_dim_kv = l.encoder_dim_kv) : (this.num_layers = l.num_layers, this.num_heads = l.num_heads, this.dim_kv = l.dim_kv) } } class Qo extends Fr { } class Jo extends Qo { } class Zo extends Qo { static async from_pretrained(e, t = {}) { return t.model_file_name ??= "text_model", super.from_pretrained(e, t) } } class ea extends Qo { static async from_pretrained(e, t = {}) { return t.model_file_name ??= "vision_model", super.from_pretrained(e, t) } } class ta extends Fr { } class sa extends ta { } class na extends ta { static async from_pretrained(e, t = {}) { return t.model_file_name ??= "text_model", super.from_pretrained(e, t) } } class ra extends Qo { static async from_pretrained(e, t = {}) { return t.model_file_name ??= "vision_model", super.from_pretrained(e, t) } } class ia extends Fr { } class oa extends ia { } class aa extends Fr { } class la extends aa { } class ca extends aa { } class ha extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.n_head, this.num_layers = this.config.n_layer, this.dim_kv = this.config.n_embd / this.num_heads } } class da extends ha { } class ua extends ha { } class _a extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.num_heads, this.num_layers = this.config.num_layers, this.dim_kv = this.config.hidden_size / this.num_heads } } class fa extends _a { } class pa extends _a { } class ma extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.num_attention_heads, this.num_layers = this.config.num_hidden_layers, this.dim_kv = this.config.hidden_size / this.num_heads } } class ga extends ma { } class wa extends ma { } class ya extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.n_head, this.num_layers = this.config.n_layer, this.dim_kv = this.config.n_embd / this.num_heads } } class xa extends ya { } class ka extends ya { } class ba extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.n_head, this.num_layers = this.config.n_layer, this.dim_kv = this.config.n_embd / this.num_heads } } class va extends ba { } class Aa extends ba { } class Ma extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.n_head, this.num_layers = this.config.n_layer, this.dim_kv = this.config.n_embd / this.num_heads } } class za extends Ma { } class Ea extends Ma { } class Ta extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.num_key_value_heads ?? this.config.num_attention_heads, this.num_layers = this.config.num_hidden_layers, this.dim_kv = this.config.hidden_size / this.config.num_attention_heads } } class Sa extends Ta { } class Ca extends Ta { } class Pa extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.num_attention_heads, this.num_layers = this.config.num_hidden_layers, this.dim_kv = this.config.hidden_size / this.num_heads } } class Fa extends Pa { } class La extends Pa { } class Ia extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.n_head, this.num_layers = this.config.n_layer, this.dim_kv = this.config.hidden_size / this.num_heads } } class Ba extends Ia { } class Ra extends Ia { } class Oa extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.n_heads, this.num_layers = this.config.n_layers, this.dim_kv = this.config.d_model / this.num_heads } } class Na extends Oa { } class Ua extends Oa { } class $a extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.num_attention_heads, this.num_layers = this.config.num_hidden_layers, this.dim_kv = this.config.hidden_size / this.num_heads } } class Da extends $a { } class ja extends $a { } class qa extends Fr { } class Ga extends qa { } class Wa extends qa { async _call(e) { return new Ih(await super._call(e)) } } class Ya extends Fr { } class Va extends Ya { async _call(e) { return new $h(await super._call(e)) } } class Xa extends Fr { } class Ka extends Xa { } class Ha extends Xa { async _call(e) { return new Ih(await super._call(e)) } } class Qa extends Fr { } class Ja extends Qa { } class Za extends Qa { } class el extends Fr { } class tl extends el { } class sl extends el { async _call(e) { return new Ih(await super._call(e)) } } class nl extends Fr { } class rl extends nl { } class il extends nl { async _call(e) { return new al(await super._call(e)) } } class ol extends nl { async _call(e) { return new ll(await super._call(e)) } } class al extends Lr { constructor({ logits: e, pred_boxes: t }) { super(), this.logits = e, this.pred_boxes = t } } class ll extends Lr { constructor({ logits: e, pred_boxes: t, pred_masks: s }) { super(), this.logits = e, this.pred_boxes = t, this.pred_masks = s } } class cl extends Fr { } class hl extends cl { } class dl extends cl { async _call(e) { return new ul(await super._call(e)) } } class ul extends al { } class _l extends Fr { } class fl extends _l { } class pl extends _l { async _call(e) { return new Ih(await super._call(e)) } } class ml extends Fr { } class gl extends ml { } class wl extends ml { async _call(e) { return new Ih(await super._call(e)) } } class yl extends Fr { } class xl extends yl { } class kl extends yl { async _call(e) { return new Ih(await super._call(e)) } } class bl extends Fr { } class vl extends bl { } class Al extends bl { } class Ml extends Fr { } class zl extends Ml { } class El extends Ml { } class Tl extends Fr { } class Sl extends Tl { } class Cl extends Tl { } class Pl extends Fr { } class Fl extends Pl { } class Ll extends Fr { } class Il extends Ll { } class Bl extends Ll { async _call(e) { return new Ih(await super._call(e)) } } class Rl extends Fr { } class Ol extends Rl { } class Nl extends Rl { async _call(e) { return new Ih(await super._call(e)) } } class Ul extends Fr { } class $l extends Ul { } class Dl extends Ul { async _call(e) { return new Ih(await super._call(e)) } } class jl extends Fr { } class ql extends jl { } class Gl extends jl { async _call(e) { return new Wl(await super._call(e)) } } class Wl extends Lr { constructor({ logits: e, pred_boxes: t }) { super(), this.logits = e, this.pred_boxes = t } } class Yl extends Fr { } class Vl extends Yl { constructor(e, t, s) { super(e, t), this.prompt_encoder_mask_decoder = s } async get_image_embeddings({ pixel_values: e }) { return await Er(this, { pixel_values: e }) } async forward(e) { if (e.image_embeddings && e.image_positional_embeddings || (e = { ...e, ...await this.get_image_embeddings(e) }), !e.input_labels) { const t = e.input_points.dims.slice(0, -1), s = t.reduce(((e, t) => e * t), 1); e.input_labels = new bt("int64", new BigInt64Array(s).fill(1n), t) } return await gr(this.prompt_encoder_mask_decoder, { input_points: e.input_points, input_labels: e.input_labels, image_embeddings: e.image_embeddings, image_positional_embeddings: e.image_positional_embeddings }) } async _call(e) { return new Xl(await super._call(e)) } } class Xl extends Lr { constructor({ iou_scores: e, pred_masks: t }) { super(), this.iou_scores = e, this.pred_masks = t } } class Kl extends Fr { } class Hl extends Kl { } class Ql extends Kl { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads } } class Jl extends Fr { } class Zl extends Jl { } class ec extends Jl { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads } } class tc extends Fr { } class sc extends tc { } class nc extends tc { async _call(e) { return new Nh(await super._call(e)) } } class rc extends tc { async _call(e) { return new Ih(await super._call(e)) } } class ic extends Fr { } class oc extends tc { } class ac extends tc { async _call(e) { return new Nh(await super._call(e)) } } class lc extends tc { async _call(e) { return new Ih(await super._call(e)) } } class cc extends Fr { } class hc extends cc { } class dc extends cc { async _call(e) { return new Nh(await super._call(e)) } } class uc extends cc { async _call(e) { return new Ih(await super._call(e)) } } class _c extends Fr { } class fc extends _c { } class pc extends _c { } class mc extends _c { constructor(e, t, s, n) { super(e, t), this.decoder_merged_session = s, this.generation_config = n, this.num_decoder_layers = this.config.decoder_layers, this.num_decoder_heads = this.config.decoder_attention_heads, this.decoder_dim_kv = this.config.hidden_size / this.num_decoder_heads, this.num_encoder_layers = this.config.encoder_layers, this.num_encoder_heads = this.config.encoder_attention_heads, this.encoder_dim_kv = this.config.hidden_size / this.num_encoder_heads } async generate_speech(e, t, { threshold: s = .5, minlenratio: n = 0, maxlenratio: r = 20, vocoder: i = null } = {}) { const o = { input_ids: e }, { encoder_outputs: a, encoder_attention_mask: l } = await Er(this, o), c = a.dims[1] / this.config.reduction_factor, h = Math.floor(c * r), d = Math.floor(c * n), u = this.config.num_mel_bins; let _ = [], f = null, p = null, m = 0; for (; ;) { ++m; const e = br(!!p); let n; n = p ? p.output_sequence_out : new bt("float32", new Float32Array(u), [1, 1, u]); let r = { use_cache_branch: e, output_sequence: n, encoder_attention_mask: l, speaker_embeddings: t, encoder_hidden_states: a }; this.addPastKeyValues(r, f), p = await gr(this.decoder_merged_session, r), f = this.getPastKeyValues(p, f); const { prob: i, spectrum: o } = p; if (_.push(o), m >= d && (Array.from(i.data).filter((e => e >= s)).length > 0 || m >= h)) break } const g = St(_), { waveform: w } = await gr(i.session, { spectrogram: g }); return { spectrogram: g, waveform: w } } } class gc extends Fr { main_input_name = "spectrogram" } class wc extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_encoder_layers = this.num_decoder_layers = this.config.decoder_layers, this.num_encoder_heads = this.num_decoder_heads = this.config.decoder_attention_heads, this.encoder_dim_kv = this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads } } class yc extends wc { } class xc extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.num_key_value_heads, this.num_layers = this.config.num_hidden_layers, this.dim_kv = this.config.hidden_size / this.config.num_attention_heads } } class kc extends xc { } class bc extends xc { } class vc extends Fr { constructor(e, t, s) { super(e, t), this.generation_config = s, this.config.pad_token_id = this.config.eos_token_id, this.num_heads = this.config.num_attention_heads, this.num_layers = this.config.num_hidden_layers, this.dim_kv = this.config.hidden_size / this.config.num_attention_heads } } class Ac extends vc { } class Mc extends vc { } class zc extends Fr { } class Ec extends zc { } class Tc extends zc { static async from_pretrained(e, t = {}) { return t.model_file_name ??= "text_model", super.from_pretrained(e, t) } } class Sc extends zc { static async from_pretrained(e, t = {}) { return t.model_file_name ??= "audio_model", super.from_pretrained(e, t) } } class Cc extends Fr { } class Pc extends Cc { async _call(e) { return new Dh(await super._call(e)) } } class Fc extends Fr { } class Lc extends Fc { } class Ic extends Fc { } class Bc extends Fc { } class Rc { static MODEL_CLASS_MAPPINGS = null; static BASE_IF_FAIL = !1; static async from_pretrained(e, { quantized: t = !0, progress_callback: s = null, config: n = null, cache_dir: r = null, local_files_only: i = !1, revision: o = "main", model_file_name: a = null } = {}) { let l = { quantized: t, progress_callback: s, config: n, cache_dir: r, local_files_only: i, revision: o, model_file_name: a }; if (n = await $n.from_pretrained(e, l), l.config || (l.config = n), !this.MODEL_CLASS_MAPPINGS) throw new Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: " + this.name); for (let t of this.MODEL_CLASS_MAPPINGS) { const s = t.get(n.model_type); if (s) return await s[1].from_pretrained(e, l) } if (this.BASE_IF_FAIL) return console.warn(`Unknown model class "${n.model_type}", attempting to construct from base class.`), await Fr.from_pretrained(e, l); throw Error(`Unsupported model type: ${n.model_type}`) } } const Oc = new Map([["bert", ["BertModel", Rr]], ["roformer", ["RoFormerModel", jr]], ["electra", ["ElectraModel", ei]], ["esm", ["EsmModel", Ci]], ["convbert", ["ConvBertModel", Xr]], ["camembert", ["CamembertModel", oi]], ["deberta", ["DebertaModel", ui]], ["deberta-v2", ["DebertaV2Model", wi]], ["mpnet", ["MPNetModel", $i]], ["albert", ["AlbertModel", Qi]], ["distilbert", ["DistilBertModel", Ai]], ["roberta", ["RobertaModel", Eo]], ["xlm", ["XLMModel", Lo]], ["xlm-roberta", ["XLMRobertaModel", Uo]], ["clap", ["ClapModel", Ec]], ["clip", ["CLIPModel", Jo]], ["clipseg", ["CLIPSegModel", la]], ["chinese_clip", ["ChineseCLIPModel", oa]], ["siglip", ["SiglipModel", sa]], ["mobilebert", ["MobileBertModel", Bi]], ["squeezebert", ["SqueezeBertModel", Yi]], ["wav2vec2", ["Wav2Vec2Model", sc]], ["hubert", ["HubertModel", oc]], ["wavlm", ["WavLMModel", hc]], ["audio-spectrogram-transformer", ["ASTModel", Wo]], ["vits", ["VitsModel", Pc]], ["detr", ["DetrModel", rl]], ["table-transformer", ["TableTransformerModel", hl]], ["vit", ["ViTModel", Ga]], ["mobilevit", ["MobileViTModel", Ka]], ["owlvit", ["OwlViTModel", Ja]], ["beit", ["BeitModel", tl]], ["deit", ["DeiTModel", fl]], ["convnext", ["ConvNextModel", Il]], ["convnextv2", ["ConvNextV2Model", Ol]], ["dinov2", ["Dinov2Model", $l]], ["resnet", ["ResNetModel", gl]], ["swin", ["SwinModel", xl]], ["swin2sr", ["Swin2SRModel", vl]], ["donut-swin", ["DonutSwinModel", Fl]], ["yolos", ["YolosModel", ql]], ["dpt", ["DPTModel", zl]], ["glpn", ["GLPNModel", Sl]], ["hifigan", ["SpeechT5HifiGan", gc]]]), Nc = new Map([["t5", ["T5Model", so]], ["longt5", ["LongT5Model", io]], ["mt5", ["MT5Model", lo]], ["bart", ["BartModel", uo]], ["mbart", ["MBartModel", mo]], ["marian", ["MarianModel", Hl]], ["whisper", ["WhisperModel", Xo]], ["m2m_100", ["M2M100Model", Zl]], ["blenderbot", ["BlenderbotModel", ko]], ["blenderbot-small", ["BlenderbotSmallModel", Ao]]]), Uc = new Map([["bloom", ["BloomModel", Ba]], ["gpt2", ["GPT2Model", da]], ["gptj", ["GPTJModel", xa]], ["gpt_bigcode", ["GPTBigCodeModel", va]], ["gpt_neo", ["GPTNeoModel", fa]], ["gpt_neox", ["GPTNeoXModel", ga]], ["codegen", ["CodeGenModel", za]], ["llama", ["LlamaModel", Sa]], ["phi", ["PhiModel", Fa]], ["mpt", ["MptModel", Na]], ["opt", ["OPTModel", Da]], ["mistral", ["MistralModel", kc]], ["falcon", ["FalconModel", Ac]]]), $c = new Map([["speecht5", ["SpeechT5ForSpeechToText", pc]], ["whisper", ["WhisperForConditionalGeneration", Ko]]]), Dc = new Map([["speecht5", ["SpeechT5ForTextToSpeech", mc]]]), jc = new Map([["vits", ["VitsModel", Pc]]]), qc = new Map([["bert", ["BertForSequenceClassification", Nr]], ["roformer", ["RoFormerForSequenceClassification", Gr]], ["electra", ["ElectraForSequenceClassification", si]], ["esm", ["EsmForSequenceClassification", Fi]], ["convbert", ["ConvBertForSequenceClassification", Hr]], ["camembert", ["CamembertForSequenceClassification", li]], ["deberta", ["DebertaForSequenceClassification", fi]], ["deberta-v2", ["DebertaV2ForSequenceClassification", xi]], ["mpnet", ["MPNetForSequenceClassification", ji]], ["albert", ["AlbertForSequenceClassification", Ji]], ["distilbert", ["DistilBertForSequenceClassification", Mi]], ["roberta", ["RobertaForSequenceClassification", So]], ["xlm", ["XLMForSequenceClassification", Bo]], ["xlm-roberta", ["XLMRobertaForSequenceClassification", Do]], ["bart", ["BartForSequenceClassification", fo]], ["mbart", ["MBartForSequenceClassification", wo]], ["mobilebert", ["MobileBertForSequenceClassification", Oi]], ["squeezebert", ["SqueezeBertForSequenceClassification", Xi]]]), Gc = new Map([["bert", ["BertForTokenClassification", Ur]], ["roformer", ["RoFormerForTokenClassification", Wr]], ["electra", ["ElectraForTokenClassification", ni]], ["esm", ["EsmForTokenClassification", Li]], ["convbert", ["ConvBertForTokenClassification", Qr]], ["camembert", ["CamembertForTokenClassification", ci]], ["deberta", ["DebertaForTokenClassification", pi]], ["deberta-v2", ["DebertaV2ForTokenClassification", ki]], ["mpnet", ["MPNetForTokenClassification", qi]], ["distilbert", ["DistilBertForTokenClassification", zi]], ["roberta", ["RobertaForTokenClassification", Co]], ["xlm", ["XLMForTokenClassification", Ro]], ["xlm-roberta", ["XLMRobertaForTokenClassification", jo]]]), Wc = new Map([["t5", ["T5ForConditionalGeneration", no]], ["longt5", ["LongT5ForConditionalGeneration", oo]], ["mt5", ["MT5ForConditionalGeneration", co]], ["bart", ["BartForConditionalGeneration", _o]], ["mbart", ["MBartForConditionalGeneration", go]], ["marian", ["MarianMTModel", Ql]], ["m2m_100", ["M2M100ForConditionalGeneration", ec]], ["blenderbot", ["BlenderbotForConditionalGeneration", bo]], ["blenderbot-small", ["BlenderbotSmallForConditionalGeneration", Mo]]]), Yc = new Map([["bloom", ["BloomForCausalLM", Ra]], ["gpt2", ["GPT2LMHeadModel", ua]], ["gptj", ["GPTJForCausalLM", ka]], ["gpt_bigcode", ["GPTBigCodeForCausalLM", Aa]], ["gpt_neo", ["GPTNeoForCausalLM", pa]], ["gpt_neox", ["GPTNeoXForCausalLM", wa]], ["codegen", ["CodeGenForCausalLM", Ea]], ["llama", ["LlamaForCausalLM", Ca]], ["phi", ["PhiForCausalLM", La]], ["mpt", ["MptForCausalLM", Ua]], ["opt", ["OPTForCausalLM", ja]], ["mbart", ["MBartForCausalLM", yo]], ["mistral", ["MistralForCausalLM", bc]], ["falcon", ["FalconForCausalLM", Mc]], ["trocr", ["TrOCRForCausalLM", yc]]]), Vc = new Map([["bert", ["BertForMaskedLM", Or]], ["roformer", ["RoFormerForMaskedLM", qr]], ["electra", ["ElectraForMaskedLM", ti]], ["esm", ["EsmForMaskedLM", Pi]], ["convbert", ["ConvBertForMaskedLM", Kr]], ["camembert", ["CamembertForMaskedLM", ai]], ["deberta", ["DebertaForMaskedLM", _i]], ["deberta-v2", ["DebertaV2ForMaskedLM", yi]], ["mpnet", ["MPNetForMaskedLM", Di]], ["albert", ["AlbertForMaskedLM", eo]], ["distilbert", ["DistilBertForMaskedLM", Ti]], ["roberta", ["RobertaForMaskedLM", To]], ["xlm", ["XLMWithLMHeadModel", Io]], ["xlm-roberta", ["XLMRobertaForMaskedLM", $o]], ["mobilebert", ["MobileBertForMaskedLM", Ri]], ["squeezebert", ["SqueezeBertForMaskedLM", Vi]]]), Xc = new Map([["bert", ["BertForQuestionAnswering", $r]], ["roformer", ["RoFormerForQuestionAnswering", Yr]], ["electra", ["ElectraForQuestionAnswering", ri]], ["convbert", ["ConvBertForQuestionAnswering", Jr]], ["camembert", ["CamembertForQuestionAnswering", hi]], ["deberta", ["DebertaForQuestionAnswering", mi]], ["deberta-v2", ["DebertaV2ForQuestionAnswering", bi]], ["mpnet", ["MPNetForQuestionAnswering", Gi]], ["albert", ["AlbertForQuestionAnswering", Zi]], ["distilbert", ["DistilBertForQuestionAnswering", Ei]], ["roberta", ["RobertaForQuestionAnswering", Po]], ["xlm", ["XLMForQuestionAnswering", Oo]], ["xlm-roberta", ["XLMRobertaForQuestionAnswering", qo]], ["mobilebert", ["MobileBertForQuestionAnswering", Ni]], ["squeezebert", ["SqueezeBertForQuestionAnswering", Ki]]]), Kc = new Map([["vision-encoder-decoder", ["VisionEncoderDecoderModel", Ho]]]), Hc = new Map([["vision-encoder-decoder", ["VisionEncoderDecoderModel", Ho]]]), Qc = new Map([["vit", ["ViTForImageClassification", Wa]], ["mobilevit", ["MobileViTForImageClassification", Ha]], ["beit", ["BeitForImageClassification", sl]], ["deit", ["DeiTForImageClassification", pl]], ["convnext", ["ConvNextForImageClassification", Bl]], ["convnextv2", ["ConvNextV2ForImageClassification", Nl]], ["dinov2", ["Dinov2ForImageClassification", Dl]], ["resnet", ["ResNetForImageClassification", wl]], ["swin", ["SwinForImageClassification", kl]], ["segformer", ["SegformerForImageClassification", Ic]]]), Jc = new Map([["detr", ["DetrForObjectDetection", il]], ["table-transformer", ["TableTransformerForObjectDetection", dl]], ["yolos", ["YolosForObjectDetection", Gl]]]), Zc = new Map([["owlvit", ["OwlViTForObjectDetection", Za]]]), eh = new Map([["detr", ["DetrForSegmentation", ol]], ["clipseg", ["CLIPSegForImageSegmentation", ca]]]), th = new Map([["segformer", ["SegformerForSemanticSegmentation", Bc]]]), sh = new Map([["sam", ["SamModel", Vl]]]), nh = new Map([["wav2vec2", ["Wav2Vec2ForCTC", nc]], ["wavlm", ["WavLMForCTC", dc]], ["hubert", ["HubertForCTC", ac]]]), rh = new Map([["wav2vec2", ["Wav2Vec2ForSequenceClassification", rc]], ["wavlm", ["WavLMForSequenceClassification", uc]], ["hubert", ["HubertForSequenceClassification", lc]], ["audio-spectrogram-transformer", ["ASTForAudioClassification", Yo]]]), ih = new Map([["vitmatte", ["VitMatteForImageMatting", Va]]]), oh = new Map([["swin2sr", ["Swin2SRForImageSuperResolution", Al]]]), ah = new Map([["dpt", ["DPTForDepthEstimation", El]], ["glpn", ["GLPNForDepthEstimation", Cl]]]), lh = [[Oc, ar], [Nc, lr], [Uc, dr], [qc, ar], [Gc, ar], [Wc, cr], [$c, cr], [Yc, dr], [Vc, ar], [Xc, ar], [Kc, hr], [Qc, ar], [eh, ar], [th, ar], [ih, ar], [oh, ar], [ah, ar], [Jc, ar], [Zc, ar], [sh, ur], [nh, ar], [rh, ar], [Dc, cr], [jc, ar]]; for (const [e, t] of lh) for (const [s, n] of e.values()) _r.set(s, t), pr.set(n, s), fr.set(s, n); const ch = [["CLIPTextModelWithProjection", Zo, ar], ["CLIPVisionModelWithProjection", ea, ar], ["SiglipTextModel", na, ar], ["SiglipVisionModel", ra, ar], ["ClapTextModelWithProjection", Tc, ar], ["ClapAudioModelWithProjection", Sc, ar]]; for (const [e, t, s] of ch) _r.set(e, s), pr.set(t, e), fr.set(e, t); class hh extends Rc { static MODEL_CLASS_MAPPINGS = lh.map((e => e[0])); static BASE_IF_FAIL = !0 } class dh extends Rc { static MODEL_CLASS_MAPPINGS = [qc] } class uh extends Rc { static MODEL_CLASS_MAPPINGS = [Gc] } class _h extends Rc { static MODEL_CLASS_MAPPINGS = [Wc] } class fh extends Rc { static MODEL_CLASS_MAPPINGS = [$c] } class ph extends Rc { static MODEL_CLASS_MAPPINGS = [Dc] } class mh extends Rc { static MODEL_CLASS_MAPPINGS = [jc] } class gh extends Rc { static MODEL_CLASS_MAPPINGS = [Yc] } class wh extends Rc { static MODEL_CLASS_MAPPINGS = [Vc] } class yh extends Rc { static MODEL_CLASS_MAPPINGS = [Xc] } class xh extends Rc { static MODEL_CLASS_MAPPINGS = [Kc] } class kh extends Rc { static MODEL_CLASS_MAPPINGS = [Qc] } class bh extends Rc { static MODEL_CLASS_MAPPINGS = [eh] } class vh extends Rc { static MODEL_CLASS_MAPPINGS = [th] } class Ah extends Rc { static MODEL_CLASS_MAPPINGS = [Jc] } class Mh extends Rc { static MODEL_CLASS_MAPPINGS = [Zc] } class zh extends Rc { static MODEL_CLASS_MAPPINGS = [sh] } class Eh extends Rc { static MODEL_CLASS_MAPPINGS = [nh] } class Th extends Rc { static MODEL_CLASS_MAPPINGS = [rh] } class Sh extends Rc { static MODEL_CLASS_MAPPINGS = [Hc] } class Ch extends Rc { static MODEL_CLASS_MAPPINGS = [ih] } class Ph extends Rc { static MODEL_CLASS_MAPPINGS = [oh] } class Fh extends Rc { static MODEL_CLASS_MAPPINGS = [ah] } class Lh extends Lr { constructor({ logits: e, past_key_values: t, encoder_outputs: s, decoder_attentions: n = null, cross_attentions: r = null }) { super(), this.logits = e, this.past_key_values = t, this.encoder_outputs = s, this.decoder_attentions = n, this.cross_attentions = r } } class Ih extends Lr { constructor({ logits: e }) { super(), this.logits = e } } class Bh extends Lr { constructor({ logits: e }) { super(), this.logits = e } } class Rh extends Lr { constructor({ logits: e }) { super(), this.logits = e } } class Oh extends Lr { constructor({ start_logits: e, end_logits: t }) { super(), this.start_logits = e, this.end_logits = t } } class Nh extends Lr { constructor({ logits: e }) { super(), this.logits = e } } class Uh extends Lr { constructor({ logits: e, past_key_values: t }) { super(), this.logits = e, this.past_key_values = t } } class $h extends Lr { constructor({ alphas: e }) { super(), this.alphas = e } } class Dh extends Lr { constructor({ waveform: e, spectrogram: t }) { super(), this.waveform = e, this.spectrogram = t } } const jh = "undefined" != typeof self, qh = jh && "DedicatedWorkerGlobalScope" === self.constructor.name; let Gh, Wh, Yh; if (jh) Gh = (e, t) => { if (!self.OffscreenCanvas) throw new Error("OffscreenCanvas not supported by this browser."); return new self.OffscreenCanvas(e, t) }, Yh = self.createImageBitmap, Wh = self.ImageData; else { if (!Ie) throw new Error("Unable to load image processing library."); Yh = async e => { const t = (await e.metadata()).channels; let { data: s, info: n } = await e.raw().toBuffer({ resolveWithObject: !0 }); const r = new Kh(new Uint8ClampedArray(s), n.width, n.height, n.channels); return void 0 !== t && t !== n.channels && r.convert(t), r } } const Vh = { 0: "nearest", 1: "lanczos", 2: "bilinear", 3: "bicubic", 4: "box", 5: "hamming" }, Xh = new Map([["png", "image/png"], ["jpg", "image/jpeg"], ["jpeg", "image/jpeg"], ["gif", "image/gif"]]); class Kh { constructor(e, t, s, n) { this.data = e, this.width = t, this.height = s, this.channels = n } get size() { return [this.width, this.height] } static async read(e) { if (e instanceof Kh) return e; if ("string" == typeof e || e instanceof URL) return await this.fromURL(e); throw new Error("Unsupported input type: " + typeof e) } static async fromURL(e) { let t = await Je(e); if (200 !== t.status) throw new Error(`Unable to read image from "${e}" (${t.status} ${t.statusText})`); let s = await t.blob(); return this.fromBlob(s) } static async fromBlob(e) { if (jh) { let t = await Yh(e); const s = Gh(t.width, t.height).getContext("2d"); return s.drawImage(t, 0, 0), new this(s.getImageData(0, 0, t.width, t.height).data, t.width, t.height, 4) } { let t = Ie(await e.arrayBuffer()); return await Yh(t) } } static fromTensor(e, t = "CHW") { if (3 !== e.dims.length) throw new Error(`Tensor should have 3 dimensions, but has ${e.dims.length} dimensions.`); if ("CHW" === t) e = e.transpose(1, 2, 0); else if ("HWC" !== t) throw new Error(`Unsupported channel format: ${t}`); if (!(e.data instanceof Uint8ClampedArray || e.data instanceof Uint8Array)) throw new Error(`Unsupported tensor type: ${e.type}`); switch (e.dims[2]) { case 1: case 2: case 3: case 4: return new Kh(e.data, e.dims[1], e.dims[0], e.dims[2]); default: throw new Error(`Unsupported number of channels: ${e.dims[2]}`) } } grayscale() { if (1 === this.channels) return this; let e = new Uint8ClampedArray(this.width * this.height * 1); switch (this.channels) { case 3: case 4: for (let t = 0, s = 0; t < this.data.length; t += this.channels) { const n = this.data[t], r = this.data[t + 1], i = this.data[t + 2]; e[s++] = Math.round(.2989 * n + .587 * r + .114 * i) } break; default: throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`) }return this._update(e, this.width, this.height, 1) } rgb() { if (3 === this.channels) return this; let e = new Uint8ClampedArray(this.width * this.height * 3); switch (this.channels) { case 1: for (let t = 0, s = 0; t < this.data.length; ++t)e[s++] = this.data[t], e[s++] = this.data[t], e[s++] = this.data[t]; break; case 4: for (let t = 0, s = 0; t < this.data.length; t += 4)e[s++] = this.data[t], e[s++] = this.data[t + 1], e[s++] = this.data[t + 2]; break; default: throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`) }return this._update(e, this.width, this.height, 3) } rgba() { if (4 === this.channels) return this; let e = new Uint8ClampedArray(this.width * this.height * 4); switch (this.channels) { case 1: for (let t = 0, s = 0; t < this.data.length; ++t)e[s++] = this.data[t], e[s++] = this.data[t], e[s++] = this.data[t], e[s++] = 255; break; case 3: for (let t = 0, s = 0; t < this.data.length; t += 3)e[s++] = this.data[t], e[s++] = this.data[t + 1], e[s++] = this.data[t + 2], e[s++] = 255; break; default: throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`) }return this._update(e, this.width, this.height, 4) } async resize(e, t, { resample: s = 2 } = {}) { let n = Vh[s] ?? s; if (jh) { let s = this.channels, n = this.toCanvas(); const r = Gh(e, t).getContext("2d"); return r.drawImage(n, 0, 0, e, t), new Kh(r.getImageData(0, 0, e, t).data, e, t, 4).convert(s) } { let s = this.toSharp(); switch (n) { case "box": case "hamming": "box" !== n && "hamming" !== n || (console.warn(`Resampling method ${n} is not yet supported. Using bilinear instead.`), n = "bilinear"); case "nearest": case "bilinear": case "bicubic": s = s.affine([e / this.width, 0, 0, t / this.height], { interpolator: n }); break; case "lanczos": s = s.resize({ width: e, height: t, fit: "fill", kernel: "lanczos3" }); break; default: throw new Error(`Resampling method ${n} is not supported.`) }return await Yh(s) } } async pad([e, t, s, n]) { if (e = Math.max(e, 0), t = Math.max(t, 0), s = Math.max(s, 0), n = Math.max(n, 0), 0 === e && 0 === t && 0 === s && 0 === n) return this; if (jh) { let r = this.channels, i = this.toCanvas(), o = this.width + e + t, a = this.height + s + n; const l = Gh(o, a).getContext("2d"); return l.drawImage(i, 0, 0, this.width, this.height, e, s, o, a), new Kh(l.getImageData(0, 0, o, a).data, o, a, 4).convert(r) } { let r = this.toSharp().extend({ left: e, right: t, top: s, bottom: n }); return await Yh(r) } } async crop([e, t, s, n]) { if (e = Math.max(e, 0), t = Math.max(t, 0), s = Math.min(s, this.width - 1), n = Math.min(n, this.height - 1), 0 === e && 0 === t && s === this.width - 1 && n === this.height - 1) return this; const r = s - e + 1, i = n - t + 1; if (jh) { const s = this.channels, n = this.toCanvas(), o = Gh(r, i).getContext("2d"); o.drawImage(n, e, t, r, i, 0, 0, r, i); return new Kh(o.getImageData(0, 0, r, i).data, r, i, 4).convert(s) } { const s = this.toSharp().extract({ left: e, top: t, width: r, height: i }); return await Yh(s) } } async center_crop(e, t) { if (this.width === e && this.height === t) return this; let s = (this.width - e) / 2, n = (this.height - t) / 2; if (jh) { let r = this.channels, i = this.toCanvas(); const o = Gh(e, t).getContext("2d"); let a = 0, l = 0, c = 0, h = 0; return s >= 0 ? a = s : c = -s, n >= 0 ? l = n : h = -n, o.drawImage(i, a, l, e, t, c, h, e, t), new Kh(o.getImageData(0, 0, e, t).data, e, t, 4).convert(r) } { let r = this.toSharp(); if (s >= 0 && n >= 0) r = r.extract({ left: Math.floor(s), top: Math.floor(n), width: e, height: t }); else if (s <= 0 && n <= 0) { let i = Math.floor(-n), o = Math.floor(-s); r = r.extend({ top: i, left: o, right: e - this.width - o, bottom: t - this.height - i }) } else { let i = [0, 0], o = 0; n < 0 ? (i[0] = Math.floor(-n), i[1] = t - this.height - i[0]) : o = Math.floor(n); let a = [0, 0], l = 0; s < 0 ? (a[0] = Math.floor(-s), a[1] = e - this.width - a[0]) : l = Math.floor(s), r = r.extend({ top: i[0], bottom: i[1], left: a[0], right: a[1] }).extract({ left: l, top: o, width: e, height: t }) } return await Yh(r) } } async toBlob(e = "image/png", t = 1) { if (!jh) throw new Error("toBlob() is only supported in browser environments."); const s = this.toCanvas(); return await s.convertToBlob({ type: e, quality: t }) } toCanvas() { if (!jh) throw new Error("toCanvas() is only supported in browser environments."); let e = this.clone().rgba(), t = Gh(e.width, e.height), s = new Wh(e.data, e.width, e.height); return t.getContext("2d").putImageData(s, 0, 0), t } _update(e, t, s, n = null) { return this.data = e, this.width = t, this.height = s, null !== n && (this.channels = n), this } clone() { return new Kh(this.data.slice(), this.width, this.height, this.channels) } convert(e) { if (this.channels === e) return this; switch (e) { case 1: this.grayscale(); break; case 3: this.rgb(); break; case 4: this.rgba(); break; default: throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`) }return this } async save(e) { if (!jh) { if (Xe.useFS) { const t = this.toSharp(); return await t.toFile(e) } throw new Error("Unable to save the image because filesystem is disabled in this environment.") } { if (qh) throw new Error("Unable to save an image from a Web Worker."); const t = e.split(".").pop().toLowerCase(), s = Xh.get(t) ?? "image/png", n = await this.toBlob(s), r = URL.createObjectURL(n), i = document.createElement("a"); i.href = r, i.download = e, i.click(), i.remove() } } toSharp() { if (jh) throw new Error("toSharp() is only supported in server-side environments."); return Ie(this.data, { raw: { width: this.width, height: this.height, channels: this.channels } }) } } async function Hh(e, t) { if ("undefined" == typeof AudioContext) throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing."); const s = await (await Je(e)).arrayBuffer(), n = new AudioContext({ sampleRate: t }); void 0 === t && console.warn(`No sampling rate provided, using default of ${n.sampleRate}Hz.`); const r = await n.decodeAudioData(s); let i; if (2 === r.numberOfChannels) { const e = Math.sqrt(2), t = r.getChannelData(0), s = r.getChannelData(1); i = new Float32Array(t.length); for (let n = 0; n < r.length; ++n)i[n] = e * (t[n] + s[n]) / 2 } else i = r.getChannelData(0); return i } function Qh(e) { if (e < 1) return new Float64Array; if (1 === e) return new Float64Array([1]); const t = e - 1, s = Math.PI / t, n = new Float64Array(e); for (let r = 0; r < e; ++r) { const e = 2 * r - t; n[r] = .5 + .5 * Math.cos(s * e) } return n } const Jh = { htk: e => 2595 * Math.log10(1 + e / 700), kaldi: e => 1127 * Math.log(1 + e / 700), slaney: (e, t = 1e3, s = 15, n = 27 / Math.log(6.4)) => e >= t ? s + Math.log(e / t) * n : 3 * e / 200 }; function Zh(e, t = "htk") { const s = Jh[t]; if (!s) throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".'); return "number" == typeof e ? s(e) : e.map((e => s(e))) } const ed = { htk: e => 700 * (10 ** (e / 2595) - 1), kaldi: e => 700 * (Math.exp(e / 1127) - 1), slaney: (e, t = 1e3, s = 15, n = Math.log(6.4) / 27) => e >= s ? t * Math.exp(n * (e - s)) : 200 * e / 3 }; function td(e, t, s) { const n = (t - e) / (s - 1); return Float64Array.from({ length: s }, ((t, s) => e + n * s)) } function sd(e, t, s, n, r, i = null, o = "htk", a = !1) { if (null !== i && "slaney" !== i) throw new Error('norm must be one of null or "slaney"'); const l = td(Zh(s, o), Zh(n, o), t + 2); let c, h = function (e, t = "htk") { const s = ed[t]; if (!s) throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".'); return "number" == typeof e ? s(e) : e.map((e => s(e))) }(l, o); if (a) { const t = r / (2 * e); c = Zh(Float64Array.from({ length: e }, ((e, s) => s * t)), o), h = l } else c = td(0, Math.floor(r / 2), e); const d = function (e, t) { const s = Float64Array.from({ length: t.length - 1 }, ((e, s) => t[s + 1] - t[s])), n = Array.from({ length: e.length }, (() => new Array(t.length))); for (let s = 0; s < e.length; ++s) { const r = n[s]; for (let n = 0; n < t.length; ++n)r[n] = t[n] - e[s] } const r = t.length - 2, i = Array.from({ length: r }, (() => new Array(e.length))); for (let t = 0; t < e.length; ++t) { const e = n[t]; for (let n = 0; n < r; ++n) { const r = -e[n] / s[n], o = e[n + 2] / s[n + 1]; i[n][t] = Math.max(0, Math.min(r, o)) } } return i }(c, h); if (null !== i && "slaney" === i) for (let s = 0; s < t; ++s) { const t = d[s], n = 2 / (h[s + 2] - h[s]); for (let s = 0; s < e; ++s)t[s] *= n } return d } function nd(e, t, s, n, r) { if (s <= 0) throw new Error("reference must be greater than zero"); if (n <= 0) throw new Error("min_value must be greater than zero"); s = Math.max(n, s); const i = Math.log10(s); for (let s = 0; s < e.length; ++s)e[s] = t * Math.log10(Math.max(n, e[s]) - i); if (null !== r) { if (r <= 0) throw new Error("db_range must be greater than zero"); const t = _t(e)[0] - r; for (let s = 0; s < e.length; ++s)e[s] = Math.max(e[s], t) } return e } function rd(e, t, s, n, { fft_length: r = null, power: i = 1, center: o = !0, pad_mode: a = "reflect", onesided: l = !0, preemphasis: c = null, mel_filters: h = null, mel_floor: u = 1e-10, log_mel: _ = null, reference: f = 1, min_value: p = 1e-10, db_range: m = null, remove_dc_offset: g = null, max_num_frames: w = null, do_pad: y = !0, transpose: x = !1 } = {}) { const k = t.length; if (null === r && (r = s), s > r) throw Error(`frame_length (${s}) may not be larger than fft_length (${r})`); if (k !== s) throw new Error(`Length of the window (${k}) must equal frame_length (${s})`); if (n <= 0) throw new Error("hop_length must be greater than zero"); if (o) { if ("reflect" !== a) throw new Error(`pad_mode="${a}" not implemented yet.`); const t = Math.floor((r - 1) / 2) + 1; e = function (e, t, s) { const n = new e.constructor(e.length + t + s), r = e.length - 1; for (let s = 0; s < e.length; ++s)n[t + s] = e[s]; for (let s = 1; s <= t; ++s)n[t - s] = e[d(s, r)]; for (let i = 1; i <= s; ++i)n[r + t + i] = e[d(r - i, r)]; return n }(e, t, t) } const b = Math.floor(1 + Math.floor((e.length - s) / n)), v = l ? Math.floor(r / 2) + 1 : r; let A = b, M = b; null !== w && (w > b ? y && (M = w) : M = A = w); const z = new gt(r), E = new Float64Array(r), T = new Float64Array(z.outputBufferSize), S = new Array(A); for (let r = 0; r < A; ++r) { const i = r * n; for (let t = 0; t < s; ++t)E[t] = e[i + t]; if (g) { let e = 0; for (let t = 0; t < s; ++t)e += E[t]; const t = e / s; for (let e = 0; e < s; ++e)E[e] -= t } if (null !== c) { for (let e = s - 1; e >= 1; --e)E[e] -= c * E[e - 1]; E[0] *= 1 - c } for (let e = 0; e < t.length; ++e)E[e] *= t[e]; z.realTransform(T, E); const o = new Array(v); for (let e = 0; e < o.length; ++e) { const t = e << 1; o[e] = T[t] ** 2 + T[t + 1] ** 2 } S[r] = o } if (null !== i && 2 !== i) { const e = 2 / i; for (let t = 0; t < S.length; ++t) { const s = S[t]; for (let t = 0; t < s.length; ++t)s[t] **= e } } const C = h.length, P = new Float32Array(C * M), F = x ? [M, C] : [C, M]; for (let e = 0; e < C; ++e) { const t = h[e]; for (let s = 0; s < A; ++s) { const n = S[s]; let r = 0; for (let e = 0; e < v; ++e)r += t[e] * n[e]; P[x ? s * C + e : e * A + s] = Math.max(u, r) } } if (null !== i && null !== _) { const e = Math.min(P.length, A * C); switch (_) { case "log": for (let t = 0; t < e; ++t)P[t] = Math.log(P[t]); break; case "log10": for (let t = 0; t < e; ++t)P[t] = Math.log10(P[t]); break; case "dB": if (1 === i) !function (e, t = 1, s = 1e-5, n = null) { nd(e, 20, t, s, n) }(P, f, p, m); else { if (2 !== i) throw new Error(`Cannot use log_mel option '${_}' with power ${i}`); !function (e, t = 1, s = 1e-10, n = null) { nd(e, 10, t, s, n) }(P, f, p, m) } break; default: throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${_}'`) } } return { data: P, dims: F } } function id(e, t, { periodic: s = !0, frame_length: n = null, center: r = !0 } = {}) { const i = s ? e + 1 : e; let o; switch (t) { case "boxcar": o = new Float64Array(i).fill(1); break; case "hann": case "hann_window": o = Qh(i); break; default: throw new Error(`Unknown window type ${t}.`) }if (s && (o = o.subarray(0, e)), null === n) return o; if (e > n) throw new Error(`Length of the window (${e}) may not be larger than frame_length (${n})`); return o } function od([e, t, s, n]) { return [e - s / 2, t - n / 2, e + s / 2, t + n / 2] } function ad(e, t = .5, s = null, n = !1) { const r = e.logits, i = e.pred_boxes, [o, a, l] = r.dims; if (null !== s && s.length !== o) throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits"); let c = []; for (let e = 0; e < o; ++e) { let o = null !== s ? s[e] : null, h = { boxes: [], classes: [], scores: [] }, d = r[e], u = i[e]; for (let e = 0; e < a; ++e) { let s, r = d[e], i = []; if (n) { s = r.sigmoid().data; for (let e = 0; e < s.length; ++e)s[e] > t && i.push(e) } else { let e = _t(r.data)[1]; if (e === l - 1) continue; i.push(e), s = ot(r.data) } for (const t of i) { let n = u[e].data; n = od(n), null !== o && (n = n.map(((e, t) => e * o[(t + 1) % 2]))), h.boxes.push(n), h.classes.push(t), h.scores.push(s[t]) } } c.push(h) } return c } function ld(e, t) { if (!(e instanceof Float32Array || e instanceof Float64Array)) throw new Error(`${t} expects input to be a Float32Array or a Float64Array, but got ${e?.constructor?.name ?? typeof e} instead.If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`) } class cd extends i { constructor(e) { super(), this.config = e } } class hd extends cd { constructor(e) { super(e), this.image_mean = this.config.image_mean ?? this.config.mean, this.image_std = this.config.image_std ?? this.config.std, this.resample = this.config.resample ?? 2, this.do_rescale = this.config.do_rescale ?? !0, this.rescale_factor = this.config.rescale_factor ?? 1 / 255, this.do_normalize = this.config.do_normalize, this.do_resize = this.config.do_resize, this.do_thumbnail = this.config.do_thumbnail, this.size = this.config.size, this.size_divisibility = this.config.size_divisibility ?? this.config.size_divisor, this.do_center_crop = this.config.do_center_crop, this.crop_size = this.config.crop_size, this.do_convert_rgb = this.config.do_convert_rgb ?? !0, this.do_crop_margin = this.config.do_crop_margin, this.pad_size = this.config.pad_size, this.do_pad = this.config.do_pad, this.do_pad && !this.pad_size && this.size && void 0 !== this.size.width && void 0 !== this.size.height && (this.pad_size = this.size) } async thumbnail(e, t, s = 2) { const n = e.height, r = e.width, i = t.height, o = t.width; let a = Math.min(n, i), l = Math.min(r, o); return a === n && l === r ? e : (n > r ? l = Math.floor(r * a / n) : r > n && (a = Math.floor(n * l / r)), await e.resize(l, a, { resample: s })) } async crop_margin(e, t = 200) { const s = e.clone().grayscale(), n = ut(s.data)[0], r = _t(s.data)[0] - n; if (0 === r) return e; const i = t / 255; let o = s.width, a = s.height, l = 0, c = 0; for (let e = 0; e < s.height; ++e) { const t = e * s.width; for (let h = 0; h < s.width; ++h)(s.data[t + h] - n) / r < i && (o = Math.min(o, h), a = Math.min(a, e), l = Math.max(l, h), c = Math.max(c, e)) } return e = await e.crop([o, a, l, c]) } pad_image(e, t, s, { mode: n = "constant", center: r = !1, constant_values: i = 0 } = {}) { const [o, a, l] = t; let c, h; if ("number" == typeof s ? (c = s, h = s) : (c = s.width, h = s.height), c !== o || h !== a) { const s = new Float32Array(c * h * l); if (Array.isArray(i)) for (let e = 0; e < s.length; ++e)s[e] = i[e % l]; else 0 !== i && s.fill(i); const [u, _] = r ? [Math.floor((c - o) / 2), Math.floor((h - a) / 2)] : [0, 0]; for (let t = 0; t < a; ++t) { const n = (t + _) * c, r = t * o; for (let t = 0; t < o; ++t) { const i = (n + t + u) * l, o = (r + t) * l; for (let t = 0; t < l; ++t)s[i + t] = e[o + t] } } if ("symmetric" === n) { if (r) throw new Error("`center` padding is not supported when `mode` is set to `symmetric`."); const t = a - 1, n = o - 1; for (let r = 0; r < h; ++r) { const i = r * c, h = d(r, t) * o; for (let t = 0; t < c; ++t) { if (r < a && t < o) continue; const c = (i + t) * l, u = (h + d(t, n)) * l; for (let t = 0; t < l; ++t)s[c + t] = e[u + t] } } } e = s, t = [h, c, l] } return [e, t] } rescale(e) { for (let t = 0; t < e.length; ++t)e[t] = this.rescale_factor * e[t] } get_resize_output_image_size(e, t) { const [s, n] = e.size; let r, i; if (this.do_thumbnail) { const { height: e, width: s } = t; r = Math.min(e, s) } else Number.isInteger(t) ? (r = t, i = this.config.max_size ?? r) : void 0 !== t && (r = t.shortest_edge, i = t.longest_edge); if (void 0 !== r || void 0 !== i) { const e = void 0 === r ? 1 : Math.max(r / s, r / n), t = s * e, o = n * e, a = void 0 === i ? 1 : Math.min(i / t, i / o); return [Math.floor(Number((t * a).toFixed(2))), Math.floor(Number((o * a).toFixed(2)))] } if (void 0 !== t && void 0 !== t.width && void 0 !== t.height) return [t.width, t.height]; if (void 0 !== this.size_divisibility) { return [Math.floor(s / this.size_divisibility) * this.size_divisibility, Math.floor(n / this.size_divisibility) * this.size_divisibility] } throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(t)}`) } async resize(e) { const [t, s] = this.get_resize_output_image_size(e, this.size); return await e.resize(t, s, { resample: this.resample }) } async preprocess(e, { do_normalize: t = null, do_pad: s = null, do_convert_rgb: n = null, do_convert_grayscale: r = null } = {}) { this.do_crop_margin && (e = await this.crop_margin(e)); const [i, o] = e.size; if (n ?? this.do_convert_rgb ? e = e.rgb() : r && (e = e.grayscale()), this.do_resize && (e = await this.resize(e)), this.do_thumbnail && (e = await this.thumbnail(e, this.size, this.resample)), this.do_center_crop) { let t, s; Number.isInteger(this.crop_size) ? (t = this.crop_size, s = this.crop_size) : (t = this.crop_size.width, s = this.crop_size.height), e = await e.center_crop(t, s) } const a = [e.height, e.width]; let l = Float32Array.from(e.data), c = [e.height, e.width, e.channels]; if (this.do_rescale && this.rescale(l), t ?? this.do_normalize) { let t = this.image_mean; Array.isArray(this.image_mean) || (t = new Array(e.channels).fill(t)); let s = this.image_std; if (Array.isArray(this.image_std) || (s = new Array(e.channels).fill(t)), t.length !== e.channels || s.length !== e.channels) throw new Error(`When set to arrays, the length of \`image_mean\` (${t.length}) and \`image_std\` (${s.length}) must match the number of channels in the image (${e.channels}).`); for (let t = 0; t < l.length; t += e.channels)for (let s = 0; s < e.channels; ++s)l[t + s] = (l[t + s] - this.image_mean[s]) / this.image_std[s] } if (s ?? (this.do_pad && this.pad_size)) { const t = this.pad_image(l, [e.width, e.height, e.channels], this.pad_size);[l, c] = t } return { original_size: [o, i], reshaped_input_size: a, pixel_values: vt(new bt("float32", l, c), [2, 0, 1]) } } async _call(e, ...t) { Array.isArray(e) || (e = [e]); const s = await Promise.all(e.map((e => this.preprocess(e)))); return { pixel_values: Ct(s.map((e => e.pixel_values)), 0), original_sizes: s.map((e => e.original_size)), reshaped_input_sizes: s.map((e => e.reshaped_input_size)) } } } class dd extends hd { post_process_semantic_segmentation(e, t = null) { const s = e.logits, n = s.dims[0]; if (null !== t && t.length !== n) throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits"); const r = []; for (let e = 0; e < n; ++e) { const n = null !== t ? t[e] : null; let i = s[e]; null !== n && (i = At(i, n, "bilinear", !1)); const [o, a] = n ?? i.dims.slice(-2), l = new bt("int32", new Int32Array(o * a), [o, a]), c = i[0].data; for (let e = 1; e < i.dims[0]; ++e) { const t = i[e].data; for (let s = 0; s < t.length; ++s)t[s] > c[s] && (c[s] = t[s], l.data[s] = e) } const h = new Array(i.dims[0]), d = l.data; for (let e = 0; e < d.length; ++e) { const t = d[e]; h[t] = t } const u = h.filter((e => void 0 !== e)); r.push({ segmentation: l, labels: u }) } return r } } class ud extends hd { } class _d extends hd { } class fd extends hd { } class pd extends hd { } class md extends hd { } class gd extends hd { } class wd extends hd { constructor(e) { super(e), this.crop_pct = this.config.crop_pct ?? .875 } async resize(e) { const t = this.size?.shortest_edge; if (void 0 === t) throw new Error("Size dictionary must contain 'shortest_edge' key."); if (t < 384) { const s = Math.floor(t / this.crop_pct), [n, r] = this.get_resize_output_image_size(e, { shortest_edge: s }); e = await e.resize(n, r, { resample: this.resample }), e = await e.center_crop(t, t) } else e = await e.resize(t, t, { resample: this.resample }); return e } } class yd extends wd { } class xd extends hd { } class kd extends hd { } class bd extends hd { } class vd extends hd { post_process_object_detection(...e) { return ad(...e) } } class Ad extends hd { } class Md extends hd { } class zd extends hd { pad_image(e, t, s, n = {}) { const [r, i, o] = t; let a = this.image_mean; Array.isArray(this.image_mean) || (a = new Array(o).fill(a)); let l = this.image_std; Array.isArray(l) || (l = new Array(o).fill(a)); const c = a.map(((e, t) => -e / this.image_std[t])); return super.pad_image(e, t, s, { center: !0, constant_values: c, ...n }) } } class Ed extends zd { } class Td extends hd { async _call(e) { const t = await super._call(e), s = [t.pixel_values.dims[0], 64, 64], n = new bt("int64", new BigInt64Array(s.reduce(((e, t) => e * t))).fill(1n), s); return { ...t, pixel_mask: n } } post_process_object_detection(...e) { return ad(...e) } remove_low_and_no_objects(e, t, s, n) { let r = [], i = [], o = []; for (let a = 0; a < e.dims[0]; ++a) { let l = e[a], c = t[a], h = _t(l.data)[1]; if (h === n) continue; let d = ot(l.data)[h]; d > s && (r.push(c), i.push(d), o.push(h)) } return [r, i, o] } check_segment_validity(e, t, s, n = .5, r = .8) { let i = [], o = 0, a = 0; for (let r = 0; r < e.length; ++r)e[r] === s && (i.push(r), ++o), t[s].data[r] >= n && ++a; let l = o > 0 && a > 0; if (l) { l = o / a > r } return [l, i] } compute_segments(e, t, s, n, r, i = null, o = null) { let [a, l] = o ?? e[0].dims, c = new bt("int32", new Int32Array(a * l), [a, l]), h = []; if (null !== o) for (let t = 0; t < e.length; ++t)e[t] = At(e[t], o, "bilinear", !1); let d = new Int32Array(e[0].data.length), u = new Float32Array(e[0].data.length); for (let s = 0; s < e.length; ++s) { let n = t[s]; for (let t = 0; t < e[s].data.length; ++t)e[s].data[t] *= n, e[s].data[t] > u[t] && (d[t] = s, u[t] = e[s].data[t]) } let _ = 0; for (let i = 0; i < s.length; ++i) { let o = s[i], [a, l] = this.check_segment_validity(d, e, i, n, r); if (a) { ++_; for (let e of l) c.data[e] = _; h.push({ id: _, label_id: o, score: t[i] }) } } return [c, h] } post_process_panoptic_segmentation(e, t = .5, s = .5, n = .8, r = null, i = null) { null === r && (console.warn("`label_ids_to_fuse` unset. No instance will be fused."), r = new Set); const o = e.logits, a = e.pred_masks.sigmoid(); let [l, c, h] = o.dims; if (h -= 1, null !== i && i.length !== l) throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits"); let d = []; for (let e = 0; e < l; ++e) { let l = null !== i ? i[e] : null, c = o[e], u = a[e], [_, f, p] = this.remove_low_and_no_objects(c, u, t, h); if (0 === p.length) { let [e, t] = l ?? u.dims.slice(-2), s = new bt("int32", new Int32Array(e * t).fill(-1), [e, t]); d.push({ segmentation: s, segments_info: [] }); continue } let [m, g] = this.compute_segments(_, f, p, s, n, r, l); d.push({ segmentation: m, segments_info: g }) } return d } post_process_instance_segmentation() { throw Error("Not implemented yet") } } class Sd extends hd { post_process_object_detection(...e) { return ad(...e) } } class Cd extends hd { reshape_input_points(e, t, s) { let n = a(e = structuredClone(e)); if (3 === n.length) n = [1, ...n], e = [e]; else if (4 !== n.length) throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`."); for (let n = 0; n < e.length; ++n) { let r = t[n], i = s[n], o = [i[0] / r[0], i[1] / r[1]]; for (let t = 0; t < e[n].length; ++t)for (let s = 0; s < e[n][t].length; ++s)for (let r = 0; r < e[n][t][s].length; ++r)e[n][t][s][r] *= o[r] } return new bt("float32", Float32Array.from(e.flat(1 / 0)), n) } add_input_labels(e, t) { let s = a(e); if (2 === s.length) s = [1, ...s], e = [e]; else if (3 !== s.length) throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`."); if (s.some(((e, s) => e !== t.dims[s]))) throw Error(`The first ${s.length} dimensions of 'input_points' and 'input_labels' must be the same.`); return new bt("int64", e.flat(1 / 0).map(BigInt), s) } async _call(e, t = null, s = null) { const n = await super._call(e); if (t && (n.input_points = this.reshape_input_points(t, n.original_sizes, n.reshaped_input_sizes)), s) { if (!n.input_points) throw Error("`input_points` must be provided if `input_labels` are provided."); n.input_labels = this.add_input_labels(s, n.input_points) } return n } post_process_masks(e, t, s, { mask_threshold: n = 0, binarize: r = !0, pad_size: i = null } = {}) { const o = [], a = [(i = i ?? this.pad_size).height, i.width]; for (let i = 0; i < t.length; ++i) { const l = t[i], c = s[i], h = e[i], d = []; for (let e = 0; e < h.dims[0]; ++e) { let t = At(h[e], a, "bilinear", !1); if (t = t.slice(null, [0, c[0]], [0, c[1]]), t = At(t, l, "bilinear", !1), r) { const e = new Uint8Array(t.data.length); for (let s = 0; s < t.data.length; ++s)t.data[s] > n && (e[s] = 1); t = new bt("bool", e, t.dims) } d.push(t) } o.push(Ct(d)) } return o } } class Pd extends hd { pad_image(e, t, s, n = {}) { const [r, i, o] = t; return super.pad_image(e, t, { width: r + (s - r % s) % s, height: i + (s - i % s) % s }, { mode: "symmetric", center: !1, constant_values: -1, ...n }) } } class Fd extends hd { async _call(e, t) { Array.isArray(e) || (e = [e]), Array.isArray(t) || (t = [t]); const s = await Promise.all(e.map((e => this.preprocess(e)))), n = await Promise.all(t.map((e => this.preprocess(e, { do_normalize: !1, do_convert_rgb: !1, do_convert_grayscale: !0 })))); return { pixel_values: Ct(s.map(((e, t) => St([e.pixel_values, n[t].pixel_values], 0))), 0), original_sizes: s.map((e => e.original_size)), reshaped_input_sizes: s.map((e => e.reshaped_input_size)) } } } class Ld extends cd { constructor(e) { super(e), this.config.mel_filters ??= sd(Math.floor(1 + this.config.n_fft / 2), this.config.feature_size, 0, 8e3, this.config.sampling_rate, "slaney", "slaney"), this.window = id(this.config.n_fft, "hann") } _extract_fbank_features(e) { const { data: t, dims: s } = rd(e, this.window, this.config.n_fft, this.config.hop_length, { power: 2, mel_filters: this.config.mel_filters, log_mel: "log10", max_num_frames: this.config.nb_max_frames }), n = _t(t)[0]; for (let e = 0; e < t.length; ++e)t[e] = (Math.max(t[e], n - 8) + 4) / 4; return { data: t, dims: s } } async _call(e) { let t; ld(e, "WhisperFeatureExtractor"), e.length > this.config.n_samples ? (console.warn("Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."), t = e.slice(0, this.config.n_samples)) : (t = new Float32Array(this.config.n_samples), t.set(e)); const { data: s, dims: n } = this._extract_fbank_features(t); return { input_features: new bt("float32", s, [1, ...n]) } } } class Id extends cd { _zero_mean_unit_var_norm(e) { const t = e.reduce(((e, t) => e + t), 0) / e.length, s = e.reduce(((e, s) => e + (s - t) ** 2), 0) / e.length; return e.map((e => (e - t) / Math.sqrt(s + 1e-7))) } async _call(e) { ld(e, "Wav2Vec2FeatureExtractor"), e instanceof Float64Array && (e = new Float32Array(e)); let t = e; this.config.do_normalize && (t = this._zero_mean_unit_var_norm(t)); const s = [1, t.length]; return { input_values: new bt("float32", t, s), attention_mask: new bt("int64", new BigInt64Array(t.length).fill(1n), s) } } } class Bd extends cd { constructor(e) { super(e); const t = this.config.sampling_rate, s = sd(256, this.config.num_mel_bins, 20, Math.floor(t / 2), t, null, "kaldi", !0); for (let e = 0; e < s.length; ++e)s[e].push(0); this.mel_filters = s, this.window = id(400, "hann", { periodic: !1 }), this.mean = this.config.mean, this.std = this.config.std } _extract_fbank_features(e, t) { return rd(e, this.window, 400, 160, { fft_length: 512, power: 2, center: !1, preemphasis: .97, mel_filters: this.mel_filters, log_mel: "log", mel_floor: 1.192092955078125e-7, remove_dc_offset: !0, max_num_frames: t, transpose: !0 }) } async _call(e) { ld(e, "ASTFeatureExtractor"); const t = this._extract_fbank_features(e, this.config.max_length); if (this.config.do_normalize) { const e = 2 * this.std; for (let s = 0; s < t.data.length; ++s)t.data[s] = (t.data[s] - this.mean) / e } return { input_values: new bt("float32", t.data, [1, ...t.dims]) } } } class Rd extends cd { constructor(e) { super(e), this.mel_filters = sd(this.config.nb_frequency_bins, this.config.feature_size, this.config.frequency_min, this.config.frequency_max, this.config.sampling_rate, null, "htk"), this.mel_filters_slaney = sd(this.config.nb_frequency_bins, this.config.feature_size, this.config.frequency_min, this.config.frequency_max, this.config.sampling_rate, "slaney", "slaney"), this.window = id(this.config.fft_window_size, "hann") } _get_input_mel(e, t, s, n) { let r, i = !1; const o = e.length - t; if (o > 0) { if ("rand_trunc" !== s) throw new Error(`Truncation strategy "${s}" not implemented`); { i = !0; const s = Math.floor(Math.random() * (o + 1)); e = e.subarray(s, s + t), r = this._extract_fbank_features(e, this.mel_filters_slaney, this.config.nb_max_samples), r.dims = [1, ...r.dims] } } else { if (o < 0) { let s = new Float64Array(t); if (s.set(e), "repeat" === n) for (let n = e.length; n < t; n += e.length)s.set(e.subarray(0, Math.min(e.length, t - n)), n); else if ("repeatpad" === n) for (let t = e.length; t < -o; t += e.length)s.set(e, t); e = s } if ("fusion" === s) throw new Error(`Truncation strategy "${s}" not implemented`); r = this._extract_fbank_features(e, this.mel_filters_slaney, this.config.nb_max_samples), r.dims = [1, ...r.dims] } return { ...r, longer: i } } _extract_fbank_features(e, t, s = null) { return rd(e, this.window, this.config.fft_window_size, this.config.hop_length, { power: 2, mel_filters: t, log_mel: "dB", max_num_frames: s, do_pad: !1, transpose: !0 }) } async _call(e, { max_length: t = null } = {}) { ld(e, "ClapFeatureExtractor"); const s = this._get_input_mel(e, t ?? this.config.nb_max_samples, this.config.truncation, this.config.padding); return { input_features: new bt("float32", s.data, [1, ...s.dims]) } } } class Od extends cd { } class Nd extends i { constructor(e) { super(), this.feature_extractor = e } async _call(e, ...t) { return await this.feature_extractor(e, ...t) } } class Ud extends Nd { async _call(...e) { return await this.feature_extractor(...e) } post_process_masks(...e) { return this.feature_extractor.post_process_masks(...e) } reshape_input_points(...e) { return this.feature_extractor.reshape_input_points(...e) } } class $d extends Nd { async _call(e) { return await this.feature_extractor(e) } } class Dd extends Nd { async _call(e) { return await this.feature_extractor(e) } } class jd extends Nd { async _call(e) { return await this.feature_extractor(e) } } class qd extends Nd { } class Gd { static FEATURE_EXTRACTOR_CLASS_MAPPING = { WhisperFeatureExtractor: Ld, ViTFeatureExtractor: xd, MobileViTFeatureExtractor: bd, OwlViTFeatureExtractor: vd, CLIPFeatureExtractor: pd, ChineseCLIPFeatureExtractor: md, SiglipImageProcessor: gd, ConvNextFeatureExtractor: wd, ConvNextImageProcessor: yd, SegformerFeatureExtractor: dd, BitImageProcessor: ud, DPTFeatureExtractor: _d, GLPNFeatureExtractor: fd, BeitFeatureExtractor: Md, DeiTFeatureExtractor: Ad, DetrFeatureExtractor: Td, YolosFeatureExtractor: Sd, DonutFeatureExtractor: zd, NougatImageProcessor: Ed, ViTImageProcessor: kd, VitMatteImageProcessor: Fd, SamImageProcessor: Cd, Swin2SRImageProcessor: Pd, Wav2Vec2FeatureExtractor: Id, SpeechT5FeatureExtractor: Od, ASTFeatureExtractor: Bd, ClapFeatureExtractor: Rd }; static PROCESSOR_CLASS_MAPPING = { WhisperProcessor: $d, Wav2Vec2ProcessorWithLM: Dd, SamProcessor: Ud, SpeechT5Processor: jd, OwlViTProcessor: qd }; static async from_pretrained(e, { progress_callback: t = null, config: s = null, cache_dir: n = null, local_files_only: r = !1, revision: i = "main" } = {}) { let o = s ?? await st(e, "preprocessor_config.json", !0, { progress_callback: t, config: s, cache_dir: n, local_files_only: r, revision: i }), a = o.feature_extractor_type ?? o.image_processor_type, l = this.FEATURE_EXTRACTOR_CLASS_MAPPING[a]; if (!l) { if (void 0 === o.size) throw new Error(`Unknown Feature Extractor type: ${a}`); console.warn(`Feature extractor type "${a}" not found, assuming ImageFeatureExtractor due to size parameter in config.`), l = hd } return new (this.PROCESSOR_CLASS_MAPPING[o.processor_class] ?? Nd)(new l(o)) } } async function Wd(e) { return Array.isArray(e) || (e = [e]), await Promise.all(e.map((e => Kh.read(e)))) } async function Yd(e, t) { return Array.isArray(e) || (e = [e]), await Promise.all(e.map((e => "string" == typeof e || e instanceof URL ? Hh(e, t) : e instanceof Float64Array ? new Float32Array(e) : e))) } function Vd(e, t) { t && (e = e.map((e => 0 | e))); const [s, n, r, i] = e; return { xmin: s, ymin: n, xmax: r, ymax: i } } class Xd extends i { constructor({ task: e, model: t, tokenizer: s = null, processor: n = null }) { super(), this.task = e, this.model = t, this.tokenizer = s, this.processor = n } async dispose() { await this.model.dispose() } } class Kd extends Xd { constructor(e) { super(e) } async _call(e, { topk: t = 1 } = {}) { const s = this.tokenizer(e, { padding: !0, truncation: !0 }), n = await this.model(s), r = "multi_label_classification" === this.model.config.problem_type ? e => e.sigmoid().data : e => ot(e.data), i = this.model.config.id2label, o = []; for (const e of n.logits) { const s = ct(r(e), t).map((e => ({ label: i[e[0]], score: e[1] }))); 1 === t ? o.push(...s) : o.push(s) } return Array.isArray(e) || 1 === t ? o : o[0] } } class Hd extends Xd { constructor(e) { super(e) } async _call(e, { ignore_labels: t = ["O"] } = {}) { const s = Array.isArray(e), n = this.tokenizer(s ? e : [e], { padding: !0, truncation: !0 }), r = (await this.model(n)).logits, i = this.model.config.id2label, o = []; for (let e = 0; e < r.dims[0]; ++e) { const s = n.input_ids[e], a = r[e], l = []; for (let e = 0; e < a.dims[0]; ++e) { const n = a[e], r = _t(n.data)[1], o = i ? i[r] : `LABEL_${r}`; if (t.includes(o)) continue; const c = this.tokenizer.decode([s[e].item()], { skip_special_tokens: !0 }); if ("" === c) continue; const h = ot(n.data); l.push({ entity: o, score: h[r], index: e, word: c, start: null, end: null }) } o.push(l) } return s ? o : o[0] } } class Qd extends Xd { constructor(e) { super(e) } async _call(e, t, { topk: s = 1 } = {}) { const n = this.tokenizer(e, { text_pair: t, padding: !0, truncation: !0 }), r = await this.model(n), i = []; for (let e = 0; e < r.start_logits.dims[0]; ++e) { const t = n.input_ids[e], o = t.indexOf(this.tokenizer.sep_token_id), a = h(Array.from(ot(r.start_logits[e].data)).map(((e, t) => [e, t])).filter((e => e[1] > o)), Array.from(ot(r.end_logits[e].data)).map(((e, t) => [e, t])).filter((e => e[1] > o))).filter((e => e[0][1] <= e[1][1])).map((e => [e[0][1], e[1][1], e[0][0] * e[1][0]])).sort(((e, t) => t[2] - e[2])); for (let e = 0; e < Math.min(a.length, s); ++e) { const [s, n, r] = a[e], o = [...t].slice(s, n + 1), l = this.tokenizer.decode(o, { skip_special_tokens: !0 }); i.push({ answer: l, score: r }) } } return 1 === s ? i[0] : i } } class Jd extends Xd { constructor(e) { super(e) } async _call(e, { topk: t = 5 } = {}) { const s = this.tokenizer(e, { padding: !0, truncation: !0 }), n = await this.model(s), r = []; for (let e = 0; e < s.input_ids.dims[0]; ++e) { const i = s.input_ids[e], o = i.indexOf(this.tokenizer.mask_token_id); if (-1 === o) throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`); const a = ct(ot(n.logits[e][o].data), t); r.push(a.map((e => { const t = [...i]; return t[o] = e[0], { score: e[1], token: e[0], token_str: this.tokenizer.model.vocab[e[0]], sequence: this.tokenizer.decode(t, { skip_special_tokens: !0 }) } }))) } return Array.isArray(e) ? r : r[0] } } class Zd extends Xd { _key = "generated_text"; constructor(e) { super(e) } async _call(e, t = {}) { Array.isArray(e) || (e = [e]), this.model.config.prefix && (e = e.map((e => this.model.config.prefix + e))); const s = this.model.config.task_specific_params; s && s[this.task] && s[this.task].prefix && (e = e.map((e => s[this.task].prefix + e))); const n = this.tokenizer, r = { padding: !0, truncation: !0 }; let i; i = this instanceof tu && "_build_translation_inputs" in n ? n._build_translation_inputs(e, r, t).input_ids : n(e, r).input_ids; const o = await this.model.generate(i, t); return n.batch_decode(o, { skip_special_tokens: !0 }).map((e => ({ [this._key]: e }))) } } class eu extends Zd { _key = "summary_text"; constructor(e) { super(e) } } class tu extends Zd { _key = "translation_text"; constructor(e) { super(e) } } class su extends Xd { constructor(e) { super(e) } async _call(e, t = {}) { const s = Array.isArray(e); s || (e = [e]); const n = t.add_special_tokens ?? !1; this.tokenizer.padding_side = "left"; const { input_ids: r, attention_mask: i } = this.tokenizer(e, { add_special_tokens: n, padding: !0, truncation: !0 }), o = await this.model.generate(r, t, null, { inputs_attention_mask: i }), a = this.tokenizer.batch_decode(o, { skip_special_tokens: !0 }), l = Array.from({ length: e.length }, (e => [])); for (let t = 0; t < a.length; ++t) { l[Math.floor(t / o.length * e.length)].push({ generated_text: a[t] }) } return s || 1 !== l.length ? l : l[0] } } class nu extends Xd { constructor(e) { super(e), this.label2id = Object.fromEntries(Object.entries(this.model.config.label2id).map((([e, t]) => [e.toLowerCase(), t]))), this.entailment_id = this.label2id.entailment, void 0 === this.entailment_id && (console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."), this.entailment_id = 2), this.contradiction_id = this.label2id.contradiction ?? this.label2id.not_entailment, void 0 === this.contradiction_id && (console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."), this.contradiction_id = 0) } async _call(e, t, { hypothesis_template: s = "This example is {}.", multi_label: n = !1 } = {}) { const r = Array.isArray(e); r || (e = [e]), Array.isArray(t) || (t = [t]); const i = t.map((e => s.replace("{}", e))), o = n || 1 === t.length, a = []; for (const s of e) { const e = []; for (const t of i) { const n = this.tokenizer(s, { text_pair: t, padding: !0, truncation: !0 }), r = await this.model(n); o ? e.push([r.logits.data[this.contradiction_id], r.logits.data[this.entailment_id]]) : e.push(r.logits.data[this.entailment_id]) } const n = (o ? e.map((e => ot(e)[1])) : ot(e)).map(((e, t) => [e, t])).sort(((e, t) => t[0] - e[0])); a.push({ sequence: s, labels: n.map((e => t[e[1]])), scores: n.map((e => e[0])) }) } return r ? a : a[0] } } class ru extends Xd { constructor(e) { super(e) } async _call(e, { pooling: t = "none", normalize: s = !1 } = {}) { const n = this.tokenizer(e, { padding: !0, truncation: !0 }), r = await this.model(n); let i = r.last_hidden_state ?? r.logits; if ("none" === t); else if ("mean" === t) i = Mt(i, n.attention_mask); else { if ("cls" !== t) throw Error(`Pooling method '${t}' not supported.`); i = i.slice(null, 0) } return s && (i = i.normalize(2, -1)), i } } class iu extends Xd { constructor(e) { super(e) } async _call(e, { topk: t = null } = {}) { const s = !Array.isArray(e), n = this.processor.feature_extractor.config.sampling_rate, r = await Yd(e, n), i = this.model.config.id2label, o = []; for (const e of r) { const s = await this.processor(e), n = ct(ot((await this.model(s)).logits[0].data), t).map((e => ({ label: i[e[0]], score: e[1] }))); 1 === t ? o.push(...n) : o.push(n) } return s && 1 !== t ? o[0] : o } } class ou extends Xd { constructor(e) { super(e) } async _call(e, t, { hypothesis_template: s = "This is a sound of {}." } = {}) { const n = !Array.isArray(e); n && (e = [e]); const r = t.map((e => s.replace("{}", e))), i = this.tokenizer(r, { padding: !0, truncation: !0 }), o = this.processor.feature_extractor.config.sampling_rate, a = await Yd(e, o), l = []; for (const e of a) { const s = await this.processor(e), n = ot((await this.model({ ...i, ...s })).logits_per_audio.data); l.push([...n].map(((e, s) => ({ score: e, label: t[s] })))) } return n ? l[0] : l } } class au extends Xd { constructor(e) { super(e) } async _call(e, t = {}) { switch (this.model.config.model_type) { case "whisper": return this._call_whisper(e, t); case "wav2vec2": case "hubert": return this._call_wav2vec2(e, t); default: throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`) } } async _call_wav2vec2(e, t = {}) { t.language && console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'), t.task && console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".'); const s = !Array.isArray(e); s && (e = [e]); const n = this.processor.feature_extractor.config.sampling_rate, r = await Yd(e, n), i = []; for (const e of r) { const t = await this.processor(e), s = (await this.model(t)).logits[0], n = []; for (const e of s) n.push(_t(e.data)[1]); const r = this.tokenizer.decode(n); i.push({ text: r }) } return s ? i[0] : i } async _call_whisper(e, t = {}) { const s = t.return_timestamps ?? !1, n = t.chunk_length_s ?? 0, r = t.chunk_callback ?? null, i = t.force_full_sequences ?? !1; let o = t.stride_length_s ?? null; "word" === s && (t.return_token_timestamps = !0); const a = l(t, "language", null), c = l(t, "task", null); if (a || c || s) { if (t.forced_decoder_ids) throw new Error("Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time."); const e = this.tokenizer.get_decoder_prompt_ids({ language: a, task: c, no_timestamps: !s }); e.length > 0 && (t.forced_decoder_ids = e) } const h = !Array.isArray(e); h && (e = [e]); const d = this.processor.feature_extractor.config.chunk_length / this.model.config.max_source_positions, u = this.processor.feature_extractor.config.hop_length, _ = this.processor.feature_extractor.config.sampling_rate, f = await Yd(e, _), p = []; for (const e of f) { let a = []; if (n > 0) { if (null === o) o = n / 6; else if (n <= o) throw Error("`chunk_length_s` must be larger than `stride_length_s`."); const t = _ * n, s = _ * o, r = t - 2 * s; let i = 0; for (; i < e.length;) { const n = e.subarray(i, i + t), o = await this.processor(n), l = 0 === i, c = i + r >= e.length; a.push({ stride: [n.length, l ? 0 : s, c ? 0 : s], input_features: o.input_features, is_last: c }), i += r } } else a = [{ stride: [e.length, 0, 0], input_features: (await this.processor(e)).input_features, is_last: !0 }]; for (const e of a) { t.num_frames = Math.floor(e.stride[0] / u); const n = await this.model.generate(e.input_features, t); "word" === s ? (e.tokens = n.sequences[0], e.token_timestamps = n.token_timestamps.tolist()[0].map((e => yt(e, 2)))) : e.tokens = n[0], e.stride = e.stride.map((e => e / _)), null !== r && r(e) } const [l, c] = this.tokenizer._decode_asr(a, { time_precision: d, return_timestamps: s, force_full_sequences: i }); p.push({ text: l, ...c }) } return h ? p[0] : p } } class lu extends Xd { constructor(e) { super(e) } async _call(e, t = {}) { const s = Array.isArray(e), n = await Wd(e), { pixel_values: r } = await this.processor(n), i = []; for (const e of r) { e.dims = [1, ...e.dims]; const s = await this.model.generate(e, t), n = this.tokenizer.batch_decode(s, { skip_special_tokens: !0 }).map((e => ({ generated_text: e.trim() }))); i.push(n) } return s ? i : i[0] } } class cu extends Xd { constructor(e) { super(e) } async _call(e, { topk: t = 1 } = {}) { const s = Array.isArray(e), n = await Wd(e), { pixel_values: r } = await this.processor(n), i = await this.model({ pixel_values: r }), o = this.model.config.id2label, a = []; for (const e of i.logits) { const s = ct(ot(e.data), t).map((e => ({ label: o[e[0]], score: e[1] }))); 1 === t ? a.push(...s) : a.push(s) } return s || 1 === t ? a : a[0] } } class hu extends Xd { constructor(e) { super(e), this.subtasks_mapping = { panoptic: "post_process_panoptic_segmentation", instance: "post_process_instance_segmentation", semantic: "post_process_semantic_segmentation" } } async _call(e, { threshold: t = .5, mask_threshold: s = .5, overlap_mask_area_threshold: n = .8, label_ids_to_fuse: r = null, target_sizes: i = null, subtask: o = null } = {}) { if (Array.isArray(e) && 1 !== e.length) throw Error("Image segmentation pipeline currently only supports a batch size of 1."); const a = await Wd(e), l = a.map((e => [e.height, e.width])), { pixel_values: c, pixel_mask: h } = await this.processor(a), d = await this.model({ pixel_values: c, pixel_mask: h }); let u = null; if (null !== o) u = this.subtasks_mapping[o]; else for (let [e, t] of Object.entries(this.subtasks_mapping)) if (t in this.processor.feature_extractor) { u = this.processor.feature_extractor[t].bind(this.processor.feature_extractor), o = e; break } const _ = this.model.config.id2label, f = []; if ("panoptic" === o || "instance" === o) { const e = u(d, t, s, n, r, i ?? l)[0], o = e.segmentation; for (const t of e.segments_info) { const e = new Uint8ClampedArray(o.data.length); for (let s = 0; s < o.data.length; ++s)o.data[s] === t.id && (e[s] = 255); const s = new Kh(e, o.dims[1], o.dims[0], 1); f.push({ score: t.score, label: _[t.label_id], mask: s }) } } else { if ("semantic" !== o) throw Error(`Subtask ${o} not supported.`); { const { segmentation: e, labels: t } = u(d, i ?? l)[0]; for (const s of t) { const t = new Uint8ClampedArray(e.data.length); for (let n = 0; n < e.data.length; ++n)e.data[n] === s && (t[n] = 255); const n = new Kh(t, e.dims[1], e.dims[0], 1); f.push({ score: null, label: _[s], mask: n }) } } } return f } } class du extends Xd { constructor(e) { super(e) } async _call(e, t, { hypothesis_template: s = "This is a photo of {}" } = {}) { const n = Array.isArray(e), r = await Wd(e), i = t.map((e => s.replace("{}", e))), o = this.tokenizer(i, { padding: "siglip" !== this.model.config.model_type || "max_length", truncation: !0 }), { pixel_values: a } = await this.processor(r), l = await this.model({ ...o, pixel_values: a }), c = "siglip" === this.model.config.model_type ? e => e.sigmoid().data : e => ot(e.data), h = []; for (const e of l.logits_per_image) { const s = [...c(e)].map(((e, s) => ({ score: e, label: t[s] }))); s.sort(((e, t) => t.score - e.score)), h.push(s) } return n ? h : h[0] } } class uu extends Xd { constructor(e) { super(e) } async _call(e, { threshold: t = .9, percentage: s = !1 } = {}) { const n = Array.isArray(e); if (n && 1 !== e.length) throw Error("Object detection pipeline currently only supports a batch size of 1."); const r = await Wd(e), i = s ? null : r.map((e => [e.height, e.width])), { pixel_values: o, pixel_mask: a } = await this.processor(r), l = await this.model({ pixel_values: o, pixel_mask: a }), c = this.processor.feature_extractor.post_process_object_detection(l, t, i), h = this.model.config.id2label, d = c.map((e => e.boxes.map(((t, n) => ({ score: e.scores[n], label: h[e.classes[n]], box: Vd(t, !s) }))))); return n ? d : d[0] } } class _u extends Xd { constructor(e) { super(e) } async _call(e, t, { threshold: s = .1, topk: n = null, percentage: r = !1 } = {}) { const i = Array.isArray(e), o = await Wd(e), a = this.tokenizer(t, { padding: !0, truncation: !0 }), l = await this.processor(o), c = []; for (let e = 0; e < o.length; ++e) { const i = o[e], h = r ? null : [[i.height, i.width]], d = l.pixel_values[e].unsqueeze_(0), u = await this.model({ ...a, pixel_values: d }), _ = this.processor.feature_extractor.post_process_object_detection(u, s, h, !0)[0]; let f = _.boxes.map(((e, s) => ({ score: _.scores[s], label: t[_.classes[s]], box: Vd(e, !r) }))).sort(((e, t) => t.score - e.score)); null !== n && (f = f.slice(0, n)), c.push(f) } return i ? c : c[0] } } class fu extends Xd { constructor(e) { super(e) } async _call(e, t, s = {}) { const n = (await Wd(e))[0], { pixel_values: r } = await this.processor(n), i = `<s_docvqa><s_question>${t}</s_question><s_answer>`, o = this.tokenizer(i, { add_special_tokens: !1, padding: !0, truncation: !0 }).input_ids, a = await this.model.generate(r, { ...s, decoder_input_ids: o, max_length: this.model.config.decoder.max_position_embeddings }), l = this.tokenizer.batch_decode(a)[0].match(/<s_answer>(.*?)<\/s_answer>/); let c = null; return l && l.length >= 2 && (c = l[1].trim()), [{ answer: c }] } } class pu extends Xd { DEFAULT_VOCODER_ID = "Xenova/speecht5_hifigan"; constructor(e) { super(e), this.vocoder = e.vocoder ?? null } async _call(e, { speaker_embeddings: t = null } = {}) { return this.processor ? this._call_text_to_spectrogram(e, { speaker_embeddings: t }) : this._call_text_to_waveform(e) } async _call_text_to_waveform(e) { const t = this.tokenizer(e, { padding: !0, truncation: !0 }), { waveform: s } = await this.model(t), n = this.model.config.sampling_rate; return { audio: s.data, sampling_rate: n } } async _call_text_to_spectrogram(e, { speaker_embeddings: t }) { if (this.vocoder || (console.log("No vocoder specified, using default HifiGan vocoder."), this.vocoder = await hh.from_pretrained(this.DEFAULT_VOCODER_ID, { quantized: !1 })), ("string" == typeof t || t instanceof URL) && (t = new Float32Array(await (await fetch(t)).arrayBuffer())), t instanceof Float32Array) t = new bt("float32", t, [1, t.length]); else if (!(t instanceof bt)) throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`."); const { input_ids: s } = this.tokenizer(e, { padding: !0, truncation: !0 }), { waveform: n } = await this.model.generate_speech(s, t, { vocoder: this.vocoder }), r = this.processor.feature_extractor.config.sampling_rate; return { audio: n.data, sampling_rate: r } } } class mu extends Xd { constructor(e) { super(e) } async _call(e) { const t = await Wd(e), s = await this.processor(t), n = await this.model(s), r = []; for (const e of n.reconstruction) { const t = e.squeeze().clamp_(0, 1).mul_(255).round_().to("uint8"); r.push(Kh.fromTensor(t)) } return r.length > 1 ? r : r[0] } } class gu extends Xd { constructor(e) { super(e) } async _call(e) { const t = await Wd(e), s = await this.processor(t), { predicted_depth: n } = await this.model(s), r = []; for (let e = 0; e < t.length; ++e) { const s = At(n[e], t[e].size.reverse(), "bilinear", !1), i = s.mul_(255 / _t(s.data)[0]).to("uint8"); r.push({ predicted_depth: n[e], depth: Kh.fromTensor(i) }) } return r.length > 1 ? r : r[0] } } const wu = Object.freeze({ "text-classification": { tokenizer: Nn, pipeline: Kd, model: dh, default: { model: "Xenova/distilbert-base-uncased-finetuned-sst-2-english" }, type: "text" }, "token-classification": { tokenizer: Nn, pipeline: Hd, model: uh, default: { model: "Xenova/bert-base-multilingual-cased-ner-hrl" }, type: "text" }, "question-answering": { tokenizer: Nn, pipeline: Qd, model: yh, default: { model: "Xenova/distilbert-base-cased-distilled-squad" }, type: "text" }, "fill-mask": { tokenizer: Nn, pipeline: Jd, model: wh, default: { model: "Xenova/bert-base-uncased" }, type: "text" }, summarization: { tokenizer: Nn, pipeline: eu, model: _h, default: { model: "Xenova/distilbart-cnn-6-6" }, type: "text" }, translation: { tokenizer: Nn, pipeline: tu, model: _h, default: { model: "Xenova/t5-small" }, type: "text" }, "text2text-generation": { tokenizer: Nn, pipeline: Zd, model: _h, default: { model: "Xenova/flan-t5-small" }, type: "text" }, "text-generation": { tokenizer: Nn, pipeline: su, model: gh, default: { model: "Xenova/gpt2" }, type: "text" }, "zero-shot-classification": { tokenizer: Nn, pipeline: nu, model: dh, default: { model: "Xenova/distilbert-base-uncased-mnli" }, type: "text" }, "audio-classification": { pipeline: iu, model: Th, processor: Gd, default: { model: "Xenova/wav2vec2-base-superb-ks" }, type: "audio" }, "zero-shot-audio-classification": { tokenizer: Nn, pipeline: ou, model: hh, processor: Gd, default: { model: "Xenova/clap-htsat-unfused" }, type: "multimodal" }, "automatic-speech-recognition": { tokenizer: Nn, pipeline: au, model: [fh, Eh], processor: Gd, default: { model: "Xenova/whisper-tiny.en" }, type: "multimodal" }, "text-to-audio": { tokenizer: Nn, pipeline: pu, model: [mh, ph], processor: [Gd, null], default: { model: "Xenova/speecht5_tts" }, type: "text" }, "image-to-text": { tokenizer: Nn, pipeline: lu, model: xh, processor: Gd, default: { model: "Xenova/vit-gpt2-image-captioning" }, type: "multimodal" }, "image-classification": { pipeline: cu, model: kh, processor: Gd, default: { model: "Xenova/vit-base-patch16-224" }, type: "multimodal" }, "image-segmentation": { pipeline: hu, model: [bh, vh], processor: Gd, default: { model: "Xenova/detr-resnet-50-panoptic" }, type: "multimodal" }, "zero-shot-image-classification": { tokenizer: Nn, pipeline: du, model: hh, processor: Gd, default: { model: "Xenova/clip-vit-base-patch32" }, type: "multimodal" }, "object-detection": { pipeline: uu, model: Ah, processor: Gd, default: { model: "Xenova/detr-resnet-50" }, type: "multimodal" }, "zero-shot-object-detection": { tokenizer: Nn, pipeline: _u, model: Mh, processor: Gd, default: { model: "Xenova/owlvit-base-patch32" }, type: "multimodal" }, "document-question-answering": { tokenizer: Nn, pipeline: fu, model: Sh, processor: Gd, default: { model: "Xenova/donut-base-finetuned-docvqa" }, type: "multimodal" }, "image-to-image": { pipeline: mu, model: Ph, processor: Gd, default: { model: "Xenova/swin2SR-classical-sr-x2-64" }, type: "image" }, "depth-estimation": { pipeline: gu, model: Fh, processor: Gd, default: { model: "Xenova/dpt-large" }, type: "image" }, "feature-extraction": { tokenizer: Nn, pipeline: ru, model: hh, default: { model: "Xenova/all-MiniLM-L6-v2" }, type: "text" } }), yu = Object.freeze({ "sentiment-analysis": "text-classification", ner: "token-classification", asr: "automatic-speech-recognition", "text-to-speech": "text-to-audio", embeddings: "feature-extraction" }); async function xu(e, t = null, { quantized: s = !0, progress_callback: r = null, config: i = null, cache_dir: o = null, local_files_only: a = !1, revision: l = "main" } = {}) { e = yu[e] ?? e; const c = wu[e.split("_", 1)[0]]; if (!c) throw Error(`Unsupported pipeline: ${e}. Must be one of [${Object.keys(wu)}]`); t || (t = c.default.model, console.log(`No model specified. Using default model: "${t}".`)); const h = { quantized: s, progress_callback: r, config: i, cache_dir: o, local_files_only: a, revision: l }, d = new Map([["tokenizer", c.tokenizer], ["model", c.model], ["processor", c.processor]]), u = await async function (e, t, s) { const n = Object.create(null), r = []; for (let [i, o] of e.entries()) { if (!o) continue; let e; e = Array.isArray(o) ? new Promise((async (e, n) => { let r; for (let n of o) { if (null === n) return void e(null); try { return void e(await n.from_pretrained(t, s)) } catch (e) { r = e } } n(r) })) : o.from_pretrained(t, s), n[i] = e, r.push(e) } await Promise.all(r); for (let [e, t] of Object.entries(n)) n[e] = await t; return n }(d, t, h); u.task = e, n(r, { status: "ready", task: e, model: t }); return new (0, c.pipeline)(u) } export { Bd as ASTFeatureExtractor, Yo as ASTForAudioClassification, Wo as ASTModel, Go as ASTPreTrainedModel, eo as AlbertForMaskedLM, Zi as AlbertForQuestionAnswering, Ji as AlbertForSequenceClassification, Qi as AlbertModel, Hi as AlbertPreTrainedModel, Vs as AlbertTokenizer, iu as AudioClassificationPipeline, $n as AutoConfig, hh as AutoModel, Th as AutoModelForAudioClassification, Eh as AutoModelForCTC, gh as AutoModelForCausalLM, Fh as AutoModelForDepthEstimation, Sh as AutoModelForDocumentQuestionAnswering, kh as AutoModelForImageClassification, Ch as AutoModelForImageMatting, bh as AutoModelForImageSegmentation, Ph as AutoModelForImageToImage, zh as AutoModelForMaskGeneration, wh as AutoModelForMaskedLM, Ah as AutoModelForObjectDetection, yh as AutoModelForQuestionAnswering, vh as AutoModelForSemanticSegmentation, _h as AutoModelForSeq2SeqLM, dh as AutoModelForSequenceClassification, fh as AutoModelForSpeechSeq2Seq, ph as AutoModelForTextToSpectrogram, mh as AutoModelForTextToWaveform, uh as AutoModelForTokenClassification, xh as AutoModelForVision2Seq, Mh as AutoModelForZeroShotObjectDetection, Gd as AutoProcessor, Nn as AutoTokenizer, au as AutomaticSpeechRecognitionPipeline, _o as BartForConditionalGeneration, fo as BartForSequenceClassification, uo as BartModel, ho as BartPretrainedModel, ln as BartTokenizer, Ir as BaseModelOutput, Md as BeitFeatureExtractor, sl as BeitForImageClassification, tl as BeitModel, el as BeitPreTrainedModel, Or as BertForMaskedLM, $r as BertForQuestionAnswering, Nr as BertForSequenceClassification, Ur as BertForTokenClassification, Rr as BertModel, Br as BertPreTrainedModel, Ys as BertTokenizer, ud as BitImageProcessor, bo as BlenderbotForConditionalGeneration, ko as BlenderbotModel, xo as BlenderbotPreTrainedModel, Mo as BlenderbotSmallForConditionalGeneration, Ao as BlenderbotSmallModel, vo as BlenderbotSmallPreTrainedModel, In as BlenderbotSmallTokenizer, Ln as BlenderbotTokenizer, Ra as BloomForCausalLM, Ba as BloomModel, Ia as BloomPreTrainedModel, un as BloomTokenizer, pd as CLIPFeatureExtractor, Jo as CLIPModel, Qo as CLIPPreTrainedModel, ca as CLIPSegForImageSegmentation, la as CLIPSegModel, aa as CLIPSegPreTrainedModel, Zo as CLIPTextModelWithProjection, Sn as CLIPTokenizer, ea as CLIPVisionModelWithProjection, ai as CamembertForMaskedLM, hi as CamembertForQuestionAnswering, li as CamembertForSequenceClassification, ci as CamembertForTokenClassification, oi as CamembertModel, ii as CamembertPreTrainedModel, sn as CamembertTokenizer, Nh as CausalLMOutput, Uh as CausalLMOutputWithPast, md as ChineseCLIPFeatureExtractor, oa as ChineseCLIPModel, ia as ChineseCLIPPreTrainedModel, Sc as ClapAudioModelWithProjection, Rd as ClapFeatureExtractor, Ec as ClapModel, zc as ClapPreTrainedModel, Tc as ClapTextModelWithProjection, Ea as CodeGenForCausalLM, za as CodeGenModel, Ma as CodeGenPreTrainedModel, Tn as CodeGenTokenizer, pn as CodeLlamaTokenizer, Kr as ConvBertForMaskedLM, Jr as ConvBertForQuestionAnswering, Hr as ConvBertForSequenceClassification, Qr as ConvBertForTokenClassification, Xr as ConvBertModel, Vr as ConvBertPreTrainedModel, Zs as ConvBertTokenizer, wd as ConvNextFeatureExtractor, Bl as ConvNextForImageClassification, yd as ConvNextImageProcessor, Il as ConvNextModel, Ll as ConvNextPreTrainedModel, Nl as ConvNextV2ForImageClassification, Ol as ConvNextV2Model, Rl as ConvNextV2PreTrainedModel, _d as DPTFeatureExtractor, El as DPTForDepthEstimation, zl as DPTModel, Ml as DPTPreTrainedModel, _i as DebertaForMaskedLM, mi as DebertaForQuestionAnswering, fi as DebertaForSequenceClassification, pi as DebertaForTokenClassification, ui as DebertaModel, di as DebertaPreTrainedModel, Hs as DebertaTokenizer, yi as DebertaV2ForMaskedLM, bi as DebertaV2ForQuestionAnswering, xi as DebertaV2ForSequenceClassification, ki as DebertaV2ForTokenClassification, wi as DebertaV2Model, gi as DebertaV2PreTrainedModel, Qs as DebertaV2Tokenizer, Ad as DeiTFeatureExtractor, pl as DeiTForImageClassification, fl as DeiTModel, _l as DeiTPreTrainedModel, gu as DepthEstimationPipeline, Td as DetrFeatureExtractor, il as DetrForObjectDetection, ol as DetrForSegmentation, rl as DetrModel, al as DetrObjectDetectionOutput, nl as DetrPreTrainedModel, ll as DetrSegmentationOutput, Dl as Dinov2ForImageClassification, $l as Dinov2Model, Ul as Dinov2PreTrainedModel, Ti as DistilBertForMaskedLM, Ei as DistilBertForQuestionAnswering, Mi as DistilBertForSequenceClassification, zi as DistilBertForTokenClassification, Ai as DistilBertModel, vi as DistilBertPreTrainedModel, tn as DistilBertTokenizer, fu as DocumentQuestionAnsweringPipeline, zd as DonutFeatureExtractor, Fl as DonutSwinModel, Pl as DonutSwinPreTrainedModel, ti as ElectraForMaskedLM, ri as ElectraForQuestionAnswering, si as ElectraForSequenceClassification, ni as ElectraForTokenClassification, ei as ElectraModel, Zr as ElectraPreTrainedModel, rn as ElectraTokenizer, Pi as EsmForMaskedLM, Fi as EsmForSequenceClassification, Li as EsmForTokenClassification, Ci as EsmModel, Si as EsmPreTrainedModel, xn as EsmTokenizer, gt as FFT, Mc as FalconForCausalLM, Ac as FalconModel, vc as FalconPreTrainedModel, wn as FalconTokenizer, ru as FeatureExtractionPipeline, cd as FeatureExtractor, Jd as FillMaskPipeline, fd as GLPNFeatureExtractor, Cl as GLPNForDepthEstimation, Sl as GLPNModel, Tl as GLPNPreTrainedModel, ua as GPT2LMHeadModel, da as GPT2Model, ha as GPT2PreTrainedModel, an as GPT2Tokenizer, Aa as GPTBigCodeForCausalLM, va as GPTBigCodeModel, ba as GPTBigCodePreTrainedModel, ka as GPTJForCausalLM, xa as GPTJModel, ya as GPTJPreTrainedModel, pa as GPTNeoForCausalLM, fa as GPTNeoModel, _a as GPTNeoPreTrainedModel, wa as GPTNeoXForCausalLM, ga as GPTNeoXModel, ma as GPTNeoXPreTrainedModel, yn as GPTNeoXTokenizer, Js as HerbertTokenizer, ac as HubertForCTC, lc as HubertForSequenceClassification, oc as HubertModel, ic as HubertPreTrainedModel, cu as ImageClassificationPipeline, hd as ImageFeatureExtractor, $h as ImageMattingOutput, hu as ImageSegmentationPipeline, mu as ImageToImagePipeline, lu as ImageToTextPipeline, Ca as LlamaForCausalLM, Sa as LlamaModel, Ta as LlamaPreTrainedModel, fn as LlamaTokenizer, oo as LongT5ForConditionalGeneration, io as LongT5Model, ro as LongT5PreTrainedModel, ec as M2M100ForConditionalGeneration, Zl as M2M100Model, Jl as M2M100PreTrainedModel, vn as M2M100Tokenizer, hn as MBart50Tokenizer, yo as MBartForCausalLM, go as MBartForConditionalGeneration, wo as MBartForSequenceClassification, mo as MBartModel, po as MBartPreTrainedModel, cn as MBartTokenizer, Di as MPNetForMaskedLM, Gi as MPNetForQuestionAnswering, ji as MPNetForSequenceClassification, qi as MPNetForTokenClassification, $i as MPNetModel, Ui as MPNetPreTrainedModel, gn as MPNetTokenizer, co as MT5ForConditionalGeneration, lo as MT5Model, ao as MT5PreTrainedModel, Ql as MarianMTModel, Hl as MarianModel, Kl as MarianPreTrainedModel, Pn as MarianTokenizer, Rh as MaskedLMOutput, bc as MistralForCausalLM, kc as MistralModel, xc as MistralPreTrainedModel, Ri as MobileBertForMaskedLM, Ni as MobileBertForQuestionAnswering, Oi as MobileBertForSequenceClassification, Bi as MobileBertModel, Ii as MobileBertPreTrainedModel, Xs as MobileBertTokenizer, bd as MobileViTFeatureExtractor, Ha as MobileViTForImageClassification, Ka as MobileViTModel, Xa as MobileViTPreTrainedModel, Lr as ModelOutput, Ua as MptForCausalLM, Na as MptModel, Oa as MptPreTrainedModel, bn as NllbTokenizer, Ed as NougatImageProcessor, Rn as NougatTokenizer, ja as OPTForCausalLM, Da as OPTModel, $a as OPTPreTrainedModel, uu as ObjectDetectionPipeline, vd as OwlViTFeatureExtractor, Za as OwlViTForObjectDetection, Ja as OwlViTModel, Qa as OwlViTPreTrainedModel, qd as OwlViTProcessor, La as PhiForCausalLM, Fa as PhiModel, Pa as PhiPreTrainedModel, Xd as Pipeline, Fr as PreTrainedModel, Ws as PreTrainedTokenizer, Un as PretrainedConfig, Rc as PretrainedMixin, Nd as Processor, Oh as QuestionAnsweringModelOutput, Qd as QuestionAnsweringPipeline, Kh as RawImage, wl as ResNetForImageClassification, gl as ResNetModel, ml as ResNetPreTrainedModel, qr as RoFormerForMaskedLM, Yr as RoFormerForQuestionAnswering, Gr as RoFormerForSequenceClassification, Wr as RoFormerForTokenClassification, jr as RoFormerModel, Dr as RoFormerPreTrainedModel, en as RoFormerTokenizer, To as RobertaForMaskedLM, Po as RobertaForQuestionAnswering, So as RobertaForSequenceClassification, Co as RobertaForTokenClassification, Eo as RobertaModel, zo as RobertaPreTrainedModel, dn as RobertaTokenizer, Cd as SamImageProcessor, Xl as SamImageSegmentationOutput, Vl as SamModel, Yl as SamPreTrainedModel, Ud as SamProcessor, dd as SegformerFeatureExtractor, Ic as SegformerForImageClassification, Bc as SegformerForSemanticSegmentation, Lc as SegformerModel, Fc as SegformerPreTrainedModel, Lh as Seq2SeqLMOutput, Ih as SequenceClassifierOutput, gd as SiglipImageProcessor, sa as SiglipModel, ta as SiglipPreTrainedModel, na as SiglipTextModel, Cn as SiglipTokenizer, ra as SiglipVisionModel, Od as SpeechT5FeatureExtractor, pc as SpeechT5ForSpeechToText, mc as SpeechT5ForTextToSpeech, gc as SpeechT5HifiGan, fc as SpeechT5Model, _c as SpeechT5PreTrainedModel, jd as SpeechT5Processor, Bn as SpeechT5Tokenizer, Vi as SqueezeBertForMaskedLM, Ki as SqueezeBertForQuestionAnswering, Xi as SqueezeBertForSequenceClassification, Yi as SqueezeBertModel, Wi as SqueezeBertPreTrainedModel, Ks as SqueezeBertTokenizer, eu as SummarizationPipeline, Al as Swin2SRForImageSuperResolution, Pd as Swin2SRImageProcessor, vl as Swin2SRModel, bl as Swin2SRPreTrainedModel, kl as SwinForImageClassification, xl as SwinModel, yl as SwinPreTrainedModel, no as T5ForConditionalGeneration, so as T5Model, to as T5PreTrainedModel, on as T5Tokenizer, dl as TableTransformerForObjectDetection, hl as TableTransformerModel, ul as TableTransformerObjectDetectionOutput, cl as TableTransformerPreTrainedModel, bt as Tensor, Zd as Text2TextGenerationPipeline, Kd as TextClassificationPipeline, su as TextGenerationPipeline, pu as TextToAudioPipeline, Hd as TokenClassificationPipeline, Bh as TokenClassifierOutput, Kt as TokenizerModel, yc as TrOCRForCausalLM, wc as TrOCRPreTrainedModel, tu as TranslationPipeline, xd as ViTFeatureExtractor, Wa as ViTForImageClassification, kd as ViTImageProcessor, Ga as ViTModel, qa as ViTPreTrainedModel, Ho as VisionEncoderDecoderModel, Va as VitMatteForImageMatting, Fd as VitMatteImageProcessor, Ya as VitMattePreTrainedModel, Pc as VitsModel, Dh as VitsModelOutput, Cc as VitsPreTrainedModel, On as VitsTokenizer, Fn as Wav2Vec2CTCTokenizer, Id as Wav2Vec2FeatureExtractor, nc as Wav2Vec2ForCTC, rc as Wav2Vec2ForSequenceClassification, sc as Wav2Vec2Model, tc as Wav2Vec2PreTrainedModel, Dd as Wav2Vec2ProcessorWithLM, dc as WavLMForCTC, uc as WavLMForSequenceClassification, hc as WavLMModel, cc as WavLMPreTrainedModel, Ld as WhisperFeatureExtractor, Ko as WhisperForConditionalGeneration, Xo as WhisperModel, Vo as WhisperPreTrainedModel, $d as WhisperProcessor, En as WhisperTokenizer, Oo as XLMForQuestionAnswering, Bo as XLMForSequenceClassification, Ro as XLMForTokenClassification, Lo as XLMModel, Fo as XLMPreTrainedModel, $o as XLMRobertaForMaskedLM, qo as XLMRobertaForQuestionAnswering, Do as XLMRobertaForSequenceClassification, jo as XLMRobertaForTokenClassification, Uo as XLMRobertaModel, No as XLMRobertaPreTrainedModel, mn as XLMRobertaTokenizer, nn as XLMTokenizer, Io as XLMWithLMHeadModel, Sd as YolosFeatureExtractor, Gl as YolosForObjectDetection, ql as YolosModel, Wl as YolosObjectDetectionOutput, jl as YolosPreTrainedModel, ou as ZeroShotAudioClassificationPipeline, nu as ZeroShotClassificationPipeline, du as ZeroShotImageClassificationPipeline, _u as ZeroShotObjectDetectionPipeline, St as cat, ht as cos_sim, lt as dot, Lt as dynamicTimeWarping, Xe as env, ct as getTopItems, Qh as hanning, At as interpolate, rt as interpolate_data, at as log_softmax, dt as magnitude, _t as max, Ft as mean, Mt as mean_pooling, wt as medianFilter, sd as mel_filter_bank, ut as min, It as ones, Bt as ones_like, xu as pipeline, Hh as read_audio, yt as round, ot as softmax, rd as spectrogram, Ct as stack, Pt as std_mean, vt as transpose, it as transpose_data, id as window_function }; export default null;
//# sourceMappingURL=/sm/9b6ed9e09f75730382f6c3a8bc04d0b9ea342f011d7a46e19e8a90bc5adeff75.map